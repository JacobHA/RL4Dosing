{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_env import CellEnv\n",
    "# Use sb3 env checker:\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "env = CellEnv(dt=0.15)\n",
    "# eval wrapper:\n",
    "env = TimeLimit(env, 1000)\n",
    "# use the monitor wrapper to log the results:\n",
    "env = Monitor(env)\n",
    "eval_env = TimeLimit(CellEnv(dt=0.15), 1000)\n",
    "eval_env = Monitor(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./rl-logs//CellEnv-v0-U-rawlik_2\n",
      "-------------------------------------\n",
      "| batch_size             | 64       |\n",
      "| beta                   | 1        |\n",
      "| buffer_size            | 100000   |\n",
      "| gradient_steps         | 1        |\n",
      "| hidden_dim             | 64       |\n",
      "| learning_rate          | 0.0035   |\n",
      "| learning_starts        | 5000     |\n",
      "| max_grad_norm          | 10       |\n",
      "| num_nets               | 2        |\n",
      "| target_update_interval | 50       |\n",
      "| tau                    | 0.73     |\n",
      "| tau_theta              | 0.76     |\n",
      "| theta_update_interval  | 10       |\n",
      "| train_freq             | 1        |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from avg_rwds.UAgent import UAgent\n",
    "\n",
    "model = UAgent(env, \n",
    "               use_rawlik=True,\n",
    "               learning_rate=3.5e-3,\n",
    "               batch_size=64,\n",
    "               beta=1,\n",
    "               tau=0.73,\n",
    "               target_update_interval=50,\n",
    "               theta_update_interval=10,\n",
    "               tau_theta=0.76,\n",
    "               prior_tau=0.9,\n",
    "               prior_update_interval=5000,\n",
    "               tensorboard_log=\"./rl-logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 0        |\n",
      "|    action 1 (%)       | 100      |\n",
      "|    auc                | -382     |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -382     |\n",
      "|    fps                | 1.49e+03 |\n",
      "|    time               | 6.72     |\n",
      "| rollout/              |          |\n",
      "|    beta               | 1        |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 1000     |\n",
      "|    fps                | 885      |\n",
      "|    num. episodes      | 1        |\n",
      "|    num. updates       | 0        |\n",
      "| train/                |          |\n",
      "|    lr                 | 0.0035   |\n",
      "|    theta              | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 0        |\n",
      "|    action 1 (%)       | 100      |\n",
      "|    auc                | -763     |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -382     |\n",
      "|    fps                | 1.51e+03 |\n",
      "|    time               | 6.63     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 48       |\n",
      "|    action 1 (%)       | 52       |\n",
      "|    avg_entropy        | 0.000655 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.013   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -13      |\n",
      "|    neg_free_energy    | -0.0124  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 2000     |\n",
      "|    fps                | 989      |\n",
      "|    num. episodes      | 2        |\n",
      "|    num. updates       | 0        |\n",
      "| train/                |          |\n",
      "|    lr                 | 0.0035   |\n",
      "|    theta              | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0         |\n",
      "|    action 1 (%)       | 100       |\n",
      "|    auc                | -1.14e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -382      |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.63      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.2      |\n",
      "|    action 1 (%)       | 51.8      |\n",
      "|    avg_entropy        | 0.000662  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0138   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.8     |\n",
      "|    neg_free_energy    | -0.0131   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 3000      |\n",
      "|    fps                | 993       |\n",
      "|    num. episodes      | 3         |\n",
      "|    num. updates       | 0         |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0         |\n",
      "|    action 1 (%)       | 100       |\n",
      "|    auc                | -1.53e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -382      |\n",
      "|    fps                | 1.5e+03   |\n",
      "|    time               | 6.68      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.2      |\n",
      "|    action 1 (%)       | 51.8      |\n",
      "|    avg_entropy        | 0.000653  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0148   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -14.8     |\n",
      "|    neg_free_energy    | -0.0142   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 4000      |\n",
      "|    fps                | 1e+03     |\n",
      "|    num. episodes      | 4         |\n",
      "|    num. updates       | 0         |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0         |\n",
      "|    action 1 (%)       | 100       |\n",
      "|    auc                | -1.91e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -382      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.7       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.1      |\n",
      "|    action 1 (%)       | 51.9      |\n",
      "|    avg_entropy        | 0.000657  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00865  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.65     |\n",
      "|    neg_free_energy    | -0.008    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 5000      |\n",
      "|    fps                | 982       |\n",
      "|    num. episodes      | 5         |\n",
      "|    num. updates       | 0         |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97.8      |\n",
      "|    action 1 (%)       | 2.2       |\n",
      "|    auc                | -2.28e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -375      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.51      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.6      |\n",
      "|    action 1 (%)       | 50.4      |\n",
      "|    avg_entropy        | 0.000667  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0166   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -16.6     |\n",
      "|    neg_free_energy    | -0.0159   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 6000      |\n",
      "|    fps                | 344       |\n",
      "|    num. episodes      | 6         |\n",
      "|    num. updates       | 1000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.00447   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00393   |\n",
      "|    prior_loss         | 0.000297  |\n",
      "|    theta              | 0.00497   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 96.1      |\n",
      "|    action 1 (%)       | 3.9       |\n",
      "|    auc                | -2.64e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -362      |\n",
      "|    fps                | 1.5e+03   |\n",
      "|    time               | 6.68      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.6      |\n",
      "|    action 1 (%)       | 47.4      |\n",
      "|    avg_entropy        | 0.000989  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0148   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -14.8     |\n",
      "|    neg_free_energy    | -0.0138   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 7000      |\n",
      "|    fps                | 353       |\n",
      "|    num. episodes      | 7         |\n",
      "|    num. updates       | 2000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.00811   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00956   |\n",
      "|    prior_loss         | 0.000243  |\n",
      "|    theta              | 0.0078    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97        |\n",
      "|    action 1 (%)       | 3         |\n",
      "|    auc                | -3.01e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -370      |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.6       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.9      |\n",
      "|    action 1 (%)       | 51.1      |\n",
      "|    avg_entropy        | 0.000701  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00709  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.09     |\n",
      "|    neg_free_energy    | -0.00639  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 8000      |\n",
      "|    fps                | 336       |\n",
      "|    num. episodes      | 8         |\n",
      "|    num. updates       | 3000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.00686   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00736  |\n",
      "|    prior_loss         | 0.000148  |\n",
      "|    theta              | 0.00604   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 60.3      |\n",
      "|    action 1 (%)       | 39.7      |\n",
      "|    auc                | -3.06e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -44.4     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47        |\n",
      "|    action 1 (%)       | 53        |\n",
      "|    avg_entropy        | 0.00102   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.012    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12       |\n",
      "|    neg_free_energy    | -0.011    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 9000      |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 9         |\n",
      "|    num. updates       | 4000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.00845   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0219    |\n",
      "|    prior_loss         | 0.000304  |\n",
      "|    theta              | 0.0142    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 96.8      |\n",
      "|    action 1 (%)       | 3.2       |\n",
      "|    auc                | -3.43e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -369      |\n",
      "|    fps                | 1.5e+03   |\n",
      "|    time               | 6.65      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.6      |\n",
      "|    action 1 (%)       | 50.4      |\n",
      "|    avg_entropy        | 0.000824  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0179   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -17.9     |\n",
      "|    neg_free_energy    | -0.0171   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 10000     |\n",
      "|    fps                | 329       |\n",
      "|    num. episodes      | 10        |\n",
      "|    num. updates       | 5000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.0201    |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0105    |\n",
      "|    prior_loss         | 0.000255  |\n",
      "|    theta              | 0.0134    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 95.7      |\n",
      "|    action 1 (%)       | 4.3       |\n",
      "|    auc                | -3.79e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -359      |\n",
      "|    fps                | 1.5e+03   |\n",
      "|    time               | 6.68      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.9      |\n",
      "|    action 1 (%)       | 48.1      |\n",
      "|    avg_entropy        | 0.000606  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0123   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.3     |\n",
      "|    neg_free_energy    | -0.0117   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 11000     |\n",
      "|    fps                | 345       |\n",
      "|    num. episodes      | 11        |\n",
      "|    num. updates       | 6000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.0467    |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0112    |\n",
      "|    prior_loss         | 0.000129  |\n",
      "|    theta              | 0.00775   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 91.8      |\n",
      "|    action 1 (%)       | 8.2       |\n",
      "|    auc                | -4.11e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -324      |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.64      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 0.000724  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00951  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.51     |\n",
      "|    neg_free_energy    | -0.00879  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 12000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 12        |\n",
      "|    num. updates       | 7000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.0274    |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00753   |\n",
      "|    prior_loss         | 9.91e-05  |\n",
      "|    theta              | 0.0124    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97.1      |\n",
      "|    action 1 (%)       | 2.9       |\n",
      "|    auc                | -4.48e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -371      |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.61      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.6      |\n",
      "|    action 1 (%)       | 47.4      |\n",
      "|    avg_entropy        | 0.000993  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0176   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -17.6     |\n",
      "|    neg_free_energy    | -0.0166   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 13000     |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 13        |\n",
      "|    num. updates       | 8000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.0795    |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0029    |\n",
      "|    prior_loss         | 7.87e-05  |\n",
      "|    theta              | 0.0125    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97.1      |\n",
      "|    action 1 (%)       | 2.9       |\n",
      "|    auc                | -4.85e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -371      |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.64      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.4      |\n",
      "|    action 1 (%)       | 48.6      |\n",
      "|    avg_entropy        | 0.000632  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00913  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.13     |\n",
      "|    neg_free_energy    | -0.0085   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 14000     |\n",
      "|    fps                | 356       |\n",
      "|    num. episodes      | 14        |\n",
      "|    num. updates       | 9000      |\n",
      "| train/                |           |\n",
      "|    loss               | 0.11      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0117    |\n",
      "|    prior_loss         | 0.000125  |\n",
      "|    theta              | 0.012     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.4      |\n",
      "|    action 1 (%)       | 41.6      |\n",
      "|    auc                | -4.89e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -41       |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.62      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.3      |\n",
      "|    action 1 (%)       | 51.7      |\n",
      "|    avg_entropy        | 0.000621  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0149   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -14.9     |\n",
      "|    neg_free_energy    | -0.0143   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 15000     |\n",
      "|    fps                | 353       |\n",
      "|    num. episodes      | 15        |\n",
      "|    num. updates       | 10000     |\n",
      "| train/                |           |\n",
      "|    loss               | 0.292     |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00175   |\n",
      "|    prior_loss         | 0.000231  |\n",
      "|    theta              | 0.00703   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 59.2      |\n",
      "|    action 1 (%)       | 40.8      |\n",
      "|    auc                | -4.97e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -73.3     |\n",
      "|    fps                | 1.5e+03   |\n",
      "|    time               | 6.67      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.8      |\n",
      "|    action 1 (%)       | 48.2      |\n",
      "|    avg_entropy        | 0.00089   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0202   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -20.2     |\n",
      "|    neg_free_energy    | -0.0193   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 16000     |\n",
      "|    fps                | 354       |\n",
      "|    num. episodes      | 16        |\n",
      "|    num. updates       | 11000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.04      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0224    |\n",
      "|    prior_loss         | 0.00037   |\n",
      "|    theta              | 0.0162    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38.2      |\n",
      "|    action 1 (%)       | 61.8      |\n",
      "|    auc                | -5.03e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -58.2     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.77      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.5      |\n",
      "|    action 1 (%)       | 51.5      |\n",
      "|    avg_entropy        | 0.000851  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.013    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13       |\n",
      "|    neg_free_energy    | -0.0122   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 17000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 17        |\n",
      "|    num. updates       | 12000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.03      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0062   |\n",
      "|    prior_loss         | 0.000163  |\n",
      "|    theta              | 0.00579   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.09e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -62.7     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.2      |\n",
      "|    action 1 (%)       | 47.8      |\n",
      "|    avg_entropy        | 0.00039   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00952  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.52     |\n",
      "|    neg_free_energy    | -0.00913  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 18000     |\n",
      "|    fps                | 328       |\n",
      "|    num. episodes      | 18        |\n",
      "|    num. updates       | 13000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.33      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0252   |\n",
      "|    prior_loss         | 0.000297  |\n",
      "|    theta              | 9.34e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 56.5      |\n",
      "|    action 1 (%)       | 43.5      |\n",
      "|    auc                | -5.13e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -36.9     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.37      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.7      |\n",
      "|    action 1 (%)       | 48.3      |\n",
      "|    avg_entropy        | 0.000449  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0136   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.6     |\n",
      "|    neg_free_energy    | -0.0132   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 19000     |\n",
      "|    fps                | 345       |\n",
      "|    num. episodes      | 19        |\n",
      "|    num. updates       | 14000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.96      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0297    |\n",
      "|    prior_loss         | 0.000156  |\n",
      "|    theta              | 0.00528   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58        |\n",
      "|    action 1 (%)       | 42        |\n",
      "|    auc                | -5.17e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -44.1     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.6      |\n",
      "|    action 1 (%)       | 50.4      |\n",
      "|    avg_entropy        | 0.000403  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00763  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.63     |\n",
      "|    neg_free_energy    | -0.00722  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 20000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 20        |\n",
      "|    num. updates       | 15000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.31      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00981   |\n",
      "|    prior_loss         | 0.000161  |\n",
      "|    theta              | 0.00746   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 62.8      |\n",
      "|    action 1 (%)       | 37.2      |\n",
      "|    auc                | -5.25e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -78       |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.38      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.8      |\n",
      "|    action 1 (%)       | 49.2      |\n",
      "|    avg_entropy        | 0.000468  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00937  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.37     |\n",
      "|    neg_free_energy    | -0.0089   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 21000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 21        |\n",
      "|    num. updates       | 16000     |\n",
      "| train/                |           |\n",
      "|    loss               | 9.59      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0184   |\n",
      "|    prior_loss         | 0.000165  |\n",
      "|    theta              | 0.00165   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 48.4      |\n",
      "|    action 1 (%)       | 51.6      |\n",
      "|    auc                | -5.29e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -40.3     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 0.000451  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0102   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.2     |\n",
      "|    neg_free_energy    | -0.00971  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 22000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 22        |\n",
      "|    num. updates       | 17000     |\n",
      "| train/                |           |\n",
      "|    loss               | 18.3      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0204    |\n",
      "|    prior_loss         | 0.000137  |\n",
      "|    theta              | 0.00947   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 25.8      |\n",
      "|    action 1 (%)       | 74.2      |\n",
      "|    auc                | -5.43e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -146      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.41      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.4      |\n",
      "|    action 1 (%)       | 51.6      |\n",
      "|    avg_entropy        | 0.00116   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0314   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -31.4     |\n",
      "|    neg_free_energy    | -0.0303   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 23000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 23        |\n",
      "|    num. updates       | 18000     |\n",
      "| train/                |           |\n",
      "|    loss               | 38.5      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0391    |\n",
      "|    prior_loss         | 0.000131  |\n",
      "|    theta              | 0.0162    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 69        |\n",
      "|    action 1 (%)       | 31        |\n",
      "|    auc                | -5.59e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -157      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 0.000409  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00991  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.91     |\n",
      "|    neg_free_energy    | -0.0095   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 24000     |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 24        |\n",
      "|    num. updates       | 19000     |\n",
      "| train/                |           |\n",
      "|    loss               | 35.9      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0212    |\n",
      "|    prior_loss         | 9.33e-05  |\n",
      "|    theta              | 0.0167    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 28.5      |\n",
      "|    action 1 (%)       | 71.5      |\n",
      "|    auc                | -5.71e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -122      |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.54      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 0.000263  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0084   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.4      |\n",
      "|    neg_free_energy    | -0.00814  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 25000     |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 25        |\n",
      "|    num. updates       | 20000     |\n",
      "| train/                |           |\n",
      "|    loss               | 76.6      |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00706   |\n",
      "|    prior_loss         | 0.000199  |\n",
      "|    theta              | 0.007     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 24.7      |\n",
      "|    action 1 (%)       | 75.3      |\n",
      "|    auc                | -5.87e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -155      |\n",
      "|    fps                | 1.6e+03   |\n",
      "|    time               | 6.25      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.5      |\n",
      "|    action 1 (%)       | 47.5      |\n",
      "|    avg_entropy        | 0.000477  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0128   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.8     |\n",
      "|    neg_free_energy    | -0.0123   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 26000     |\n",
      "|    fps                | 372       |\n",
      "|    num. episodes      | 26        |\n",
      "|    num. updates       | 21000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.14e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00133   |\n",
      "|    prior_loss         | 0.000121  |\n",
      "|    theta              | 0.00619   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 28.9      |\n",
      "|    action 1 (%)       | 71.1      |\n",
      "|    auc                | -5.99e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -119      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.5      |\n",
      "|    action 1 (%)       | 51.5      |\n",
      "|    avg_entropy        | 0.00025   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00946  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.46     |\n",
      "|    neg_free_energy    | -0.00921  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 27000     |\n",
      "|    fps                | 372       |\n",
      "|    num. episodes      | 27        |\n",
      "|    num. updates       | 22000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.89e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0778   |\n",
      "|    prior_loss         | 0.000152  |\n",
      "|    theta              | -0.0112   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 32.6      |\n",
      "|    action 1 (%)       | 67.4      |\n",
      "|    auc                | -6.08e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -87.9     |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.29      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.8      |\n",
      "|    action 1 (%)       | 49.2      |\n",
      "|    avg_entropy        | 0.000396  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0113   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.3     |\n",
      "|    neg_free_energy    | -0.0109   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 28000     |\n",
      "|    fps                | 376       |\n",
      "|    num. episodes      | 28        |\n",
      "|    num. updates       | 23000     |\n",
      "| train/                |           |\n",
      "|    loss               | 158       |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0341    |\n",
      "|    prior_loss         | 0.000198  |\n",
      "|    theta              | 0.00936   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 25        |\n",
      "|    action 1 (%)       | 75        |\n",
      "|    auc                | -6.23e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -153      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.51      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 0.000191  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00578  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.78     |\n",
      "|    neg_free_energy    | -0.00559  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 29000     |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 29        |\n",
      "|    num. updates       | 24000     |\n",
      "| train/                |           |\n",
      "|    loss               | 132       |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.003    |\n",
      "|    prior_loss         | 8.31e-05  |\n",
      "|    theta              | 0.0106    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 28.5      |\n",
      "|    action 1 (%)       | 71.5      |\n",
      "|    auc                | -6.35e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -122      |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.31      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.4      |\n",
      "|    action 1 (%)       | 49.6      |\n",
      "|    avg_entropy        | 0.00019   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00744  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.44     |\n",
      "|    neg_free_energy    | -0.00724  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 30000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 30        |\n",
      "|    num. updates       | 25000     |\n",
      "| train/                |           |\n",
      "|    loss               | 191       |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00821   |\n",
      "|    prior_loss         | 3.76e-05  |\n",
      "|    theta              | 0.00864   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 28.7      |\n",
      "|    action 1 (%)       | 71.3      |\n",
      "|    auc                | -6.47e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -120      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.42      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 44.9      |\n",
      "|    action 1 (%)       | 55.1      |\n",
      "|    avg_entropy        | 0.000835  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0308   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -30.8     |\n",
      "|    neg_free_energy    | -0.03     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 31000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 31        |\n",
      "|    num. updates       | 26000     |\n",
      "| train/                |           |\n",
      "|    loss               | 390       |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0159    |\n",
      "|    prior_loss         | 0.000279  |\n",
      "|    theta              | -0.0122   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 29.1      |\n",
      "|    action 1 (%)       | 70.9      |\n",
      "|    auc                | -6.59e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -117      |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.28      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49        |\n",
      "|    action 1 (%)       | 51        |\n",
      "|    avg_entropy        | 0.000272  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0121   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.1     |\n",
      "|    neg_free_energy    | -0.0119   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 32000     |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 32        |\n",
      "|    num. updates       | 27000     |\n",
      "| train/                |           |\n",
      "|    loss               | 684       |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00476  |\n",
      "|    prior_loss         | 0.000104  |\n",
      "|    theta              | -0.00329  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 32.7      |\n",
      "|    action 1 (%)       | 67.3      |\n",
      "|    auc                | -6.67e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -86.9     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 0.000314  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0111   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.1     |\n",
      "|    neg_free_energy    | -0.0108   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 33000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 33        |\n",
      "|    num. updates       | 28000     |\n",
      "| train/                |           |\n",
      "|    loss               | 883       |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0161    |\n",
      "|    prior_loss         | 7.23e-05  |\n",
      "|    theta              | 0.00535   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 35.3      |\n",
      "|    action 1 (%)       | 64.7      |\n",
      "|    auc                | -6.74e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -68.1     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.3      |\n",
      "|    action 1 (%)       | 49.7      |\n",
      "|    avg_entropy        | 0.000123  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00739  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.39     |\n",
      "|    neg_free_energy    | -0.00727  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 34000     |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 34        |\n",
      "|    num. updates       | 29000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.44e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0287    |\n",
      "|    prior_loss         | 0.000164  |\n",
      "|    theta              | 0.0104    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 96.7      |\n",
      "|    action 1 (%)       | 3.3       |\n",
      "|    auc                | -7.11e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -369      |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.52      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 43.2      |\n",
      "|    action 1 (%)       | 56.8      |\n",
      "|    avg_entropy        | 0.000893  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0318   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -31.8     |\n",
      "|    neg_free_energy    | -0.0309   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 35000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 35        |\n",
      "|    num. updates       | 30000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.62e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.022     |\n",
      "|    prior_loss         | 0.000108  |\n",
      "|    theta              | 0.0131    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 35        |\n",
      "|    action 1 (%)       | 65        |\n",
      "|    auc                | -7.18e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -72.9     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 0.000125  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00833  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.33     |\n",
      "|    neg_free_energy    | -0.00821  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 36000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 36        |\n",
      "|    num. updates       | 31000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.06e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00521   |\n",
      "|    prior_loss         | 0.000156  |\n",
      "|    theta              | 0.00169   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 54.8     |\n",
      "|    action 1 (%)       | 45.2     |\n",
      "|    auc                | -7.2e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -11.3    |\n",
      "|    fps                | 1.58e+03 |\n",
      "|    time               | 6.32     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 51.3     |\n",
      "|    action 1 (%)       | 48.7     |\n",
      "|    avg_entropy        | 8.04e-05 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00493 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -4.93    |\n",
      "|    neg_free_energy    | -0.00485 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 37000    |\n",
      "|    fps                | 365      |\n",
      "|    num. episodes      | 37       |\n",
      "|    num. updates       | 32000    |\n",
      "| train/                |          |\n",
      "|    loss               | 8.82e+05 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.118   |\n",
      "|    prior_loss         | 0.000156 |\n",
      "|    theta              | -0.0373  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.3      |\n",
      "|    action 1 (%)       | 45.7      |\n",
      "|    auc                | -7.21e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -15.5     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.6      |\n",
      "|    action 1 (%)       | 47.4      |\n",
      "|    avg_entropy        | 0.000359  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0131   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.1     |\n",
      "|    neg_free_energy    | -0.0128   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 38000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 38        |\n",
      "|    num. updates       | 33000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.84e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00138  |\n",
      "|    prior_loss         | 0.00012   |\n",
      "|    theta              | -0.00693  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 35        |\n",
      "|    action 1 (%)       | 65        |\n",
      "|    auc                | -7.28e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -70.8     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49        |\n",
      "|    action 1 (%)       | 51        |\n",
      "|    avg_entropy        | 0.000166  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00695  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.95     |\n",
      "|    neg_free_energy    | -0.00678  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 39000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 39        |\n",
      "|    num. updates       | 34000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.14e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00512   |\n",
      "|    prior_loss         | 0.000203  |\n",
      "|    theta              | 0.0144    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38.3      |\n",
      "|    action 1 (%)       | 61.7      |\n",
      "|    auc                | -7.33e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -50.4     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 45.3      |\n",
      "|    action 1 (%)       | 54.7      |\n",
      "|    avg_entropy        | 0.000575  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0217   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -21.7     |\n",
      "|    neg_free_energy    | -0.0211   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 40000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 40        |\n",
      "|    num. updates       | 35000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.43e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00668  |\n",
      "|    prior_loss         | 0.000123  |\n",
      "|    theta              | -0.0215   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.5      |\n",
      "|    action 1 (%)       | 45.5      |\n",
      "|    auc                | -7.34e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -12.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.5      |\n",
      "|    action 1 (%)       | 49.5      |\n",
      "|    avg_entropy        | 7.9e-05   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00506  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.06     |\n",
      "|    neg_free_energy    | -0.00498  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 41000     |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 41        |\n",
      "|    num. updates       | 36000     |\n",
      "| train/                |           |\n",
      "|    loss               | 5.59e+03  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00639   |\n",
      "|    prior_loss         | 5.05e-05  |\n",
      "|    theta              | 0.00931   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 37.9     |\n",
      "|    action 1 (%)       | 62.1     |\n",
      "|    auc                | -7.4e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -51.4    |\n",
      "|    fps                | 1.55e+03 |\n",
      "|    time               | 6.44     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 49.1     |\n",
      "|    action 1 (%)       | 50.9     |\n",
      "|    avg_entropy        | 0.000114 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00524 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -5.24    |\n",
      "|    neg_free_energy    | -0.00512 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 42000    |\n",
      "|    fps                | 363      |\n",
      "|    num. episodes      | 42       |\n",
      "|    num. updates       | 37000    |\n",
      "| train/                |          |\n",
      "|    loss               | 2.94e+04 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0234   |\n",
      "|    prior_loss         | 7.42e-05 |\n",
      "|    theta              | 0.00797  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.2      |\n",
      "|    action 1 (%)       | 45.8      |\n",
      "|    auc                | -7.41e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -11.4     |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.31      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.8      |\n",
      "|    action 1 (%)       | 49.2      |\n",
      "|    avg_entropy        | 0.000127  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00568  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.68     |\n",
      "|    neg_free_energy    | -0.00555  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 43000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 43        |\n",
      "|    num. updates       | 38000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.01e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00952   |\n",
      "|    prior_loss         | 7.65e-05  |\n",
      "|    theta              | 0.00988   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38        |\n",
      "|    action 1 (%)       | 62        |\n",
      "|    auc                | -7.46e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -52.6     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.5      |\n",
      "|    action 1 (%)       | 51.5      |\n",
      "|    avg_entropy        | 0.00014   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00649  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.49     |\n",
      "|    neg_free_energy    | -0.00635  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 44000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 44        |\n",
      "|    num. updates       | 39000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.16e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.029     |\n",
      "|    prior_loss         | 5.24e-05  |\n",
      "|    theta              | 0.00727   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 38.9     |\n",
      "|    action 1 (%)       | 61.1     |\n",
      "|    auc                | -7.5e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -44.5    |\n",
      "|    fps                | 1.55e+03 |\n",
      "|    time               | 6.47     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 50.5     |\n",
      "|    action 1 (%)       | 49.5     |\n",
      "|    avg_entropy        | 0.000132 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00771 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -7.71    |\n",
      "|    neg_free_energy    | -0.00758 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 45000    |\n",
      "|    fps                | 362      |\n",
      "|    num. episodes      | 45       |\n",
      "|    num. updates       | 40000    |\n",
      "| train/                |          |\n",
      "|    loss               | 8.96e+03 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.00202 |\n",
      "|    prior_loss         | 4.09e-05 |\n",
      "|    theta              | 0.0069   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 39.4      |\n",
      "|    action 1 (%)       | 60.6      |\n",
      "|    auc                | -7.55e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -41       |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.1      |\n",
      "|    action 1 (%)       | 48.9      |\n",
      "|    avg_entropy        | 0.000176  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0113   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.3     |\n",
      "|    neg_free_energy    | -0.0111   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 46000     |\n",
      "|    fps                | 355       |\n",
      "|    num. episodes      | 46        |\n",
      "|    num. updates       | 41000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.63e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.011     |\n",
      "|    prior_loss         | 0.00019   |\n",
      "|    theta              | 0.0171    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 37.8     |\n",
      "|    action 1 (%)       | 62.2     |\n",
      "|    auc                | -7.6e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -51.6    |\n",
      "|    fps                | 1.55e+03 |\n",
      "|    time               | 6.46     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 47.5     |\n",
      "|    action 1 (%)       | 52.5     |\n",
      "|    avg_entropy        | 0.000149 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.0111  |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -11.1    |\n",
      "|    neg_free_energy    | -0.0109  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 47000    |\n",
      "|    fps                | 363      |\n",
      "|    num. episodes      | 47       |\n",
      "|    num. updates       | 42000    |\n",
      "| train/                |          |\n",
      "|    loss               | 2.74e+04 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0219   |\n",
      "|    prior_loss         | 7.64e-05 |\n",
      "|    theta              | 0.011    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.8      |\n",
      "|    action 1 (%)       | 62.2      |\n",
      "|    auc                | -7.65e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -51.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 8.78e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00721  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.21     |\n",
      "|    neg_free_energy    | -0.00712  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 48000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 48        |\n",
      "|    num. updates       | 43000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.93e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0427    |\n",
      "|    prior_loss         | 0.000123  |\n",
      "|    theta              | 0.0168    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.1      |\n",
      "|    action 1 (%)       | 45.9      |\n",
      "|    auc                | -7.66e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -10.5     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.3      |\n",
      "|    action 1 (%)       | 52.7      |\n",
      "|    avg_entropy        | 0.000243  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0147   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -14.7     |\n",
      "|    neg_free_energy    | -0.0145   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 49000     |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 49        |\n",
      "|    num. updates       | 44000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.56e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00218  |\n",
      "|    prior_loss         | 2.02e-05  |\n",
      "|    theta              | 0.00769   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38        |\n",
      "|    action 1 (%)       | 62        |\n",
      "|    auc                | -7.71e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -52.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.2      |\n",
      "|    action 1 (%)       | 50.8      |\n",
      "|    avg_entropy        | 5.83e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00359  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.59     |\n",
      "|    neg_free_energy    | -0.00353  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 50000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 50        |\n",
      "|    num. updates       | 45000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.43e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.000635  |\n",
      "|    prior_loss         | 2.35e-05  |\n",
      "|    theta              | 0.0139    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38        |\n",
      "|    action 1 (%)       | 62        |\n",
      "|    auc                | -7.76e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -52.6     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.4      |\n",
      "|    action 1 (%)       | 48.6      |\n",
      "|    avg_entropy        | 6.63e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00576  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.76     |\n",
      "|    neg_free_energy    | -0.0057   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 51000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 51        |\n",
      "|    num. updates       | 46000     |\n",
      "| train/                |           |\n",
      "|    loss               | 7.65e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0016    |\n",
      "|    prior_loss         | 0.000104  |\n",
      "|    theta              | -0.00407  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38        |\n",
      "|    action 1 (%)       | 62        |\n",
      "|    auc                | -7.82e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -52.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 45.8      |\n",
      "|    action 1 (%)       | 54.2      |\n",
      "|    avg_entropy        | 0.000221  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0201   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -20.1     |\n",
      "|    neg_free_energy    | -0.0198   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 52000     |\n",
      "|    fps                | 356       |\n",
      "|    num. episodes      | 52        |\n",
      "|    num. updates       | 47000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.65e+04  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0043   |\n",
      "|    prior_loss         | 2.97e-05  |\n",
      "|    theta              | -0.00999  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.8      |\n",
      "|    action 1 (%)       | 62.2      |\n",
      "|    auc                | -7.87e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -51.6     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.42      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.5      |\n",
      "|    action 1 (%)       | 50.5      |\n",
      "|    avg_entropy        | 8.34e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00825  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.25     |\n",
      "|    neg_free_energy    | -0.00817  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 53000     |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 53        |\n",
      "|    num. updates       | 48000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.45e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0164    |\n",
      "|    prior_loss         | 4.38e-05  |\n",
      "|    theta              | 0.00975   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.8      |\n",
      "|    action 1 (%)       | 62.2      |\n",
      "|    auc                | -7.92e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -51.6     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 0.000167  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0152   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -15.2     |\n",
      "|    neg_free_energy    | -0.015    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 54000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 54        |\n",
      "|    num. updates       | 49000     |\n",
      "| train/                |           |\n",
      "|    loss               | 9e+04     |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00667   |\n",
      "|    prior_loss         | 0.000145  |\n",
      "|    theta              | 0.00686   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37        |\n",
      "|    action 1 (%)       | 63        |\n",
      "|    auc                | -7.98e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -57.9     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 53.1      |\n",
      "|    action 1 (%)       | 46.9      |\n",
      "|    avg_entropy        | 0.000204  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0121   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.1     |\n",
      "|    neg_free_energy    | -0.0119   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 55000     |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 55        |\n",
      "|    num. updates       | 50000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.02e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0145    |\n",
      "|    prior_loss         | 2.08e-05  |\n",
      "|    theta              | 0.0225    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.8      |\n",
      "|    action 1 (%)       | 62.2      |\n",
      "|    auc                | -8.03e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -51.6     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.39      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.4      |\n",
      "|    action 1 (%)       | 48.6      |\n",
      "|    avg_entropy        | 0.000122  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0136   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.6     |\n",
      "|    neg_free_energy    | -0.0135   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 56000     |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 56        |\n",
      "|    num. updates       | 51000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.41e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00731  |\n",
      "|    prior_loss         | 7.62e-05  |\n",
      "|    theta              | -0.0106   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.8      |\n",
      "|    action 1 (%)       | 62.2      |\n",
      "|    auc                | -8.08e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -51.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.7      |\n",
      "|    action 1 (%)       | 51.3      |\n",
      "|    avg_entropy        | 0.000119  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0105   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.5     |\n",
      "|    neg_free_energy    | -0.0104   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 57000     |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 57        |\n",
      "|    num. updates       | 52000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.18e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00539   |\n",
      "|    prior_loss         | 7.05e-05  |\n",
      "|    theta              | 0.00654   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37        |\n",
      "|    action 1 (%)       | 63        |\n",
      "|    auc                | -8.14e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -57.1     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.36      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 45.1      |\n",
      "|    action 1 (%)       | 54.9      |\n",
      "|    avg_entropy        | 0.000155  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0128   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.8     |\n",
      "|    neg_free_energy    | -0.0126   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 58000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 58        |\n",
      "|    num. updates       | 53000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.04e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0152    |\n",
      "|    prior_loss         | 0.000139  |\n",
      "|    theta              | 0.00659   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38.2      |\n",
      "|    action 1 (%)       | 61.8      |\n",
      "|    auc                | -8.19e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -50       |\n",
      "|    fps                | 1.6e+03   |\n",
      "|    time               | 6.27      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.3      |\n",
      "|    action 1 (%)       | 50.7      |\n",
      "|    avg_entropy        | 0.0001    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00435  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -4.35     |\n",
      "|    neg_free_energy    | -0.00425  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 59000     |\n",
      "|    fps                | 373       |\n",
      "|    num. episodes      | 59        |\n",
      "|    num. updates       | 54000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.71e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0033    |\n",
      "|    prior_loss         | 3.98e-05  |\n",
      "|    theta              | 0.00552   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.2      |\n",
      "|    action 1 (%)       | 62.8      |\n",
      "|    auc                | -8.24e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -55.9     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.6      |\n",
      "|    action 1 (%)       | 48.4      |\n",
      "|    avg_entropy        | 0.000254  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0146   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -14.6     |\n",
      "|    neg_free_energy    | -0.0144   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 60000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 60        |\n",
      "|    num. updates       | 55000     |\n",
      "| train/                |           |\n",
      "|    loss               | 9.07e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0159   |\n",
      "|    prior_loss         | 5.31e-05  |\n",
      "|    theta              | 0.00547   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 37       |\n",
      "|    action 1 (%)       | 63       |\n",
      "|    auc                | -8.3e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -57.1    |\n",
      "|    fps                | 1.57e+03 |\n",
      "|    time               | 6.39     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 47.5     |\n",
      "|    action 1 (%)       | 52.5     |\n",
      "|    avg_entropy        | 0.000137 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00897 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -8.97    |\n",
      "|    neg_free_energy    | -0.00883 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 61000    |\n",
      "|    fps                | 361      |\n",
      "|    num. episodes      | 61       |\n",
      "|    num. updates       | 56000    |\n",
      "| train/                |          |\n",
      "|    loss               | 1.64e+07 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.0114  |\n",
      "|    prior_loss         | 3.69e-05 |\n",
      "|    theta              | 0.00263  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.9      |\n",
      "|    action 1 (%)       | 63.1      |\n",
      "|    auc                | -8.36e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -56.6     |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.29      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.4      |\n",
      "|    action 1 (%)       | 50.6      |\n",
      "|    avg_entropy        | 9.04e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0126   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.6     |\n",
      "|    neg_free_energy    | -0.0125   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 62000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 62        |\n",
      "|    num. updates       | 57000     |\n",
      "| train/                |           |\n",
      "|    loss               | 5.42e+05  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00899   |\n",
      "|    prior_loss         | 1.96e-05  |\n",
      "|    theta              | 0.00633   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.8      |\n",
      "|    action 1 (%)       | 63.2      |\n",
      "|    auc                | -8.42e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -58.9     |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.29      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.5      |\n",
      "|    action 1 (%)       | 49.5      |\n",
      "|    avg_entropy        | 4.77e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00287  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -2.87     |\n",
      "|    neg_free_energy    | -0.00282  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 63000     |\n",
      "|    fps                | 371       |\n",
      "|    num. episodes      | 63        |\n",
      "|    num. updates       | 58000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.23e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00109   |\n",
      "|    prior_loss         | 0.000121  |\n",
      "|    theta              | 0.00888   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 39.1      |\n",
      "|    action 1 (%)       | 60.9      |\n",
      "|    auc                | -8.46e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -40.4     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.5      |\n",
      "|    action 1 (%)       | 51.5      |\n",
      "|    avg_entropy        | 7.53e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0069   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.9      |\n",
      "|    neg_free_energy    | -0.00683  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 64000     |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 64        |\n",
      "|    num. updates       | 59000     |\n",
      "| train/                |           |\n",
      "|    loss               | 5.1e+07   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0465   |\n",
      "|    prior_loss         | 9.15e-05  |\n",
      "|    theta              | -0.0248   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.1      |\n",
      "|    action 1 (%)       | 63.9      |\n",
      "|    auc                | -8.52e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -62.2     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.4       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    avg_entropy        | 0.000102  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0126   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.6     |\n",
      "|    neg_free_energy    | -0.0125   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 65000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 65        |\n",
      "|    num. updates       | 60000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.28e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0268    |\n",
      "|    prior_loss         | 3.36e-05  |\n",
      "|    theta              | 0.0185    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36        |\n",
      "|    action 1 (%)       | 64        |\n",
      "|    auc                | -8.58e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -63.1     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.9      |\n",
      "|    action 1 (%)       | 50.1      |\n",
      "|    avg_entropy        | 0.000131  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00667  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.67     |\n",
      "|    neg_free_energy    | -0.00654  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 66000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 66        |\n",
      "|    num. updates       | 61000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.15e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.000637 |\n",
      "|    prior_loss         | 7.23e-05  |\n",
      "|    theta              | 0.0081    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.8      |\n",
      "|    action 1 (%)       | 63.2      |\n",
      "|    auc                | -8.64e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -58.9     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.36      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.3      |\n",
      "|    action 1 (%)       | 51.7      |\n",
      "|    avg_entropy        | 5.88e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00741  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.41     |\n",
      "|    neg_free_energy    | -0.00735  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 67000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 67        |\n",
      "|    num. updates       | 62000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.26e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.022     |\n",
      "|    prior_loss         | 2.95e-05  |\n",
      "|    theta              | 0.0109    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 36.9     |\n",
      "|    action 1 (%)       | 63.1     |\n",
      "|    auc                | -8.7e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -56.6    |\n",
      "|    fps                | 1.54e+03 |\n",
      "|    time               | 6.48     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 48.3     |\n",
      "|    action 1 (%)       | 51.7     |\n",
      "|    avg_entropy        | 0.000118 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.0109  |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -10.9    |\n",
      "|    neg_free_energy    | -0.0107  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 68000    |\n",
      "|    fps                | 360      |\n",
      "|    num. episodes      | 68       |\n",
      "|    num. updates       | 63000    |\n",
      "| train/                |          |\n",
      "|    loss               | 1.79e+06 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.00501  |\n",
      "|    prior_loss         | 4.79e-05 |\n",
      "|    theta              | -0.0141  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.9      |\n",
      "|    action 1 (%)       | 63.1      |\n",
      "|    auc                | -8.75e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -56.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48        |\n",
      "|    action 1 (%)       | 52        |\n",
      "|    avg_entropy        | 4.07e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00701  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.01     |\n",
      "|    neg_free_energy    | -0.00697  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 69000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 69        |\n",
      "|    num. updates       | 64000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.66e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00586  |\n",
      "|    prior_loss         | 6.92e-05  |\n",
      "|    theta              | -0.000398 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37        |\n",
      "|    action 1 (%)       | 63        |\n",
      "|    auc                | -8.81e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -55       |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.6      |\n",
      "|    action 1 (%)       | 51.4      |\n",
      "|    avg_entropy        | 0.000115  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0134   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.4     |\n",
      "|    neg_free_energy    | -0.0132   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 70000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 70        |\n",
      "|    num. updates       | 65000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.91e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0254    |\n",
      "|    prior_loss         | 0.000115  |\n",
      "|    theta              | 0.00986   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37        |\n",
      "|    action 1 (%)       | 63        |\n",
      "|    auc                | -8.86e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -55       |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.38      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.5      |\n",
      "|    action 1 (%)       | 47.5      |\n",
      "|    avg_entropy        | 5.58e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00755  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.55     |\n",
      "|    neg_free_energy    | -0.0075   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 71000     |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 71        |\n",
      "|    num. updates       | 66000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.82e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00998   |\n",
      "|    prior_loss         | 7.97e-05  |\n",
      "|    theta              | 0.00178   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.9      |\n",
      "|    action 1 (%)       | 63.1      |\n",
      "|    auc                | -8.92e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -55.3     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 7e-05     |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00792  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.92     |\n",
      "|    neg_free_energy    | -0.00785  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 72000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 72        |\n",
      "|    num. updates       | 67000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.19e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.012     |\n",
      "|    prior_loss         | 1.51e-05  |\n",
      "|    theta              | -0.00156  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37        |\n",
      "|    action 1 (%)       | 63        |\n",
      "|    auc                | -8.97e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -55       |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.35      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 0.000253  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0159   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -15.9     |\n",
      "|    neg_free_energy    | -0.0156   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 73000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 73        |\n",
      "|    num. updates       | 68000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.25e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0132    |\n",
      "|    prior_loss         | 3.13e-05  |\n",
      "|    theta              | 0.00806   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.7      |\n",
      "|    action 1 (%)       | 63.3      |\n",
      "|    auc                | -9.03e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -58.8     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.6      |\n",
      "|    action 1 (%)       | 49.4      |\n",
      "|    avg_entropy        | 6.65e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00613  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.13     |\n",
      "|    neg_free_energy    | -0.00606  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 74000     |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 74        |\n",
      "|    num. updates       | 69000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.03e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00749   |\n",
      "|    prior_loss         | 5.28e-05  |\n",
      "|    theta              | 0.00385   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.8      |\n",
      "|    action 1 (%)       | 63.2      |\n",
      "|    auc                | -9.09e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -57.9     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.2      |\n",
      "|    action 1 (%)       | 51.8      |\n",
      "|    avg_entropy        | 0.000156  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.012    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12       |\n",
      "|    neg_free_energy    | -0.0119   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 75000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 75        |\n",
      "|    num. updates       | 70000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.97e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0197    |\n",
      "|    prior_loss         | 5.93e-05  |\n",
      "|    theta              | 0.011     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37        |\n",
      "|    action 1 (%)       | 63        |\n",
      "|    auc                | -9.15e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -55       |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.3      |\n",
      "|    action 1 (%)       | 49.7      |\n",
      "|    avg_entropy        | 7.09e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00578  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.78     |\n",
      "|    neg_free_energy    | -0.00571  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 76000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 76        |\n",
      "|    num. updates       | 71000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.83e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.012     |\n",
      "|    prior_loss         | 7.99e-05  |\n",
      "|    theta              | 0.00177   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.4      |\n",
      "|    action 1 (%)       | 63.6      |\n",
      "|    auc                | -9.21e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -60.1     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.4      |\n",
      "|    action 1 (%)       | 51.6      |\n",
      "|    avg_entropy        | 7.49e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00982  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.82     |\n",
      "|    neg_free_energy    | -0.00975  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 77000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 77        |\n",
      "|    num. updates       | 72000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.47e+06  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00149  |\n",
      "|    prior_loss         | 3.87e-05  |\n",
      "|    theta              | 0.00579   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 36.7      |\n",
      "|    action 1 (%)       | 63.3      |\n",
      "|    auc                | -9.26e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -56.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 46.3      |\n",
      "|    action 1 (%)       | 53.7      |\n",
      "|    avg_entropy        | 0.000154  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0148   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -14.8     |\n",
      "|    neg_free_energy    | -0.0146   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 78000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 78        |\n",
      "|    num. updates       | 73000     |\n",
      "| train/                |           |\n",
      "|    loss               | 8.4e+06   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00376   |\n",
      "|    prior_loss         | 2.29e-05  |\n",
      "|    theta              | 0.0112    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37        |\n",
      "|    action 1 (%)       | 63        |\n",
      "|    auc                | -9.32e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -55       |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 7.04e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00521  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.21     |\n",
      "|    neg_free_energy    | -0.00514  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 79000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 79        |\n",
      "|    num. updates       | 74000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.64e+08  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0312   |\n",
      "|    prior_loss         | 0.00019   |\n",
      "|    theta              | -0.000652 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.4      |\n",
      "|    action 1 (%)       | 62.6      |\n",
      "|    auc                | -9.37e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -49.9     |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.31      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 46.4      |\n",
      "|    action 1 (%)       | 53.6      |\n",
      "|    avg_entropy        | 0.000152  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0137   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.7     |\n",
      "|    neg_free_energy    | -0.0135   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 80000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 80        |\n",
      "|    num. updates       | 75000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.15e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.028     |\n",
      "|    prior_loss         | 2.07e-05  |\n",
      "|    theta              | 0.0012    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.3      |\n",
      "|    action 1 (%)       | 62.7      |\n",
      "|    auc                | -9.42e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -52.1     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.41      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.2      |\n",
      "|    action 1 (%)       | 50.8      |\n",
      "|    avg_entropy        | 0.000193  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0131   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.1     |\n",
      "|    neg_free_energy    | -0.0129   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 81000     |\n",
      "|    fps                | 370       |\n",
      "|    num. episodes      | 81        |\n",
      "|    num. updates       | 76000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.92e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00141  |\n",
      "|    prior_loss         | 5.79e-05  |\n",
      "|    theta              | 0.00466   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.7      |\n",
      "|    action 1 (%)       | 62.3      |\n",
      "|    auc                | -9.47e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -49.2     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.37      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.5      |\n",
      "|    action 1 (%)       | 51.5      |\n",
      "|    avg_entropy        | 0.000124  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0109   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.9     |\n",
      "|    neg_free_energy    | -0.0108   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 82000     |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 82        |\n",
      "|    num. updates       | 77000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.61e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0199    |\n",
      "|    prior_loss         | 7.16e-05  |\n",
      "|    theta              | 0.0119    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.3      |\n",
      "|    action 1 (%)       | 62.7      |\n",
      "|    auc                | -9.52e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -52       |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.34      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.5      |\n",
      "|    action 1 (%)       | 51.5      |\n",
      "|    avg_entropy        | 0.000153  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00821  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.21     |\n",
      "|    neg_free_energy    | -0.00805  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 83000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 83        |\n",
      "|    num. updates       | 78000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.23e+08  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0113    |\n",
      "|    prior_loss         | 4.3e-05   |\n",
      "|    theta              | 0.00591   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 37.5      |\n",
      "|    action 1 (%)       | 62.5      |\n",
      "|    auc                | -9.57e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -49.8     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.51      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 46.4      |\n",
      "|    action 1 (%)       | 53.6      |\n",
      "|    avg_entropy        | 0.000181  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0132   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.2     |\n",
      "|    neg_free_energy    | -0.013    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 84000     |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 84        |\n",
      "|    num. updates       | 79000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.76e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0159    |\n",
      "|    prior_loss         | 9.88e-05  |\n",
      "|    theta              | 0.00236   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 38.9      |\n",
      "|    action 1 (%)       | 61.1      |\n",
      "|    auc                | -9.61e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -42.1     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.8      |\n",
      "|    action 1 (%)       | 52.2      |\n",
      "|    avg_entropy        | 0.000207  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0125   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.5     |\n",
      "|    neg_free_energy    | -0.0123   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 85000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 85        |\n",
      "|    num. updates       | 80000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.43e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.019     |\n",
      "|    prior_loss         | 4.44e-05  |\n",
      "|    theta              | 0.0101    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 40.5      |\n",
      "|    action 1 (%)       | 59.5      |\n",
      "|    auc                | -9.65e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35       |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.28      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 44.6      |\n",
      "|    action 1 (%)       | 55.4      |\n",
      "|    avg_entropy        | 0.00028   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0176   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -17.6     |\n",
      "|    neg_free_energy    | -0.0173   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 86000     |\n",
      "|    fps                | 369       |\n",
      "|    num. episodes      | 86        |\n",
      "|    num. updates       | 81000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.42e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00697   |\n",
      "|    prior_loss         | 6.25e-05  |\n",
      "|    theta              | -0.00117  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 40.1      |\n",
      "|    action 1 (%)       | 59.9      |\n",
      "|    auc                | -9.69e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -37.4     |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.33      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.1      |\n",
      "|    action 1 (%)       | 52.9      |\n",
      "|    avg_entropy        | 0.000248  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0172   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -17.2     |\n",
      "|    neg_free_energy    | -0.0169   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 87000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 87        |\n",
      "|    num. updates       | 82000     |\n",
      "| train/                |           |\n",
      "|    loss               | 3.7e+07   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.000862 |\n",
      "|    prior_loss         | 3.25e-05  |\n",
      "|    theta              | 0.00433   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 41.1      |\n",
      "|    action 1 (%)       | 58.9      |\n",
      "|    auc                | -9.72e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -34.5     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.2      |\n",
      "|    action 1 (%)       | 51.8      |\n",
      "|    avg_entropy        | 0.000109  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0074   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.4      |\n",
      "|    neg_free_energy    | -0.00729  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 88000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 88        |\n",
      "|    num. updates       | 83000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.07e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0241    |\n",
      "|    prior_loss         | 3.12e-05  |\n",
      "|    theta              | 0.00577   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 40        |\n",
      "|    action 1 (%)       | 60        |\n",
      "|    auc                | -9.76e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -36.8     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.41      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 45.8      |\n",
      "|    action 1 (%)       | 54.2      |\n",
      "|    avg_entropy        | 0.000194  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0118   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.8     |\n",
      "|    neg_free_energy    | -0.0116   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 89000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 89        |\n",
      "|    num. updates       | 84000     |\n",
      "| train/                |           |\n",
      "|    loss               | 5.55e+07  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00726   |\n",
      "|    prior_loss         | 6.59e-05  |\n",
      "|    theta              | 0.00917   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 45        |\n",
      "|    action 1 (%)       | 55        |\n",
      "|    auc                | -9.77e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -16.4     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.5       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.3      |\n",
      "|    action 1 (%)       | 51.7      |\n",
      "|    avg_entropy        | 0.000126  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00891  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.91     |\n",
      "|    neg_free_energy    | -0.00878  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 90000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 90        |\n",
      "|    num. updates       | 85000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.77e+09  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0136   |\n",
      "|    prior_loss         | 4.07e-05  |\n",
      "|    theta              | 0.00957   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 43.3     |\n",
      "|    action 1 (%)       | 56.7     |\n",
      "|    auc                | -9.8e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -22.4    |\n",
      "|    fps                | 1.56e+03 |\n",
      "|    time               | 6.42     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 48.7     |\n",
      "|    action 1 (%)       | 51.3     |\n",
      "|    avg_entropy        | 6.75e-05 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00587 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -5.87    |\n",
      "|    neg_free_energy    | -0.0058  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 91000    |\n",
      "|    fps                | 365      |\n",
      "|    num. episodes      | 91       |\n",
      "|    num. updates       | 86000    |\n",
      "| train/                |          |\n",
      "|    loss               | 6.38e+07 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.00272  |\n",
      "|    prior_loss         | 0.000112 |\n",
      "|    theta              | 0.000158 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 45.3      |\n",
      "|    action 1 (%)       | 54.7      |\n",
      "|    auc                | -9.82e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.7     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 46        |\n",
      "|    action 1 (%)       | 54        |\n",
      "|    avg_entropy        | 0.000172  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0125   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.5     |\n",
      "|    neg_free_energy    | -0.0124   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 92000     |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 92        |\n",
      "|    num. updates       | 87000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.14e+08  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0163    |\n",
      "|    prior_loss         | 6.88e-05  |\n",
      "|    theta              | 0.00583   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 44.6      |\n",
      "|    action 1 (%)       | 55.4      |\n",
      "|    auc                | -9.84e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -18.7     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 72.8      |\n",
      "|    action 1 (%)       | 27.2      |\n",
      "|    avg_entropy        | 0.000277  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.201    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -201      |\n",
      "|    neg_free_energy    | -0.2      |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 93000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 93        |\n",
      "|    num. updates       | 88000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.17e+09  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0118   |\n",
      "|    prior_loss         | 0.000152  |\n",
      "|    theta              | -0.00507  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 44.1      |\n",
      "|    action 1 (%)       | 55.9      |\n",
      "|    auc                | -9.86e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.1     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 45.9      |\n",
      "|    action 1 (%)       | 54.1      |\n",
      "|    avg_entropy        | 0.000104  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00967  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.67     |\n",
      "|    neg_free_energy    | -0.00956  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 94000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 94        |\n",
      "|    num. updates       | 89000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.73e+08  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0201    |\n",
      "|    prior_loss         | 8.89e-05  |\n",
      "|    theta              | 0.0172    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 46        |\n",
      "|    action 1 (%)       | 54        |\n",
      "|    auc                | -9.87e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -19.4     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49        |\n",
      "|    action 1 (%)       | 51        |\n",
      "|    avg_entropy        | 7.71e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00378  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.78     |\n",
      "|    neg_free_energy    | -0.0037   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 95000     |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 95        |\n",
      "|    num. updates       | 90000     |\n",
      "| train/                |           |\n",
      "|    loss               | 2.59e+09  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00686  |\n",
      "|    prior_loss         | 8.37e-05  |\n",
      "|    theta              | -0.00149  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 44.4     |\n",
      "|    action 1 (%)       | 55.6     |\n",
      "|    auc                | -9.9e+03 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -22.4    |\n",
      "|    fps                | 1.61e+03 |\n",
      "|    time               | 6.23     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 46.6     |\n",
      "|    action 1 (%)       | 53.4     |\n",
      "|    avg_entropy        | 0.000173 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.0112  |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -11.2    |\n",
      "|    neg_free_energy    | -0.0111  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 96000    |\n",
      "|    fps                | 358      |\n",
      "|    num. episodes      | 96       |\n",
      "|    num. updates       | 91000    |\n",
      "| train/                |          |\n",
      "|    loss               | 2.93e+08 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0145   |\n",
      "|    prior_loss         | 0.000266 |\n",
      "|    theta              | 0.00494  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47        |\n",
      "|    action 1 (%)       | 53        |\n",
      "|    auc                | -9.91e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -15.9     |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.31      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47        |\n",
      "|    action 1 (%)       | 53        |\n",
      "|    avg_entropy        | 0.000162  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0088   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.8      |\n",
      "|    neg_free_energy    | -0.00864  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 97000     |\n",
      "|    fps                | 376       |\n",
      "|    num. episodes      | 97        |\n",
      "|    num. updates       | 92000     |\n",
      "| train/                |           |\n",
      "|    loss               | 7.32e+08  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0165   |\n",
      "|    prior_loss         | 0.000108  |\n",
      "|    theta              | -0.0117   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 45.1      |\n",
      "|    action 1 (%)       | 54.9      |\n",
      "|    auc                | -9.93e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.5     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.37      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.5      |\n",
      "|    action 1 (%)       | 52.5      |\n",
      "|    avg_entropy        | 0.00016   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00879  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.79     |\n",
      "|    neg_free_energy    | -0.00863  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 98000     |\n",
      "|    fps                | 369       |\n",
      "|    num. episodes      | 98        |\n",
      "|    num. updates       | 93000     |\n",
      "| train/                |           |\n",
      "|    loss               | 9.95e+08  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0119    |\n",
      "|    prior_loss         | 7.91e-05  |\n",
      "|    theta              | 0.00583   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 45        |\n",
      "|    action 1 (%)       | 55        |\n",
      "|    auc                | -9.95e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.1     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.5       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 46.1      |\n",
      "|    action 1 (%)       | 53.9      |\n",
      "|    avg_entropy        | 0.000209  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0113   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.3     |\n",
      "|    neg_free_energy    | -0.0111   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 99000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 99        |\n",
      "|    num. updates       | 94000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.37e+09  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0103   |\n",
      "|    prior_loss         | 5.37e-05  |\n",
      "|    theta              | 0.00501   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 45.2      |\n",
      "|    action 1 (%)       | 54.8      |\n",
      "|    auc                | -9.98e+03 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -24.6     |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.3       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47        |\n",
      "|    action 1 (%)       | 53        |\n",
      "|    avg_entropy        | 0.000213  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00875  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.75     |\n",
      "|    neg_free_energy    | -0.00854  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 100000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 100       |\n",
      "|    num. updates       | 95000     |\n",
      "| train/                |           |\n",
      "|    loss               | 1.65e+10  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.000916 |\n",
      "|    prior_loss         | 8.27e-05  |\n",
      "|    theta              | 0.00834   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 46.6     |\n",
      "|    action 1 (%)       | 53.4     |\n",
      "|    auc                | -1e+04   |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -17.2    |\n",
      "|    fps                | 1.55e+03 |\n",
      "|    time               | 6.46     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 52.1     |\n",
      "|    action 1 (%)       | 47.9     |\n",
      "|    avg_entropy        | 0.000243 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.0303  |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -30.3    |\n",
      "|    neg_free_energy    | -0.0301  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 101000   |\n",
      "|    fps                | 364      |\n",
      "|    num. episodes      | 101      |\n",
      "|    num. updates       | 96000    |\n",
      "| train/                |          |\n",
      "|    loss               | 1.64e+09 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.00177  |\n",
      "|    prior_loss         | 0.000211 |\n",
      "|    theta              | 0.00446  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 46       |\n",
      "|    action 1 (%)       | 54       |\n",
      "|    auc                | -1e+04   |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -18.1    |\n",
      "|    fps                | 1.57e+03 |\n",
      "|    time               | 6.39     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 46.4     |\n",
      "|    action 1 (%)       | 53.6     |\n",
      "|    avg_entropy        | 0.000288 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00934 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -9.34    |\n",
      "|    neg_free_energy    | -0.00905 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 102000   |\n",
      "|    fps                | 369      |\n",
      "|    num. episodes      | 102      |\n",
      "|    num. updates       | 97000    |\n",
      "| train/                |          |\n",
      "|    loss               | 3e+09    |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.0136  |\n",
      "|    prior_loss         | 5.57e-05 |\n",
      "|    theta              | 0.0114   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 46.6     |\n",
      "|    action 1 (%)       | 53.4     |\n",
      "|    auc                | -1e+04   |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -18.8    |\n",
      "|    fps                | 1.54e+03 |\n",
      "|    time               | 6.48     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 48.9     |\n",
      "|    action 1 (%)       | 51.1     |\n",
      "|    avg_entropy        | 0.000333 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.0117  |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -11.7    |\n",
      "|    neg_free_energy    | -0.0114  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 103000   |\n",
      "|    fps                | 359      |\n",
      "|    num. episodes      | 103      |\n",
      "|    num. updates       | 98000    |\n",
      "| train/                |          |\n",
      "|    loss               | 3.27e+09 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0187   |\n",
      "|    prior_loss         | 6.05e-05 |\n",
      "|    theta              | 0.00818  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47        |\n",
      "|    action 1 (%)       | 53        |\n",
      "|    auc                | -1.01e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -17.7     |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.3       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 45.2      |\n",
      "|    action 1 (%)       | 54.8      |\n",
      "|    avg_entropy        | 0.000289  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0133   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.3     |\n",
      "|    neg_free_energy    | -0.013    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 104000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 104       |\n",
      "|    num. updates       | 99000     |\n",
      "| train/                |           |\n",
      "|    loss               | 4.55e+09  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00864   |\n",
      "|    prior_loss         | 8.31e-05  |\n",
      "|    theta              | 0.0092    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 46.4      |\n",
      "|    action 1 (%)       | 53.6      |\n",
      "|    auc                | -1.01e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -19.2     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.9      |\n",
      "|    action 1 (%)       | 52.1      |\n",
      "|    avg_entropy        | 0.000248  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00332  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.32     |\n",
      "|    neg_free_energy    | -0.00308  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 105000    |\n",
      "|    fps                | 371       |\n",
      "|    num. episodes      | 105       |\n",
      "|    num. updates       | 100000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.94e+09  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0216    |\n",
      "|    prior_loss         | 4.61e-05  |\n",
      "|    theta              | 0.0102    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 46.3      |\n",
      "|    action 1 (%)       | 53.7      |\n",
      "|    auc                | -1.01e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -17.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.6      |\n",
      "|    action 1 (%)       | 50.4      |\n",
      "|    avg_entropy        | 0.000193  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0066   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.6      |\n",
      "|    neg_free_energy    | -0.00641  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 106000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 106       |\n",
      "|    num. updates       | 101000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.79e+10  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0162   |\n",
      "|    prior_loss         | 4.61e-05  |\n",
      "|    theta              | -0.00675  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 46.2      |\n",
      "|    action 1 (%)       | 53.8      |\n",
      "|    auc                | -1.01e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -17.5     |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.34      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.4      |\n",
      "|    action 1 (%)       | 51.6      |\n",
      "|    avg_entropy        | 0.000211  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00797  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.97     |\n",
      "|    neg_free_energy    | -0.00775  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 107000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 107       |\n",
      "|    num. updates       | 102000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.01e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00744   |\n",
      "|    prior_loss         | 7.36e-05  |\n",
      "|    theta              | 0.00023   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.8      |\n",
      "|    action 1 (%)       | 52.2      |\n",
      "|    auc                | -1.01e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -15.8     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.41      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 85.3      |\n",
      "|    action 1 (%)       | 14.7      |\n",
      "|    avg_entropy        | 0.000266  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.284    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -284      |\n",
      "|    neg_free_energy    | -0.284    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 108000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 108       |\n",
      "|    num. updates       | 103000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.47e+10  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0236    |\n",
      "|    prior_loss         | 5.44e-05  |\n",
      "|    theta              | 0.0105    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 46        |\n",
      "|    action 1 (%)       | 54        |\n",
      "|    auc                | -1.01e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -17.3     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.42      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.9      |\n",
      "|    action 1 (%)       | 51.1      |\n",
      "|    avg_entropy        | 0.000209  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00629  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.29     |\n",
      "|    neg_free_energy    | -0.00608  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 109000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 109       |\n",
      "|    num. updates       | 104000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.38e+10  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0116    |\n",
      "|    prior_loss         | 4.44e-05  |\n",
      "|    theta              | 0.01      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.2      |\n",
      "|    action 1 (%)       | 52.8      |\n",
      "|    auc                | -1.01e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -12.1     |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.31      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.2      |\n",
      "|    action 1 (%)       | 52.8      |\n",
      "|    avg_entropy        | 0.00027   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0112   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.2     |\n",
      "|    neg_free_energy    | -0.0109   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 110000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 110       |\n",
      "|    num. updates       | 105000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.01e+10  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0019   |\n",
      "|    prior_loss         | 3.93e-05  |\n",
      "|    theta              | 0.00518   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.1      |\n",
      "|    action 1 (%)       | 52.9      |\n",
      "|    auc                | -1.02e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -11.7     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    avg_entropy        | 0.000234  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00644  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.44     |\n",
      "|    neg_free_energy    | -0.00621  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 111000    |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 111       |\n",
      "|    num. updates       | 106000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.68e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00549   |\n",
      "|    prior_loss         | 0.000105  |\n",
      "|    theta              | 0.00305   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -1.02e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -12.9     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 44.9      |\n",
      "|    action 1 (%)       | 55.1      |\n",
      "|    avg_entropy        | 0.000292  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0128   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.8     |\n",
      "|    neg_free_energy    | -0.0125   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 112000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 112       |\n",
      "|    num. updates       | 107000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.15e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00893  |\n",
      "|    prior_loss         | 8.46e-05  |\n",
      "|    theta              | 0.0031    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 46.5      |\n",
      "|    action 1 (%)       | 53.5      |\n",
      "|    auc                | -1.02e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -12.9     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 46.2      |\n",
      "|    action 1 (%)       | 53.8      |\n",
      "|    avg_entropy        | 0.000252  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00768  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.68     |\n",
      "|    neg_free_energy    | -0.00742  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 113000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 113       |\n",
      "|    num. updates       | 108000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.13e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.031    |\n",
      "|    prior_loss         | 5.88e-05  |\n",
      "|    theta              | 0.00482   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 85        |\n",
      "|    action 1 (%)       | 15        |\n",
      "|    auc                | -1.05e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -284      |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.35      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.7      |\n",
      "|    action 1 (%)       | 51.3      |\n",
      "|    avg_entropy        | 0.00022   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00701  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.01     |\n",
      "|    neg_free_energy    | -0.00679  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 114000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 114       |\n",
      "|    num. updates       | 109000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.74e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00891   |\n",
      "|    prior_loss         | 3.11e-05  |\n",
      "|    theta              | 0.00577   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97.1      |\n",
      "|    action 1 (%)       | 2.9       |\n",
      "|    auc                | -1.08e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -372      |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.32      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 82.6      |\n",
      "|    action 1 (%)       | 17.4      |\n",
      "|    avg_entropy        | 0.00141   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.255    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -255      |\n",
      "|    neg_free_energy    | -0.253    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 115000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 115       |\n",
      "|    num. updates       | 110000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.89e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0291    |\n",
      "|    prior_loss         | 0.000117  |\n",
      "|    theta              | 0.0106    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97.1      |\n",
      "|    action 1 (%)       | 2.9       |\n",
      "|    auc                | -1.12e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -372      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 46.3      |\n",
      "|    action 1 (%)       | 53.7      |\n",
      "|    avg_entropy        | 0.000294  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0109   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.9     |\n",
      "|    neg_free_energy    | -0.0106   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 116000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 116       |\n",
      "|    num. updates       | 111000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.25e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00447  |\n",
      "|    prior_loss         | 3.25e-05  |\n",
      "|    theta              | -0.00864  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97.1      |\n",
      "|    action 1 (%)       | 2.9       |\n",
      "|    auc                | -1.16e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -372      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.42      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 71.7      |\n",
      "|    action 1 (%)       | 28.3      |\n",
      "|    avg_entropy        | 0.00306   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.167    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -167      |\n",
      "|    neg_free_energy    | -0.164    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 117000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 117       |\n",
      "|    num. updates       | 112000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.02e+11  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00837   |\n",
      "|    prior_loss         | 4.83e-05  |\n",
      "|    theta              | 0.0041    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 97.1     |\n",
      "|    action 1 (%)       | 2.9      |\n",
      "|    auc                | -1.2e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -372     |\n",
      "|    fps                | 1.56e+03 |\n",
      "|    time               | 6.43     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 88.1     |\n",
      "|    action 1 (%)       | 11.9     |\n",
      "|    avg_entropy        | 0.00774  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.295   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -295     |\n",
      "|    neg_free_energy    | -0.287   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 118000   |\n",
      "|    fps                | 356      |\n",
      "|    num. episodes      | 118      |\n",
      "|    num. updates       | 113000   |\n",
      "| train/                |          |\n",
      "|    loss               | 6.85e+11 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0109   |\n",
      "|    prior_loss         | 4.68e-05 |\n",
      "|    theta              | 0.0107   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 97.1      |\n",
      "|    action 1 (%)       | 2.9       |\n",
      "|    auc                | -1.23e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -372      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 70.4      |\n",
      "|    action 1 (%)       | 29.6      |\n",
      "|    avg_entropy        | 0.00998   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.172    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -172      |\n",
      "|    neg_free_energy    | -0.162    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 119000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 119       |\n",
      "|    num. updates       | 114000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.29e+12  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00213  |\n",
      "|    prior_loss         | 4.97e-05  |\n",
      "|    theta              | -0.00298  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 91.3      |\n",
      "|    action 1 (%)       | 8.7       |\n",
      "|    auc                | -1.27e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -331      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 67.4      |\n",
      "|    action 1 (%)       | 32.6      |\n",
      "|    avg_entropy        | 0.0127    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.148    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -148      |\n",
      "|    neg_free_energy    | -0.135    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 120000    |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 120       |\n",
      "|    num. updates       | 115000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.69e+12  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00371  |\n",
      "|    prior_loss         | 0.000153  |\n",
      "|    theta              | 0.018     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 96.6     |\n",
      "|    action 1 (%)       | 3.4      |\n",
      "|    auc                | -1.3e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -368     |\n",
      "|    fps                | 1.57e+03 |\n",
      "|    time               | 6.38     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 61.5     |\n",
      "|    action 1 (%)       | 38.5     |\n",
      "|    avg_entropy        | 0.00695  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.111   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -111     |\n",
      "|    neg_free_energy    | -0.105   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 121000   |\n",
      "|    fps                | 362      |\n",
      "|    num. episodes      | 121      |\n",
      "|    num. updates       | 116000   |\n",
      "| train/                |          |\n",
      "|    loss               | 1.19e+13 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.0564  |\n",
      "|    prior_loss         | 4.97e-05 |\n",
      "|    theta              | -0.0143  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 96.9      |\n",
      "|    action 1 (%)       | 3.1       |\n",
      "|    auc                | -1.34e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -370      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.1      |\n",
      "|    action 1 (%)       | 52.9      |\n",
      "|    avg_entropy        | 0.000264  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00678  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.78     |\n",
      "|    neg_free_energy    | -0.00651  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 122000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 122       |\n",
      "|    num. updates       | 117000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.4e+12   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00678   |\n",
      "|    prior_loss         | 6.61e-05  |\n",
      "|    theta              | 0.00468   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 96.9      |\n",
      "|    action 1 (%)       | 3.1       |\n",
      "|    auc                | -1.38e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -370      |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.27      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.5      |\n",
      "|    action 1 (%)       | 51.5      |\n",
      "|    avg_entropy        | 0.000311  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0106   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.6     |\n",
      "|    neg_free_energy    | -0.0103   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 123000    |\n",
      "|    fps                | 372       |\n",
      "|    num. episodes      | 123       |\n",
      "|    num. updates       | 118000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.19e+12  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00337   |\n",
      "|    prior_loss         | 5.42e-05  |\n",
      "|    theta              | 0.0102    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 96.9      |\n",
      "|    action 1 (%)       | 3.1       |\n",
      "|    auc                | -1.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -370      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 76.5      |\n",
      "|    action 1 (%)       | 23.5      |\n",
      "|    avg_entropy        | 0.0135    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.205    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -205      |\n",
      "|    neg_free_energy    | -0.192    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 124000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 124       |\n",
      "|    num. updates       | 119000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.1e+12   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0295   |\n",
      "|    prior_loss         | 0.000134  |\n",
      "|    theta              | -0.00626  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 92.6      |\n",
      "|    action 1 (%)       | 7.4       |\n",
      "|    auc                | -1.45e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -329      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    avg_entropy        | 0.000215  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00414  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -4.14     |\n",
      "|    neg_free_energy    | -0.00392  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 125000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 125       |\n",
      "|    num. updates       | 120000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.04e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0381   |\n",
      "|    prior_loss         | 4.61e-05  |\n",
      "|    theta              | -0.0123   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 92.6      |\n",
      "|    action 1 (%)       | 7.4       |\n",
      "|    auc                | -1.48e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -329      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.2      |\n",
      "|    action 1 (%)       | 52.8      |\n",
      "|    avg_entropy        | 0.000274  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00671  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.71     |\n",
      "|    neg_free_energy    | -0.00643  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 126000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 126       |\n",
      "|    num. updates       | 121000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.01e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0122    |\n",
      "|    prior_loss         | 2.66e-05  |\n",
      "|    theta              | 0.0124    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 92.6      |\n",
      "|    action 1 (%)       | 7.4       |\n",
      "|    auc                | -1.51e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -329      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.7      |\n",
      "|    action 1 (%)       | 51.3      |\n",
      "|    avg_entropy        | 0.000185  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00291  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -2.91     |\n",
      "|    neg_free_energy    | -0.00273  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 127000    |\n",
      "|    fps                | 369       |\n",
      "|    num. episodes      | 127       |\n",
      "|    num. updates       | 122000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.24e+12  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0243    |\n",
      "|    prior_loss         | 4.04e-05  |\n",
      "|    theta              | 0.00476   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 92.6      |\n",
      "|    action 1 (%)       | 7.4       |\n",
      "|    auc                | -1.55e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -329      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 77.8      |\n",
      "|    action 1 (%)       | 22.2      |\n",
      "|    avg_entropy        | 0.00801   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.212    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -212      |\n",
      "|    neg_free_energy    | -0.204    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 128000    |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 128       |\n",
      "|    num. updates       | 123000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.05e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0144    |\n",
      "|    prior_loss         | 4.51e-05  |\n",
      "|    theta              | 0.00895   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 92.6      |\n",
      "|    action 1 (%)       | 7.4       |\n",
      "|    auc                | -1.58e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -329      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 65.4      |\n",
      "|    action 1 (%)       | 34.6      |\n",
      "|    avg_entropy        | 0.00497   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.129    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -129      |\n",
      "|    neg_free_energy    | -0.124    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 129000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 129       |\n",
      "|    num. updates       | 124000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.35e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.000812 |\n",
      "|    prior_loss         | 3.04e-05  |\n",
      "|    theta              | -0.00205  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 90        |\n",
      "|    action 1 (%)       | 10        |\n",
      "|    auc                | -1.61e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -310      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.39      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 62.6      |\n",
      "|    action 1 (%)       | 37.4      |\n",
      "|    avg_entropy        | 0.00319   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0982   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -98.2     |\n",
      "|    neg_free_energy    | -0.095    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 130000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 130       |\n",
      "|    num. updates       | 125000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.43e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0207    |\n",
      "|    prior_loss         | 2.82e-05  |\n",
      "|    theta              | 0.0046    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 89.6      |\n",
      "|    action 1 (%)       | 10.4      |\n",
      "|    auc                | -1.64e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -307      |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.32      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 87.5      |\n",
      "|    action 1 (%)       | 12.5      |\n",
      "|    avg_entropy        | 0.0145    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.284    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -284      |\n",
      "|    neg_free_energy    | -0.27     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 131000    |\n",
      "|    fps                | 371       |\n",
      "|    num. episodes      | 131       |\n",
      "|    num. updates       | 126000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.94e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0504   |\n",
      "|    prior_loss         | 3.34e-05  |\n",
      "|    theta              | -0.0139   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 89.6      |\n",
      "|    action 1 (%)       | 10.4      |\n",
      "|    auc                | -1.67e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -307      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47        |\n",
      "|    action 1 (%)       | 53        |\n",
      "|    avg_entropy        | 0.000259  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00657  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.57     |\n",
      "|    neg_free_energy    | -0.00631  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 132000    |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 132       |\n",
      "|    num. updates       | 127000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.66e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0447    |\n",
      "|    prior_loss         | 7.05e-05  |\n",
      "|    theta              | 0.0127    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 89.6     |\n",
      "|    action 1 (%)       | 10.4     |\n",
      "|    auc                | -1.7e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -307     |\n",
      "|    fps                | 1.57e+03 |\n",
      "|    time               | 6.36     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 83       |\n",
      "|    action 1 (%)       | 17       |\n",
      "|    avg_entropy        | 0.00657  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.252   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -252     |\n",
      "|    neg_free_energy    | -0.245   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 133000   |\n",
      "|    fps                | 364      |\n",
      "|    num. episodes      | 133      |\n",
      "|    num. updates       | 128000   |\n",
      "| train/                |          |\n",
      "|    loss               | 5.29e+13 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.00431 |\n",
      "|    prior_loss         | 0.00021  |\n",
      "|    theta              | 0.00547  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 89.9      |\n",
      "|    action 1 (%)       | 10.1      |\n",
      "|    auc                | -1.73e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -310      |\n",
      "|    fps                | 1.6e+03   |\n",
      "|    time               | 6.23      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 88.4      |\n",
      "|    action 1 (%)       | 11.6      |\n",
      "|    avg_entropy        | 0.00938   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.285    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -285      |\n",
      "|    neg_free_energy    | -0.276    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 134000    |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 134       |\n",
      "|    num. updates       | 129000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.59e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0118    |\n",
      "|    prior_loss         | 3.29e-05  |\n",
      "|    theta              | 0.00281   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 87.6      |\n",
      "|    action 1 (%)       | 12.4      |\n",
      "|    auc                | -1.76e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -286      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48        |\n",
      "|    action 1 (%)       | 52        |\n",
      "|    avg_entropy        | 0.00032   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0104   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.4     |\n",
      "|    neg_free_energy    | -0.0101   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 135000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 135       |\n",
      "|    num. updates       | 130000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.46e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00769   |\n",
      "|    prior_loss         | 6.79e-05  |\n",
      "|    theta              | 0.00767   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 87.5      |\n",
      "|    action 1 (%)       | 12.5      |\n",
      "|    auc                | -1.79e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -285      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 78.2      |\n",
      "|    action 1 (%)       | 21.8      |\n",
      "|    avg_entropy        | 0.00781   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.209    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -209      |\n",
      "|    neg_free_energy    | -0.201    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 136000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 136       |\n",
      "|    num. updates       | 131000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.64e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00794   |\n",
      "|    prior_loss         | 2.22e-05  |\n",
      "|    theta              | 0.00516   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 87.5      |\n",
      "|    action 1 (%)       | 12.5      |\n",
      "|    auc                | -1.82e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -285      |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.31      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 74        |\n",
      "|    action 1 (%)       | 26        |\n",
      "|    avg_entropy        | 0.0053    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.178    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -178      |\n",
      "|    neg_free_energy    | -0.173    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 137000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 137       |\n",
      "|    num. updates       | 132000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.73e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0229   |\n",
      "|    prior_loss         | 0.000119  |\n",
      "|    theta              | -0.00819  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 87.2      |\n",
      "|    action 1 (%)       | 12.8      |\n",
      "|    auc                | -1.85e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -283      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 67        |\n",
      "|    action 1 (%)       | 33        |\n",
      "|    avg_entropy        | 0.00419   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.137    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -137      |\n",
      "|    neg_free_energy    | -0.133    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 138000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 138       |\n",
      "|    num. updates       | 133000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.69e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00635   |\n",
      "|    prior_loss         | 8.75e-05  |\n",
      "|    theta              | 0.0021    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 87.2      |\n",
      "|    action 1 (%)       | 12.8      |\n",
      "|    auc                | -1.87e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -283      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 61.4      |\n",
      "|    action 1 (%)       | 38.6      |\n",
      "|    avg_entropy        | 0.00278   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.103    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -103      |\n",
      "|    neg_free_energy    | -0.1      |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 139000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 139       |\n",
      "|    num. updates       | 134000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.02e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0171   |\n",
      "|    prior_loss         | 2.2e-05   |\n",
      "|    theta              | -0.00982  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 84.8     |\n",
      "|    action 1 (%)       | 15.2     |\n",
      "|    auc                | -1.9e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -255     |\n",
      "|    fps                | 1.58e+03 |\n",
      "|    time               | 6.34     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 52.1     |\n",
      "|    action 1 (%)       | 47.9     |\n",
      "|    avg_entropy        | 0.00179  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.04    |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -40      |\n",
      "|    neg_free_energy    | -0.0382  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 140000   |\n",
      "|    fps                | 363      |\n",
      "|    num. episodes      | 140      |\n",
      "|    num. updates       | 135000   |\n",
      "| train/                |          |\n",
      "|    loss               | 3.04e+14 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.0463  |\n",
      "|    prior_loss         | 3.6e-05  |\n",
      "|    theta              | 0.0047   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 84.8      |\n",
      "|    action 1 (%)       | 15.2      |\n",
      "|    auc                | -1.93e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -255      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 74.9      |\n",
      "|    action 1 (%)       | 25.1      |\n",
      "|    avg_entropy        | 0.00569   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.186    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -186      |\n",
      "|    neg_free_energy    | -0.18     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 141000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 141       |\n",
      "|    num. updates       | 136000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.68e+13  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0131   |\n",
      "|    prior_loss         | 3.65e-05  |\n",
      "|    theta              | 5.44e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 84.8      |\n",
      "|    action 1 (%)       | 15.2      |\n",
      "|    auc                | -1.95e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -255      |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.36      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.7      |\n",
      "|    action 1 (%)       | 52.3      |\n",
      "|    avg_entropy        | 0.000179  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00372  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.72     |\n",
      "|    neg_free_energy    | -0.00354  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 142000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 142       |\n",
      "|    num. updates       | 137000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.64e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0136   |\n",
      "|    prior_loss         | 2.08e-05  |\n",
      "|    theta              | 0.00263   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 84.8      |\n",
      "|    action 1 (%)       | 15.2      |\n",
      "|    auc                | -1.98e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -255      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.41      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 78.2      |\n",
      "|    action 1 (%)       | 21.8      |\n",
      "|    avg_entropy        | 0.00515   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.202    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -202      |\n",
      "|    neg_free_energy    | -0.196    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 143000    |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 143       |\n",
      "|    num. updates       | 138000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.42e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0221    |\n",
      "|    prior_loss         | 3.42e-05  |\n",
      "|    theta              | -0.00327  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 84.8     |\n",
      "|    action 1 (%)       | 15.2     |\n",
      "|    auc                | -2e+04   |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -255     |\n",
      "|    fps                | 1.54e+03 |\n",
      "|    time               | 6.47     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 71.8     |\n",
      "|    action 1 (%)       | 28.2     |\n",
      "|    avg_entropy        | 0.00487  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.16    |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -160     |\n",
      "|    neg_free_energy    | -0.155   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 144000   |\n",
      "|    fps                | 366      |\n",
      "|    num. episodes      | 144      |\n",
      "|    num. updates       | 139000   |\n",
      "| train/                |          |\n",
      "|    loss               | 2.23e+14 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.0105  |\n",
      "|    prior_loss         | 1.39e-05 |\n",
      "|    theta              | 0.00162  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 84.7      |\n",
      "|    action 1 (%)       | 15.3      |\n",
      "|    auc                | -2.03e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -254      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 53.7      |\n",
      "|    action 1 (%)       | 46.3      |\n",
      "|    avg_entropy        | 0.00104   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0445   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -44.5     |\n",
      "|    neg_free_energy    | -0.0434   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 145000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 145       |\n",
      "|    num. updates       | 140000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.65e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00307  |\n",
      "|    prior_loss         | 2.26e-05  |\n",
      "|    theta              | 0.0135    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 84.7      |\n",
      "|    action 1 (%)       | 15.3      |\n",
      "|    auc                | -2.05e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -254      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.5      |\n",
      "|    action 1 (%)       | 50.5      |\n",
      "|    avg_entropy        | 0.000652  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0278   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -27.8     |\n",
      "|    neg_free_energy    | -0.0272   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 146000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 146       |\n",
      "|    num. updates       | 141000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.18e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00714   |\n",
      "|    prior_loss         | 4.91e-05  |\n",
      "|    theta              | 0.0045    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 84.7      |\n",
      "|    action 1 (%)       | 15.3      |\n",
      "|    auc                | -2.08e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -254      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 68.9      |\n",
      "|    action 1 (%)       | 31.1      |\n",
      "|    avg_entropy        | 0.00338   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.137    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -137      |\n",
      "|    neg_free_energy    | -0.133    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 147000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 147       |\n",
      "|    num. updates       | 142000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.93e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0349    |\n",
      "|    prior_loss         | 4.56e-05  |\n",
      "|    theta              | 0.00148   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 84.7     |\n",
      "|    action 1 (%)       | 15.3     |\n",
      "|    auc                | -2.1e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -254     |\n",
      "|    fps                | 1.55e+03 |\n",
      "|    time               | 6.46     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 48       |\n",
      "|    action 1 (%)       | 52       |\n",
      "|    avg_entropy        | 0.00018  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00337 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -3.37    |\n",
      "|    neg_free_energy    | -0.00319 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 148000   |\n",
      "|    fps                | 362      |\n",
      "|    num. episodes      | 148      |\n",
      "|    num. updates       | 143000   |\n",
      "| train/                |          |\n",
      "|    loss               | 3.04e+14 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.0275  |\n",
      "|    prior_loss         | 0.000272 |\n",
      "|    theta              | -0.0105  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 84.7      |\n",
      "|    action 1 (%)       | 15.3      |\n",
      "|    auc                | -2.13e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -254      |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.34      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 71.2      |\n",
      "|    action 1 (%)       | 28.8      |\n",
      "|    avg_entropy        | 0.00371   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.153    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -153      |\n",
      "|    neg_free_energy    | -0.149    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 149000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 149       |\n",
      "|    num. updates       | 144000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.1e+14   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0187    |\n",
      "|    prior_loss         | 2.33e-05  |\n",
      "|    theta              | 0.00096   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 83.4      |\n",
      "|    action 1 (%)       | 16.6      |\n",
      "|    auc                | -2.15e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -242      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 72.3      |\n",
      "|    action 1 (%)       | 27.7      |\n",
      "|    avg_entropy        | 0.0047    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.163    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -163      |\n",
      "|    neg_free_energy    | -0.159    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 150000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 150       |\n",
      "|    num. updates       | 145000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.67e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00134  |\n",
      "|    prior_loss         | 2.45e-05  |\n",
      "|    theta              | 0.00316   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 83.4      |\n",
      "|    action 1 (%)       | 16.6      |\n",
      "|    auc                | -2.18e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -242      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 66        |\n",
      "|    action 1 (%)       | 34        |\n",
      "|    avg_entropy        | 0.0039    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.128    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -128      |\n",
      "|    neg_free_energy    | -0.124    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 151000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 151       |\n",
      "|    num. updates       | 146000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.89e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0143   |\n",
      "|    prior_loss         | 1.58e-05  |\n",
      "|    theta              | -0.000893 |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 83.4     |\n",
      "|    action 1 (%)       | 16.6     |\n",
      "|    auc                | -2.2e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -242     |\n",
      "|    fps                | 1.57e+03 |\n",
      "|    time               | 6.37     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 68       |\n",
      "|    action 1 (%)       | 32       |\n",
      "|    avg_entropy        | 0.0034   |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.133   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -133     |\n",
      "|    neg_free_energy    | -0.13    |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 152000   |\n",
      "|    fps                | 363      |\n",
      "|    num. episodes      | 152      |\n",
      "|    num. updates       | 147000   |\n",
      "| train/                |          |\n",
      "|    loss               | 5.55e+14 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.0228  |\n",
      "|    prior_loss         | 1.4e-05  |\n",
      "|    theta              | 0.00368  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 83.4      |\n",
      "|    action 1 (%)       | 16.6      |\n",
      "|    auc                | -2.23e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -242      |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.29      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 54        |\n",
      "|    action 1 (%)       | 46        |\n",
      "|    avg_entropy        | 0.00117   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0412   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -41.2     |\n",
      "|    neg_free_energy    | -0.0401   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 153000    |\n",
      "|    fps                | 372       |\n",
      "|    num. episodes      | 153       |\n",
      "|    num. updates       | 148000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.74e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0353   |\n",
      "|    prior_loss         | 4.17e-05  |\n",
      "|    theta              | -0.0131   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 83.4      |\n",
      "|    action 1 (%)       | 16.6      |\n",
      "|    auc                | -2.25e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -242      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 66.4      |\n",
      "|    action 1 (%)       | 33.6      |\n",
      "|    avg_entropy        | 0.0032    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.121    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -121      |\n",
      "|    neg_free_energy    | -0.118    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 154000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 154       |\n",
      "|    num. updates       | 149000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.65e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0538    |\n",
      "|    prior_loss         | 2.17e-05  |\n",
      "|    theta              | 0.021     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 82.5      |\n",
      "|    action 1 (%)       | 17.5      |\n",
      "|    auc                | -2.27e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -234      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 56.5      |\n",
      "|    action 1 (%)       | 43.5      |\n",
      "|    avg_entropy        | 0.00133   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0679   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -67.9     |\n",
      "|    neg_free_energy    | -0.0666   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 155000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 155       |\n",
      "|    num. updates       | 150000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.18e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.07      |\n",
      "|    prior_loss         | 1.8e-05   |\n",
      "|    theta              | 0.0284    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 82.5     |\n",
      "|    action 1 (%)       | 17.5     |\n",
      "|    auc                | -2.3e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -234     |\n",
      "|    fps                | 1.55e+03 |\n",
      "|    time               | 6.47     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 71.2     |\n",
      "|    action 1 (%)       | 28.8     |\n",
      "|    avg_entropy        | 0.00372  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.152   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -152     |\n",
      "|    neg_free_energy    | -0.148   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 156000   |\n",
      "|    fps                | 362      |\n",
      "|    num. episodes      | 156      |\n",
      "|    num. updates       | 151000   |\n",
      "| train/                |          |\n",
      "|    loss               | 9.47e+14 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.00959 |\n",
      "|    prior_loss         | 6.63e-05 |\n",
      "|    theta              | -0.00862 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 82.6      |\n",
      "|    action 1 (%)       | 17.4      |\n",
      "|    auc                | -2.32e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -234      |\n",
      "|    fps                | 1.6e+03   |\n",
      "|    time               | 6.26      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 61        |\n",
      "|    action 1 (%)       | 39        |\n",
      "|    avg_entropy        | 0.00177   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0798   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -79.8     |\n",
      "|    neg_free_energy    | -0.0781   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 157000    |\n",
      "|    fps                | 374       |\n",
      "|    num. episodes      | 157       |\n",
      "|    num. updates       | 152000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.8e+14   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0272    |\n",
      "|    prior_loss         | 6.72e-05  |\n",
      "|    theta              | 0.0159    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 82.5      |\n",
      "|    action 1 (%)       | 17.5      |\n",
      "|    auc                | -2.34e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -234      |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.33      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 66.2      |\n",
      "|    action 1 (%)       | 33.8      |\n",
      "|    avg_entropy        | 0.0028    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.113    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -113      |\n",
      "|    neg_free_energy    | -0.111    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 158000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 158       |\n",
      "|    num. updates       | 153000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.64e+14  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0169    |\n",
      "|    prior_loss         | 2.86e-05  |\n",
      "|    theta              | 0.00821   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 82.5      |\n",
      "|    action 1 (%)       | 17.5      |\n",
      "|    auc                | -2.37e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -234      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.42      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 67.5      |\n",
      "|    action 1 (%)       | 32.5      |\n",
      "|    avg_entropy        | 0.00309   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.123    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -123      |\n",
      "|    neg_free_energy    | -0.12     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 159000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 159       |\n",
      "|    num. updates       | 154000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.01e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0665    |\n",
      "|    prior_loss         | 2.23e-05  |\n",
      "|    theta              | 0.0255    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 81.5      |\n",
      "|    action 1 (%)       | 18.5      |\n",
      "|    auc                | -2.39e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -225      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 67.9      |\n",
      "|    action 1 (%)       | 32.1      |\n",
      "|    avg_entropy        | 0.00331   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.127    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -127      |\n",
      "|    neg_free_energy    | -0.124    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 160000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 160       |\n",
      "|    num. updates       | 155000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.27e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0265    |\n",
      "|    prior_loss         | 0.000276  |\n",
      "|    theta              | 0.00867   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 81.5      |\n",
      "|    action 1 (%)       | 18.5      |\n",
      "|    auc                | -2.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -225      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 55.4      |\n",
      "|    action 1 (%)       | 44.6      |\n",
      "|    avg_entropy        | 0.00147   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0571   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -57.1     |\n",
      "|    neg_free_energy    | -0.0557   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 161000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 161       |\n",
      "|    num. updates       | 156000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.74e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0483    |\n",
      "|    prior_loss         | 1.91e-05  |\n",
      "|    theta              | 0.0107    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 81.5      |\n",
      "|    action 1 (%)       | 18.5      |\n",
      "|    auc                | -2.43e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -225      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 64.5      |\n",
      "|    action 1 (%)       | 35.5      |\n",
      "|    avg_entropy        | 0.00277   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.108    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -108      |\n",
      "|    neg_free_energy    | -0.106    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 162000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 162       |\n",
      "|    num. updates       | 157000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.42e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0103   |\n",
      "|    prior_loss         | 9.76e-05  |\n",
      "|    theta              | 0.00813   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 81.5      |\n",
      "|    action 1 (%)       | 18.5      |\n",
      "|    auc                | -2.46e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -225      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.4       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 53.7      |\n",
      "|    action 1 (%)       | 46.3      |\n",
      "|    avg_entropy        | 0.000872  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0394   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -39.4     |\n",
      "|    neg_free_energy    | -0.0385   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 163000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 163       |\n",
      "|    num. updates       | 158000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.76e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0106    |\n",
      "|    prior_loss         | 0.000394  |\n",
      "|    theta              | 0.0199    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 81.5      |\n",
      "|    action 1 (%)       | 18.5      |\n",
      "|    auc                | -2.48e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -225      |\n",
      "|    fps                | 1.6e+03   |\n",
      "|    time               | 6.25      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 54.1      |\n",
      "|    action 1 (%)       | 45.9      |\n",
      "|    avg_entropy        | 0.00109   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0445   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -44.5     |\n",
      "|    neg_free_energy    | -0.0434   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 164000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 164       |\n",
      "|    num. updates       | 159000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.79e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00917   |\n",
      "|    prior_loss         | 2.27e-05  |\n",
      "|    theta              | 0.00987   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 80.4     |\n",
      "|    action 1 (%)       | 19.6     |\n",
      "|    auc                | -2.5e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -214     |\n",
      "|    fps                | 1.56e+03 |\n",
      "|    time               | 6.43     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 69.8     |\n",
      "|    action 1 (%)       | 30.2     |\n",
      "|    avg_entropy        | 0.00267  |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.135   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -135     |\n",
      "|    neg_free_energy    | -0.132   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 165000   |\n",
      "|    fps                | 360      |\n",
      "|    num. episodes      | 165      |\n",
      "|    num. updates       | 160000   |\n",
      "| train/                |          |\n",
      "|    loss               | 4.84e+15 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.00614  |\n",
      "|    prior_loss         | 4.64e-05 |\n",
      "|    theta              | 0.0202   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 80.4      |\n",
      "|    action 1 (%)       | 19.6      |\n",
      "|    auc                | -2.52e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -214      |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.38      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.6      |\n",
      "|    action 1 (%)       | 50.4      |\n",
      "|    avg_entropy        | 0.000339  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0105   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.5     |\n",
      "|    neg_free_energy    | -0.0101   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 166000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 166       |\n",
      "|    num. updates       | 161000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.06e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00548  |\n",
      "|    prior_loss         | 3.48e-05  |\n",
      "|    theta              | 0.0119    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 80.4      |\n",
      "|    action 1 (%)       | 19.6      |\n",
      "|    auc                | -2.54e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -214      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.42      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 61.6      |\n",
      "|    action 1 (%)       | 38.4      |\n",
      "|    avg_entropy        | 0.00228   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0948   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -94.8     |\n",
      "|    neg_free_energy    | -0.0926   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 167000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 167       |\n",
      "|    num. updates       | 162000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.08e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0129    |\n",
      "|    prior_loss         | 7.81e-05  |\n",
      "|    theta              | 0.0163    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 80.4      |\n",
      "|    action 1 (%)       | 19.6      |\n",
      "|    auc                | -2.57e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -214      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.49      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.1      |\n",
      "|    action 1 (%)       | 48.9      |\n",
      "|    avg_entropy        | 0.000329  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0168   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -16.8     |\n",
      "|    neg_free_energy    | -0.0164   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 168000    |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 168       |\n",
      "|    num. updates       | 163000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.81e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0325    |\n",
      "|    prior_loss         | 9.89e-05  |\n",
      "|    theta              | 0.00698   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 80.4      |\n",
      "|    action 1 (%)       | 19.6      |\n",
      "|    auc                | -2.59e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -214      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 69.6      |\n",
      "|    action 1 (%)       | 30.4      |\n",
      "|    avg_entropy        | 0.00304   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.129    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -129      |\n",
      "|    neg_free_energy    | -0.126    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 169000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 169       |\n",
      "|    num. updates       | 164000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.12e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0324    |\n",
      "|    prior_loss         | 2.56e-05  |\n",
      "|    theta              | 0.0102    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 79        |\n",
      "|    action 1 (%)       | 21        |\n",
      "|    auc                | -2.61e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -201      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 66.2      |\n",
      "|    action 1 (%)       | 33.8      |\n",
      "|    avg_entropy        | 0.00304   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.113    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -113      |\n",
      "|    neg_free_energy    | -0.11     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 170000    |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 170       |\n",
      "|    num. updates       | 165000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.86e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0107    |\n",
      "|    prior_loss         | 7.58e-05  |\n",
      "|    theta              | 0.0053    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 79        |\n",
      "|    action 1 (%)       | 21        |\n",
      "|    auc                | -2.63e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -201      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 59.1      |\n",
      "|    action 1 (%)       | 40.9      |\n",
      "|    avg_entropy        | 0.00177   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0669   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -66.9     |\n",
      "|    neg_free_energy    | -0.0651   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 171000    |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 171       |\n",
      "|    num. updates       | 166000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.44e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0254    |\n",
      "|    prior_loss         | 3.28e-05  |\n",
      "|    theta              | 0.0151    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 79        |\n",
      "|    action 1 (%)       | 21        |\n",
      "|    auc                | -2.65e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -201      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 63.4      |\n",
      "|    action 1 (%)       | 36.6      |\n",
      "|    avg_entropy        | 0.00235   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.093    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -93       |\n",
      "|    neg_free_energy    | -0.0907   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 172000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 172       |\n",
      "|    num. updates       | 167000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.04e+15  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00861   |\n",
      "|    prior_loss         | 6.39e-05  |\n",
      "|    theta              | 0.0147    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 79        |\n",
      "|    action 1 (%)       | 21        |\n",
      "|    auc                | -2.67e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -201      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 66.6      |\n",
      "|    action 1 (%)       | 33.4      |\n",
      "|    avg_entropy        | 0.00287   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.109    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -109      |\n",
      "|    neg_free_energy    | -0.106    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 173000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 173       |\n",
      "|    num. updates       | 168000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.85e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0127    |\n",
      "|    prior_loss         | 3.48e-05  |\n",
      "|    theta              | 0.0179    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 79        |\n",
      "|    action 1 (%)       | 21        |\n",
      "|    auc                | -2.69e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -201      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.4       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 70.3      |\n",
      "|    action 1 (%)       | 29.7      |\n",
      "|    avg_entropy        | 0.00387   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.135    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -135      |\n",
      "|    neg_free_energy    | -0.132    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 174000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 174       |\n",
      "|    num. updates       | 169000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.13e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0183    |\n",
      "|    prior_loss         | 3.83e-05  |\n",
      "|    theta              | 0.0133    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 78.9      |\n",
      "|    action 1 (%)       | 21.1      |\n",
      "|    auc                | -2.71e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -200      |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.38      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 64.7      |\n",
      "|    action 1 (%)       | 35.3      |\n",
      "|    avg_entropy        | 0.00279   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0977   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -97.7     |\n",
      "|    neg_free_energy    | -0.0949   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 175000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 175       |\n",
      "|    num. updates       | 170000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.03e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0173   |\n",
      "|    prior_loss         | 2.93e-05  |\n",
      "|    theta              | 0.00545   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 78.9      |\n",
      "|    action 1 (%)       | 21.1      |\n",
      "|    auc                | -2.73e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -200      |\n",
      "|    fps                | 1.6e+03   |\n",
      "|    time               | 6.24      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 56.2      |\n",
      "|    action 1 (%)       | 43.8      |\n",
      "|    avg_entropy        | 0.00127   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0543   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -54.3     |\n",
      "|    neg_free_energy    | -0.053    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 176000    |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 176       |\n",
      "|    num. updates       | 171000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.34e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.016    |\n",
      "|    prior_loss         | 4.52e-05  |\n",
      "|    theta              | 0.0177    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 78.9      |\n",
      "|    action 1 (%)       | 21.1      |\n",
      "|    auc                | -2.75e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -200      |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.36      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 67.2      |\n",
      "|    action 1 (%)       | 32.8      |\n",
      "|    avg_entropy        | 0.00289   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.109    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -109      |\n",
      "|    neg_free_energy    | -0.106    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 177000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 177       |\n",
      "|    num. updates       | 172000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.01e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0551    |\n",
      "|    prior_loss         | 9.07e-05  |\n",
      "|    theta              | 0.0253    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 78.9      |\n",
      "|    action 1 (%)       | 21.1      |\n",
      "|    auc                | -2.77e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -200      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.39      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 62.5      |\n",
      "|    action 1 (%)       | 37.5      |\n",
      "|    avg_entropy        | 0.00218   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0785   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -78.5     |\n",
      "|    neg_free_energy    | -0.0764   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 178000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 178       |\n",
      "|    num. updates       | 173000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.03e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.000478 |\n",
      "|    prior_loss         | 2.42e-05  |\n",
      "|    theta              | 0.0124    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 78.9      |\n",
      "|    action 1 (%)       | 21.1      |\n",
      "|    auc                | -2.79e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -200      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 53.6      |\n",
      "|    action 1 (%)       | 46.4      |\n",
      "|    avg_entropy        | 0.000805  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0293   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -29.3     |\n",
      "|    neg_free_energy    | -0.0285   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 179000    |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 179       |\n",
      "|    num. updates       | 174000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.56e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0315    |\n",
      "|    prior_loss         | 4.97e-05  |\n",
      "|    theta              | 0.00965   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 76.5     |\n",
      "|    action 1 (%)       | 23.5     |\n",
      "|    auc                | -2.8e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -179     |\n",
      "|    fps                | 1.54e+03 |\n",
      "|    time               | 6.48     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 55.3     |\n",
      "|    action 1 (%)       | 44.7     |\n",
      "|    avg_entropy        | 0.000805 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.0354  |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -35.4    |\n",
      "|    neg_free_energy    | -0.0346  |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 180000   |\n",
      "|    fps                | 362      |\n",
      "|    num. episodes      | 180      |\n",
      "|    num. updates       | 175000   |\n",
      "| train/                |          |\n",
      "|    loss               | 3.44e+16 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.045    |\n",
      "|    prior_loss         | 2.36e-05 |\n",
      "|    theta              | 0.0172   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 76.5      |\n",
      "|    action 1 (%)       | 23.5      |\n",
      "|    auc                | -2.82e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -179      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 62.9      |\n",
      "|    action 1 (%)       | 37.1      |\n",
      "|    avg_entropy        | 0.00308   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0885   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -88.5     |\n",
      "|    neg_free_energy    | -0.0854   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 181000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 181       |\n",
      "|    num. updates       | 176000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.64e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0306    |\n",
      "|    prior_loss         | 3.4e-05   |\n",
      "|    theta              | 0.0142    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 76.5      |\n",
      "|    action 1 (%)       | 23.5      |\n",
      "|    auc                | -2.84e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -179      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 56.9      |\n",
      "|    action 1 (%)       | 43.1      |\n",
      "|    avg_entropy        | 0.00129   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0422   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -42.2     |\n",
      "|    neg_free_energy    | -0.0409   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 182000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 182       |\n",
      "|    num. updates       | 177000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.03e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0034   |\n",
      "|    prior_loss         | 4.97e-05  |\n",
      "|    theta              | 0.00442   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 76.5      |\n",
      "|    action 1 (%)       | 23.5      |\n",
      "|    auc                | -2.86e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -179      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 70.1      |\n",
      "|    action 1 (%)       | 29.9      |\n",
      "|    avg_entropy        | 0.00448   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.128    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -128      |\n",
      "|    neg_free_energy    | -0.123    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 183000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 183       |\n",
      "|    num. updates       | 178000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.62e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00153   |\n",
      "|    prior_loss         | 8.3e-05   |\n",
      "|    theta              | 0.0161    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 76.5      |\n",
      "|    action 1 (%)       | 23.5      |\n",
      "|    auc                | -2.88e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -179      |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.32      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.8      |\n",
      "|    action 1 (%)       | 50.2      |\n",
      "|    avg_entropy        | 0.000357  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.013    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13       |\n",
      "|    neg_free_energy    | -0.0127   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 184000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 184       |\n",
      "|    num. updates       | 179000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.45e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0265    |\n",
      "|    prior_loss         | 3.67e-05  |\n",
      "|    theta              | 0.0222    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 75.3      |\n",
      "|    action 1 (%)       | 24.7      |\n",
      "|    auc                | -2.89e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -168      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 63        |\n",
      "|    action 1 (%)       | 37        |\n",
      "|    avg_entropy        | 0.00328   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0873   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -87.3     |\n",
      "|    neg_free_energy    | -0.084    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 185000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 185       |\n",
      "|    num. updates       | 180000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.37e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0124    |\n",
      "|    prior_loss         | 4.41e-05  |\n",
      "|    theta              | 0.027     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 75.3      |\n",
      "|    action 1 (%)       | 24.7      |\n",
      "|    auc                | -2.91e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -168      |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 58.8      |\n",
      "|    action 1 (%)       | 41.2      |\n",
      "|    avg_entropy        | 0.00221   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0559   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -55.9     |\n",
      "|    neg_free_energy    | -0.0537   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 186000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 186       |\n",
      "|    num. updates       | 181000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.71e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0266    |\n",
      "|    prior_loss         | 0.000106  |\n",
      "|    theta              | 0.0185    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 69.7      |\n",
      "|    action 1 (%)       | 30.3      |\n",
      "|    auc                | -2.92e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -130      |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.4       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 60.1      |\n",
      "|    action 1 (%)       | 39.9      |\n",
      "|    avg_entropy        | 0.00269   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0647   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -64.7     |\n",
      "|    neg_free_energy    | -0.0621   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 187000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 187       |\n",
      "|    num. updates       | 182000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.16e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0171    |\n",
      "|    prior_loss         | 0.000148  |\n",
      "|    theta              | 0.0172    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 51.1      |\n",
      "|    action 1 (%)       | 48.9      |\n",
      "|    auc                | -2.92e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -18       |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.43      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 53.6      |\n",
      "|    action 1 (%)       | 46.4      |\n",
      "|    avg_entropy        | 0.000933  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0302   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -30.2     |\n",
      "|    neg_free_energy    | -0.0292   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 188000    |\n",
      "|    fps                | 367       |\n",
      "|    num. episodes      | 188       |\n",
      "|    num. updates       | 183000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.37e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0213    |\n",
      "|    prior_loss         | 3.89e-05  |\n",
      "|    theta              | 0.0041    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 69.7      |\n",
      "|    action 1 (%)       | 30.3      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -130      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 60.5      |\n",
      "|    action 1 (%)       | 39.5      |\n",
      "|    avg_entropy        | 0.00323   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0719   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -71.9     |\n",
      "|    neg_free_energy    | -0.0687   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 189000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 189       |\n",
      "|    num. updates       | 184000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.18e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00732   |\n",
      "|    prior_loss         | 4.88e-05  |\n",
      "|    theta              | 0.0163    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 4.18      |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.36      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 55.4      |\n",
      "|    action 1 (%)       | 44.6      |\n",
      "|    avg_entropy        | 0.0017    |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0415   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -41.5     |\n",
      "|    neg_free_energy    | -0.0398   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 190000    |\n",
      "|    fps                | 373       |\n",
      "|    num. episodes      | 190       |\n",
      "|    num. updates       | 185000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.81e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0151   |\n",
      "|    prior_loss         | 7.15e-05  |\n",
      "|    theta              | 0.0119    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 4.18      |\n",
      "|    fps                | 1.59e+03  |\n",
      "|    time               | 6.27      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 57.8      |\n",
      "|    action 1 (%)       | 42.2      |\n",
      "|    avg_entropy        | 0.00168   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0398   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -39.8     |\n",
      "|    neg_free_energy    | -0.0381   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 191000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 191       |\n",
      "|    num. updates       | 186000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.28e+16  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00168  |\n",
      "|    prior_loss         | 3.09e-05  |\n",
      "|    theta              | 0.00357   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 4.18      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.1      |\n",
      "|    action 1 (%)       | 47.9      |\n",
      "|    avg_entropy        | 0.000954  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0223   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -22.3     |\n",
      "|    neg_free_energy    | -0.0213   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 192000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 192       |\n",
      "|    num. updates       | 187000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.27e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00168  |\n",
      "|    prior_loss         | 6.19e-05  |\n",
      "|    theta              | 0.00484   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 4.16      |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.36      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.4      |\n",
      "|    action 1 (%)       | 50.6      |\n",
      "|    avg_entropy        | 0.00016   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00587  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.87     |\n",
      "|    neg_free_energy    | -0.00571  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 193000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 193       |\n",
      "|    num. updates       | 188000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.33e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0129   |\n",
      "|    prior_loss         | 2.86e-05  |\n",
      "|    theta              | 0.00683   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 4.16      |\n",
      "|    fps                | 1.6e+03   |\n",
      "|    time               | 6.26      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.4      |\n",
      "|    action 1 (%)       | 48.6      |\n",
      "|    avg_entropy        | 0.000944  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0164   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -16.4     |\n",
      "|    neg_free_energy    | -0.0154   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 194000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 194       |\n",
      "|    num. updates       | 189000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.24e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00157  |\n",
      "|    prior_loss         | 0.000113  |\n",
      "|    theta              | 0.0136    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 49.7      |\n",
      "|    action 1 (%)       | 50.3      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -8.89     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.3      |\n",
      "|    action 1 (%)       | 49.7      |\n",
      "|    avg_entropy        | 0.000579  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0131   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.1     |\n",
      "|    neg_free_energy    | -0.0126   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 195000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 195       |\n",
      "|    num. updates       | 190000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.71e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0123    |\n",
      "|    prior_loss         | 5.48e-05  |\n",
      "|    theta              | 0.0139    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 51        |\n",
      "|    action 1 (%)       | 49        |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -15.8     |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.32      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 0.000673  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0133   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.3     |\n",
      "|    neg_free_energy    | -0.0127   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 196000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 196       |\n",
      "|    num. updates       | 191000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.3e+17   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00262  |\n",
      "|    prior_loss         | 9.23e-05  |\n",
      "|    theta              | 0.00708   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 51.2      |\n",
      "|    action 1 (%)       | 48.8      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -17.3     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.45      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.7      |\n",
      "|    action 1 (%)       | 52.3      |\n",
      "|    avg_entropy        | 0.000576  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0105   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.5     |\n",
      "|    neg_free_energy    | -0.00993  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 197000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 197       |\n",
      "|    num. updates       | 192000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.47e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0167    |\n",
      "|    prior_loss         | 0.000119  |\n",
      "|    theta              | 0.00647   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 4.13      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52        |\n",
      "|    action 1 (%)       | 48        |\n",
      "|    avg_entropy        | 0.00117   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.02     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -20       |\n",
      "|    neg_free_energy    | -0.0188   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 198000    |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 198       |\n",
      "|    num. updates       | 193000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.78e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0448    |\n",
      "|    prior_loss         | 0.00011   |\n",
      "|    theta              | 0.0175    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 4.13      |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.33      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.4      |\n",
      "|    action 1 (%)       | 47.6      |\n",
      "|    avg_entropy        | 0.00141   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0205   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -20.5     |\n",
      "|    neg_free_energy    | -0.0191   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 199000    |\n",
      "|    fps                | 371       |\n",
      "|    num. episodes      | 199       |\n",
      "|    num. updates       | 194000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.98e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00317  |\n",
      "|    prior_loss         | 5.38e-05  |\n",
      "|    theta              | -0.000884 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.5      |\n",
      "|    action 1 (%)       | 41.5      |\n",
      "|    auc                | -2.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -53.6     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.4       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52        |\n",
      "|    action 1 (%)       | 48        |\n",
      "|    avg_entropy        | 0.00111   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.017    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -17       |\n",
      "|    neg_free_energy    | -0.0159   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 200000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 200       |\n",
      "|    num. updates       | 195000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.49e+17  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0336    |\n",
      "|    prior_loss         | 6.53e-05  |\n",
      "|    theta              | 0.0103    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "def evaluate_model(env_class, max_steps, num_episodes, model=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model over several episodes and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained RL model to be evaluated.\n",
    "    - env_class: Environment class to create new instances of the evaluation environment.\n",
    "    - max_steps: Maximum number of steps per episode.\n",
    "    - num_episodes: Number of episodes to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - avg_observations: Average observations at each step.\n",
    "    - all_observations: List of observations for all episodes.\n",
    "    \"\"\"\n",
    "    all_observations = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        eval_env = TimeLimit(env_class(), max_steps)\n",
    "        done = False\n",
    "        obs, _ = eval_env.reset()\n",
    "        episode_observations = []\n",
    "        while not done:\n",
    "            if model is not None:\n",
    "                action = model.evaluation_policy(obs)\n",
    "            else:\n",
    "                action = eval_env.action_space.sample()\n",
    "            obs, rewards, term, trunc, info = eval_env.step(action)\n",
    "            done = term or trunc\n",
    "            episode_observations.append(info['n_cells'])\n",
    "        \n",
    "        all_observations.append(episode_observations)\n",
    "    \n",
    "    # Compute the average observations\n",
    "    max_len = max(len(obs) for obs in all_observations)\n",
    "    avg_observations = np.zeros(max_len)\n",
    "    counts = np.zeros(max_len)\n",
    "    \n",
    "    for obs in all_observations:\n",
    "        for i, val in enumerate(obs):\n",
    "            avg_observations[i] += val[-1]\n",
    "            counts[i] += 1\n",
    "    \n",
    "    avg_observations /= counts\n",
    "\n",
    "    return avg_observations, all_observations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_observations(avg_observations, all_observations, unif_obs=None, all_unif_obs=None):\n",
    "    \"\"\"\n",
    "    Plot the average observations and individual episode tracks.\n",
    "\n",
    "    Parameters:\n",
    "    - avg_observations: Average observations at each step.\n",
    "    - all_observations: List of observations for all episodes.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    x_axis = np.linspace(0, 0.15*len(avg_observations), len(avg_observations))\n",
    "    \n",
    "    # Plot individual episode tracks with lower alpha\n",
    "    for obs in all_observations:\n",
    "        plt.plot(x_axis, obs, alpha=0.05, linewidth=0.5, color='black')\n",
    "\n",
    "    if unif_obs is not None:\n",
    "        for obs in all_unif_obs:\n",
    "            plt.plot(x_axis, obs, alpha=0.05, linewidth=0.5, color='red')\n",
    "    \n",
    "    # Plot average observations\n",
    "    plt.plot(x_axis, avg_observations, label='trained policy', linewidth=3, color='black')\n",
    "    if unif_obs is not None:\n",
    "        plt.plot(x_axis, unif_obs, label='random policy', linewidth=3, color='red')\n",
    "    \n",
    "    plt.xlabel('Time (hours)')\n",
    "    plt.ylabel('Total cells (n_cells)')\n",
    "    plt.title('Model Evaluation: Average Observations and Individual Episode Tracks')\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_observations, all_observations = evaluate_model(CellEnv, 1000, 10, model)\n",
    "unif_obs, all_unif_obs = evaluate_model(CellEnv, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_observations(avg_observations, all_observations, unif_obs, all_unif_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -3.54e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.46e+03  |\n",
      "|    time               | 6.86      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 2.2       |\n",
      "|    action 1 (%)       | 97.8      |\n",
      "|    avg_entropy        | 4.47e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.363    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -363      |\n",
      "|    neg_free_energy    | -0.363    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 1000      |\n",
      "|    fps                | 969       |\n",
      "|    num. episodes      | 251       |\n",
      "|    num. updates       | 240000    |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0.0257    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -3.54e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.47e+03  |\n",
      "|    time               | 6.79      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.4      |\n",
      "|    action 1 (%)       | 51.6      |\n",
      "|    avg_entropy        | 0.000115  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0116   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.6     |\n",
      "|    neg_free_energy    | -0.0115   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 2000      |\n",
      "|    fps                | 963       |\n",
      "|    num. episodes      | 252       |\n",
      "|    num. updates       | 240000    |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0.0257    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -3.54e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.76      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 37.8      |\n",
      "|    action 1 (%)       | 62.2      |\n",
      "|    avg_entropy        | 0.000101  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0911   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -91.1     |\n",
      "|    neg_free_energy    | -0.091    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 3000      |\n",
      "|    fps                | 973       |\n",
      "|    num. episodes      | 253       |\n",
      "|    num. updates       | 240000    |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0.0257    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -3.55e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 21.8      |\n",
      "|    action 1 (%)       | 78.2      |\n",
      "|    avg_entropy        | 8.96e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.212    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -212      |\n",
      "|    neg_free_energy    | -0.212    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 4000      |\n",
      "|    fps                | 978       |\n",
      "|    num. episodes      | 254       |\n",
      "|    num. updates       | 240000    |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0.0257    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 56.3      |\n",
      "|    action 1 (%)       | 43.7      |\n",
      "|    auc                | -3.55e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -27.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 0.000109  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00652  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.52     |\n",
      "|    neg_free_energy    | -0.00641  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 5000      |\n",
      "|    fps                | 978       |\n",
      "|    num. episodes      | 255       |\n",
      "|    num. updates       | 240000    |\n",
      "| train/                |           |\n",
      "|    lr                 | 0.0035    |\n",
      "|    theta              | 0.0257    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -3.55e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 41.6      |\n",
      "|    action 1 (%)       | 58.4      |\n",
      "|    avg_entropy        | 0.000136  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0681   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -68.1     |\n",
      "|    neg_free_energy    | -0.068    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 6000      |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 256       |\n",
      "|    num. updates       | 241000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.69e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.00433  |\n",
      "|    prior_loss         | 1.54e-05  |\n",
      "|    theta              | 0.0219    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.4      |\n",
      "|    action 1 (%)       | 44.6      |\n",
      "|    auc                | -3.55e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -23.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 38.9      |\n",
      "|    action 1 (%)       | 61.1      |\n",
      "|    avg_entropy        | 9.22e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0921   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -92.1     |\n",
      "|    neg_free_energy    | -0.092    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 7000      |\n",
      "|    fps                | 352       |\n",
      "|    num. episodes      | 257       |\n",
      "|    num. updates       | 242000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.17e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0161    |\n",
      "|    prior_loss         | 1.83e-05  |\n",
      "|    theta              | 0.0417    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.8      |\n",
      "|    action 1 (%)       | 45.2      |\n",
      "|    auc                | -3.56e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -21.5     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 16.3      |\n",
      "|    action 1 (%)       | 83.7      |\n",
      "|    avg_entropy        | 4.69e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.255    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -255      |\n",
      "|    neg_free_energy    | -0.255    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 8000      |\n",
      "|    fps                | 352       |\n",
      "|    num. episodes      | 258       |\n",
      "|    num. updates       | 243000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.4e+18   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0555    |\n",
      "|    prior_loss         | 0.0001    |\n",
      "|    theta              | 0.0527    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.8      |\n",
      "|    action 1 (%)       | 45.2      |\n",
      "|    auc                | -3.56e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -21.5     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.2      |\n",
      "|    action 1 (%)       | 48.8      |\n",
      "|    avg_entropy        | 4.99e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00523  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.23     |\n",
      "|    neg_free_energy    | -0.00518  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 9000      |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 259       |\n",
      "|    num. updates       | 244000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.81e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0757    |\n",
      "|    prior_loss         | 1.46e-05  |\n",
      "|    theta              | 0.0396    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 0.5      |\n",
      "|    action 1 (%)       | 99.5     |\n",
      "|    auc                | -3.6e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -377     |\n",
      "|    fps                | 1.49e+03 |\n",
      "|    time               | 6.7      |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 14.9     |\n",
      "|    action 1 (%)       | 85.1     |\n",
      "|    avg_entropy        | 3.27e-05 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.273   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -273     |\n",
      "|    neg_free_energy    | -0.273   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 10000    |\n",
      "|    fps                | 349      |\n",
      "|    num. episodes      | 260      |\n",
      "|    num. updates       | 245000   |\n",
      "| train/                |          |\n",
      "|    loss               | 2.44e+18 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | -0.00949 |\n",
      "|    prior_loss         | 1.58e-05 |\n",
      "|    theta              | 0.00372  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.63e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.2      |\n",
      "|    action 1 (%)       | 47.8      |\n",
      "|    avg_entropy        | 2.63e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00783  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.83     |\n",
      "|    neg_free_energy    | -0.00781  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 11000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 261       |\n",
      "|    num. updates       | 246000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.44e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0684    |\n",
      "|    prior_loss         | 5.34e-05  |\n",
      "|    theta              | 0.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.67e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.7       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 9         |\n",
      "|    action 1 (%)       | 91        |\n",
      "|    avg_entropy        | 4.59e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.31     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -310      |\n",
      "|    neg_free_energy    | -0.31     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 12000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 262       |\n",
      "|    num. updates       | 247000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.46e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0118    |\n",
      "|    prior_loss         | 2.88e-05  |\n",
      "|    theta              | 0.0226    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.7      |\n",
      "|    action 1 (%)       | 44.3      |\n",
      "|    auc                | -3.67e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -24.8     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50        |\n",
      "|    action 1 (%)       | 50        |\n",
      "|    avg_entropy        | 3.02e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0125   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.5     |\n",
      "|    neg_free_energy    | -0.0124   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 13000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 263       |\n",
      "|    num. updates       | 248000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.68e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0672    |\n",
      "|    prior_loss         | 2.53e-05  |\n",
      "|    theta              | 0.0442    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.7      |\n",
      "|    action 1 (%)       | 44.3      |\n",
      "|    auc                | -3.68e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -24.8     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 36.1      |\n",
      "|    action 1 (%)       | 63.9      |\n",
      "|    avg_entropy        | 1.35e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.104    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -104      |\n",
      "|    neg_free_energy    | -0.104    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 14000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 264       |\n",
      "|    num. updates       | 249000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.71e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0619    |\n",
      "|    prior_loss         | 5.11e-06  |\n",
      "|    theta              | 0.0487    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.71e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.9       |\n",
      "|    action 1 (%)       | 98.1      |\n",
      "|    avg_entropy        | 3.13e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.366    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -366      |\n",
      "|    neg_free_energy    | -0.366    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 15000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 265       |\n",
      "|    num. updates       | 250000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.12e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | -0.0443   |\n",
      "|    prior_loss         | 4.66e-05  |\n",
      "|    theta              | 0.0324    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.75e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.8       |\n",
      "|    action 1 (%)       | 99.2      |\n",
      "|    avg_entropy        | 3.21e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.374    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -374      |\n",
      "|    neg_free_energy    | -0.374    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 16000     |\n",
      "|    fps                | 347       |\n",
      "|    num. episodes      | 266       |\n",
      "|    num. updates       | 251000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.82e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.105     |\n",
      "|    prior_loss         | 1.16e-05  |\n",
      "|    theta              | 0.0693    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.79e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 16.6      |\n",
      "|    action 1 (%)       | 83.4      |\n",
      "|    avg_entropy        | 1.49e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.255    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -255      |\n",
      "|    neg_free_energy    | -0.255    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 17000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 267       |\n",
      "|    num. updates       | 252000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.72e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0255    |\n",
      "|    prior_loss         | 4.37e-05  |\n",
      "|    theta              | 0.0383    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.83e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.5      |\n",
      "|    action 1 (%)       | 48.5      |\n",
      "|    avg_entropy        | 4.89e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00335  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.35     |\n",
      "|    neg_free_energy    | -0.00335  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 18000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 268       |\n",
      "|    num. updates       | 253000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.4e+18   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0918    |\n",
      "|    prior_loss         | 0.000271  |\n",
      "|    theta              | 0.0525    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.86e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.5      |\n",
      "|    action 1 (%)       | 52.5      |\n",
      "|    avg_entropy        | 1.87e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0107   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -10.7     |\n",
      "|    neg_free_energy    | -0.0106   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 19000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 269       |\n",
      "|    num. updates       | 254000    |\n",
      "| train/                |           |\n",
      "|    loss               | 7.55e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.00798   |\n",
      "|    prior_loss         | 2.44e-05  |\n",
      "|    theta              | 0.0439    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 0.5      |\n",
      "|    action 1 (%)       | 99.5     |\n",
      "|    auc                | -3.9e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -377     |\n",
      "|    fps                | 1.49e+03 |\n",
      "|    time               | 6.73     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 50.7     |\n",
      "|    action 1 (%)       | 49.3     |\n",
      "|    avg_entropy        | 8.06e-06 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00647 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -6.47    |\n",
      "|    neg_free_energy    | -0.00646 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 20000    |\n",
      "|    fps                | 344      |\n",
      "|    num. episodes      | 270      |\n",
      "|    num. updates       | 255000   |\n",
      "| train/                |          |\n",
      "|    loss               | 7.95e+18 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0722   |\n",
      "|    prior_loss         | 6.01e-05 |\n",
      "|    theta              | 0.0796   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.94e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 2.7       |\n",
      "|    action 1 (%)       | 97.3      |\n",
      "|    avg_entropy        | 4.82e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.357    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -357      |\n",
      "|    neg_free_energy    | -0.357    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 21000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 271       |\n",
      "|    num. updates       | 256000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.24e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.107     |\n",
      "|    prior_loss         | 1.19e-05  |\n",
      "|    theta              | 0.0707    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -3.98e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 10.9      |\n",
      "|    action 1 (%)       | 89.1      |\n",
      "|    avg_entropy        | 2.63e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.289    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -289      |\n",
      "|    neg_free_energy    | -0.289    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 22000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 272       |\n",
      "|    num. updates       | 257000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.27e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0296    |\n",
      "|    prior_loss         | 4.56e-05  |\n",
      "|    theta              | 0.0649    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.02e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.74      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 32.6      |\n",
      "|    action 1 (%)       | 67.4      |\n",
      "|    avg_entropy        | 2.68e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.12     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -120      |\n",
      "|    neg_free_energy    | -0.119    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 23000     |\n",
      "|    fps                | 354       |\n",
      "|    num. episodes      | 273       |\n",
      "|    num. updates       | 258000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.22e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0927    |\n",
      "|    prior_loss         | 2.84e-05  |\n",
      "|    theta              | 0.0658    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.05e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 40.8      |\n",
      "|    action 1 (%)       | 59.2      |\n",
      "|    avg_entropy        | 1.54e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.09     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -90       |\n",
      "|    neg_free_energy    | -0.09     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 24000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 274       |\n",
      "|    num. updates       | 259000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.03e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0517    |\n",
      "|    prior_loss         | 2.39e-05  |\n",
      "|    theta              | 0.0635    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.09e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.7       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 16        |\n",
      "|    action 1 (%)       | 84        |\n",
      "|    avg_entropy        | 8.94e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.265    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -265      |\n",
      "|    neg_free_energy    | -0.265    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 25000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 275       |\n",
      "|    num. updates       | 260000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.03e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0819    |\n",
      "|    prior_loss         | 1.43e-05  |\n",
      "|    theta              | 0.047     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.13e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.7       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 22.4      |\n",
      "|    action 1 (%)       | 77.6      |\n",
      "|    avg_entropy        | 7.07e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.209    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -209      |\n",
      "|    neg_free_energy    | -0.209    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 26000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 276       |\n",
      "|    num. updates       | 261000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.31e+18  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.106     |\n",
      "|    prior_loss         | 1.29e-05  |\n",
      "|    theta              | 0.0682    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.17e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.7       |\n",
      "|    action 1 (%)       | 99.3      |\n",
      "|    avg_entropy        | 1.02e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.375    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -375      |\n",
      "|    neg_free_energy    | -0.375    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 27000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 277       |\n",
      "|    num. updates       | 262000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.52e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0843    |\n",
      "|    prior_loss         | 2.24e-05  |\n",
      "|    theta              | 0.0757    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 0.5      |\n",
      "|    action 1 (%)       | 99.5     |\n",
      "|    auc                | -4.2e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -377     |\n",
      "|    fps                | 1.49e+03 |\n",
      "|    time               | 6.72     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 49.2     |\n",
      "|    action 1 (%)       | 50.8     |\n",
      "|    avg_entropy        | 6.22e-06 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00876 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -8.76    |\n",
      "|    neg_free_energy    | -0.00875 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 28000    |\n",
      "|    fps                | 351      |\n",
      "|    num. episodes      | 278      |\n",
      "|    num. updates       | 263000   |\n",
      "| train/                |          |\n",
      "|    loss               | 1.72e+19 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0733   |\n",
      "|    prior_loss         | 2.22e-05 |\n",
      "|    theta              | 0.0705   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.24e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 15.7      |\n",
      "|    action 1 (%)       | 84.3      |\n",
      "|    avg_entropy        | 5.54e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.273    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -273      |\n",
      "|    neg_free_energy    | -0.273    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 29000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 279       |\n",
      "|    num. updates       | 264000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.12e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0785    |\n",
      "|    prior_loss         | 1.27e-05  |\n",
      "|    theta              | 0.0785    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.28e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.9      |\n",
      "|    action 1 (%)       | 48.1      |\n",
      "|    avg_entropy        | 4.02e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00748  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.48     |\n",
      "|    neg_free_energy    | -0.00748  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 30000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 280       |\n",
      "|    num. updates       | 265000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.47e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0413    |\n",
      "|    prior_loss         | 1.02e-05  |\n",
      "|    theta              | 0.072     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.32e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.74      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 5.09e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00897  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.97     |\n",
      "|    neg_free_energy    | -0.00897  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 31000     |\n",
      "|    fps                | 347       |\n",
      "|    num. episodes      | 281       |\n",
      "|    num. updates       | 266000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.41e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0572    |\n",
      "|    prior_loss         | 4.92e-05  |\n",
      "|    theta              | 0.0775    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.35e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.7       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.2      |\n",
      "|    action 1 (%)       | 47.8      |\n",
      "|    avg_entropy        | 4.15e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00923  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.23     |\n",
      "|    neg_free_energy    | -0.00923  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 32000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 282       |\n",
      "|    num. updates       | 267000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.25e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0692    |\n",
      "|    prior_loss         | 6.75e-06  |\n",
      "|    theta              | 0.0925    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.39e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.7      |\n",
      "|    action 1 (%)       | 50.3      |\n",
      "|    avg_entropy        | 3.57e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00648  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.48     |\n",
      "|    neg_free_energy    | -0.00648  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 33000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 283       |\n",
      "|    num. updates       | 268000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.36e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0435    |\n",
      "|    prior_loss         | 3.36e-05  |\n",
      "|    theta              | 0.0636    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.43e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 33.4      |\n",
      "|    action 1 (%)       | 66.6      |\n",
      "|    avg_entropy        | 2.58e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.134    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -134      |\n",
      "|    neg_free_energy    | -0.134    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 34000     |\n",
      "|    fps                | 347       |\n",
      "|    num. episodes      | 284       |\n",
      "|    num. updates       | 269000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.73e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0168    |\n",
      "|    prior_loss         | 7.77e-06  |\n",
      "|    theta              | 0.0663    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.47e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.74      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.6      |\n",
      "|    action 1 (%)       | 51.4      |\n",
      "|    avg_entropy        | 4e-06     |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0123   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.3     |\n",
      "|    neg_free_energy    | -0.0123   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 35000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 285       |\n",
      "|    num. updates       | 270000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.16e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.101     |\n",
      "|    prior_loss         | 1.4e-05   |\n",
      "|    theta              | 0.0938    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.51e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 3.4       |\n",
      "|    action 1 (%)       | 96.6      |\n",
      "|    avg_entropy        | 9.17e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.355    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -355      |\n",
      "|    neg_free_energy    | -0.355    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 36000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 286       |\n",
      "|    num. updates       | 271000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.24e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0581    |\n",
      "|    prior_loss         | 1.17e-05  |\n",
      "|    theta              | 0.0829    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.54e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.7       |\n",
      "|    action 1 (%)       | 98.3      |\n",
      "|    avg_entropy        | 1.34e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.366    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -366      |\n",
      "|    neg_free_energy    | -0.366    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 37000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 287       |\n",
      "|    num. updates       | 272000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.04e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0446    |\n",
      "|    prior_loss         | 1.46e-05  |\n",
      "|    theta              | 0.0796    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.58e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 13.8      |\n",
      "|    action 1 (%)       | 86.2      |\n",
      "|    avg_entropy        | 1.34e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.276    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -276      |\n",
      "|    neg_free_energy    | -0.276    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 38000     |\n",
      "|    fps                | 352       |\n",
      "|    num. episodes      | 288       |\n",
      "|    num. updates       | 273000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.68e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.116     |\n",
      "|    prior_loss         | 5.45e-06  |\n",
      "|    theta              | 0.0955    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.62e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.74      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.9       |\n",
      "|    action 1 (%)       | 98.1      |\n",
      "|    avg_entropy        | 3.61e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.365    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -365      |\n",
      "|    neg_free_energy    | -0.365    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 39000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 289       |\n",
      "|    num. updates       | 274000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.19e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.174     |\n",
      "|    prior_loss         | 1.49e-05  |\n",
      "|    theta              | 0.105     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.66e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.4       |\n",
      "|    action 1 (%)       | 98.6      |\n",
      "|    avg_entropy        | 5.26e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.37     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -370      |\n",
      "|    neg_free_energy    | -0.37     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 40000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 290       |\n",
      "|    num. updates       | 275000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.84e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.116     |\n",
      "|    prior_loss         | 2.02e-05  |\n",
      "|    theta              | 0.0921    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.69e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.4      |\n",
      "|    action 1 (%)       | 49.6      |\n",
      "|    avg_entropy        | 5.51e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00848  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.48     |\n",
      "|    neg_free_energy    | -0.00848  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 41000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 291       |\n",
      "|    num. updates       | 276000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.22e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.13      |\n",
      "|    prior_loss         | 1.17e-05  |\n",
      "|    theta              | 0.104     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.73e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 25.9      |\n",
      "|    action 1 (%)       | 74.1      |\n",
      "|    avg_entropy        | 3.4e-06   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.183    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -183      |\n",
      "|    neg_free_energy    | -0.183    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 42000     |\n",
      "|    fps                | 347       |\n",
      "|    num. episodes      | 292       |\n",
      "|    num. updates       | 277000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.66e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.114     |\n",
      "|    prior_loss         | 1.07e-05  |\n",
      "|    theta              | 0.102     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.77e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.6       |\n",
      "|    action 1 (%)       | 99.4      |\n",
      "|    avg_entropy        | 3.45e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.377    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -377      |\n",
      "|    neg_free_energy    | -0.377    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 43000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 293       |\n",
      "|    num. updates       | 278000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.78e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.12      |\n",
      "|    prior_loss         | 7.7e-06   |\n",
      "|    theta              | 0.0916    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.81e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 43.2      |\n",
      "|    action 1 (%)       | 56.8      |\n",
      "|    avg_entropy        | 5.63e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0658   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -65.8     |\n",
      "|    neg_free_energy    | -0.0658   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 44000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 294       |\n",
      "|    num. updates       | 279000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.82e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0713    |\n",
      "|    prior_loss         | 6e-06     |\n",
      "|    theta              | 0.102     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.84e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.76      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.9      |\n",
      "|    action 1 (%)       | 49.1      |\n",
      "|    avg_entropy        | 7.07e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00683  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.83     |\n",
      "|    neg_free_energy    | -0.00682  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 45000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 295       |\n",
      "|    num. updates       | 280000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.57e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.121     |\n",
      "|    prior_loss         | 7.78e-05  |\n",
      "|    theta              | 0.109     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.88e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.9       |\n",
      "|    action 1 (%)       | 99.1      |\n",
      "|    avg_entropy        | 3.19e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.374    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -374      |\n",
      "|    neg_free_energy    | -0.374    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 46000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 296       |\n",
      "|    num. updates       | 281000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.01e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.118     |\n",
      "|    prior_loss         | 2.45e-06  |\n",
      "|    theta              | 0.0925    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.92e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.8      |\n",
      "|    action 1 (%)       | 50.2      |\n",
      "|    avg_entropy        | 7.06e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00325  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.25     |\n",
      "|    neg_free_energy    | -0.00324  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 47000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 297       |\n",
      "|    num. updates       | 282000    |\n",
      "| train/                |           |\n",
      "|    loss               | 7.78e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.112     |\n",
      "|    prior_loss         | 3.54e-06  |\n",
      "|    theta              | 0.105     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -4.96e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 39.1      |\n",
      "|    action 1 (%)       | 60.9      |\n",
      "|    avg_entropy        | 5.21e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0858   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -85.8     |\n",
      "|    neg_free_energy    | -0.0858   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 48000     |\n",
      "|    fps                | 352       |\n",
      "|    num. episodes      | 298       |\n",
      "|    num. updates       | 283000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.39e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.112     |\n",
      "|    prior_loss         | 3.02e-06  |\n",
      "|    theta              | 0.117     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 0.5      |\n",
      "|    action 1 (%)       | 99.5     |\n",
      "|    auc                | -5e+04   |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -377     |\n",
      "|    fps                | 1.49e+03 |\n",
      "|    time               | 6.71     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 10.9     |\n",
      "|    action 1 (%)       | 89.1     |\n",
      "|    avg_entropy        | 1.56e-06 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.295   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -295     |\n",
      "|    neg_free_energy    | -0.295   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 49000    |\n",
      "|    fps                | 349      |\n",
      "|    num. episodes      | 299      |\n",
      "|    num. updates       | 284000   |\n",
      "| train/                |          |\n",
      "|    loss               | 1.17e+20 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0884   |\n",
      "|    prior_loss         | 6.69e-06 |\n",
      "|    theta              | 0.111    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -5.03e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 48.6      |\n",
      "|    action 1 (%)       | 51.4      |\n",
      "|    avg_entropy        | 7.02e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00914  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.14     |\n",
      "|    neg_free_energy    | -0.00913  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 50000     |\n",
      "|    fps                | 352       |\n",
      "|    num. episodes      | 300       |\n",
      "|    num. updates       | 285000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.96e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0937    |\n",
      "|    prior_loss         | 7.98e-06  |\n",
      "|    theta              | 0.0965    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -5.07e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.76      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 7.64e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00606  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.06     |\n",
      "|    neg_free_energy    | -0.00606  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 51000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 301       |\n",
      "|    num. updates       | 286000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.05e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.147     |\n",
      "|    prior_loss         | 7.75e-06  |\n",
      "|    theta              | 0.0776    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -5.11e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.5e+03   |\n",
      "|    time               | 6.66      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 7.72e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00657  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.57     |\n",
      "|    neg_free_energy    | -0.00656  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 52000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 302       |\n",
      "|    num. updates       | 287000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.75e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.122     |\n",
      "|    prior_loss         | 4.14e-05  |\n",
      "|    theta              | 0.107     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -5.15e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.74      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 6.95e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00941  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.41     |\n",
      "|    neg_free_energy    | -0.0094   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 53000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 303       |\n",
      "|    num. updates       | 288000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.17e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0958    |\n",
      "|    prior_loss         | 1.23e-05  |\n",
      "|    theta              | 0.0997    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 0.5       |\n",
      "|    action 1 (%)       | 99.5      |\n",
      "|    auc                | -5.18e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -377      |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.7      |\n",
      "|    action 1 (%)       | 48.3      |\n",
      "|    avg_entropy        | 6.82e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00747  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.47     |\n",
      "|    neg_free_energy    | -0.00747  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 54000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 304       |\n",
      "|    num. updates       | 289000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.04e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.116     |\n",
      "|    prior_loss         | 1.52e-05  |\n",
      "|    theta              | 0.0987    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.4      |\n",
      "|    action 1 (%)       | 45.6      |\n",
      "|    auc                | -5.19e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.5     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.5      |\n",
      "|    action 1 (%)       | 49.5      |\n",
      "|    avg_entropy        | 6.97e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00387  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.87     |\n",
      "|    neg_free_energy    | -0.00386  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 55000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 305       |\n",
      "|    num. updates       | 290000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.79e+19  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.145     |\n",
      "|    prior_loss         | 6.88e-06  |\n",
      "|    theta              | 0.0986    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -5.19e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -21.4     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.2      |\n",
      "|    action 1 (%)       | 48.8      |\n",
      "|    avg_entropy        | 6.59e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00435  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -4.35     |\n",
      "|    neg_free_energy    | -0.00434  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 56000     |\n",
      "|    fps                | 352       |\n",
      "|    num. episodes      | 306       |\n",
      "|    num. updates       | 291000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.9e+20   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0445    |\n",
      "|    prior_loss         | 1.44e-05  |\n",
      "|    theta              | 0.0776    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -5.19e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -21.4     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.7       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 5.94e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00867  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.67     |\n",
      "|    neg_free_energy    | -0.00866  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 57000     |\n",
      "|    fps                | 346       |\n",
      "|    num. episodes      | 307       |\n",
      "|    num. updates       | 292000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.94e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0593    |\n",
      "|    prior_loss         | 8.98e-06  |\n",
      "|    theta              | 0.101     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -5.19e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -21.4     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.1      |\n",
      "|    action 1 (%)       | 47.9      |\n",
      "|    avg_entropy        | 5.72e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00679  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.79     |\n",
      "|    neg_free_energy    | -0.00678  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 58000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 308       |\n",
      "|    num. updates       | 293000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.7e+20   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.1       |\n",
      "|    prior_loss         | 0.000202  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.9      |\n",
      "|    action 1 (%)       | 45.1      |\n",
      "|    auc                | -5.19e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -21.4     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 5.52e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00549  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.49     |\n",
      "|    neg_free_energy    | -0.00549  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 59000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 309       |\n",
      "|    num. updates       | 294000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.39e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.101     |\n",
      "|    prior_loss         | 4.95e-06  |\n",
      "|    theta              | 0.0932    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 57.2     |\n",
      "|    action 1 (%)       | 42.8     |\n",
      "|    auc                | -5.2e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -30.8    |\n",
      "|    fps                | 1.48e+03 |\n",
      "|    time               | 6.76     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 50.8     |\n",
      "|    action 1 (%)       | 49.2     |\n",
      "|    avg_entropy        | 5.23e-06 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00482 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -4.82    |\n",
      "|    neg_free_energy    | -0.00481 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 60000    |\n",
      "|    fps                | 351      |\n",
      "|    num. episodes      | 310      |\n",
      "|    num. updates       | 295000   |\n",
      "| train/                |          |\n",
      "|    loss               | 1.34e+20 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.142    |\n",
      "|    prior_loss         | 0.000147 |\n",
      "|    theta              | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 57.2     |\n",
      "|    action 1 (%)       | 42.8     |\n",
      "|    auc                | -5.2e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -30.8    |\n",
      "|    fps                | 1.48e+03 |\n",
      "|    time               | 6.74     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 51.1     |\n",
      "|    action 1 (%)       | 48.9     |\n",
      "|    avg_entropy        | 4.83e-06 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00576 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -5.76    |\n",
      "|    neg_free_energy    | -0.00575 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 61000    |\n",
      "|    fps                | 349      |\n",
      "|    num. episodes      | 311      |\n",
      "|    num. updates       | 296000   |\n",
      "| train/                |          |\n",
      "|    loss               | 1.69e+20 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.124    |\n",
      "|    prior_loss         | 9.26e-06 |\n",
      "|    theta              | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 57.2     |\n",
      "|    action 1 (%)       | 42.8     |\n",
      "|    auc                | -5.2e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -30.8    |\n",
      "|    fps                | 1.49e+03 |\n",
      "|    time               | 6.72     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 3.1      |\n",
      "|    action 1 (%)       | 96.9     |\n",
      "|    avg_entropy        | 4.39e-07 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.356   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -356     |\n",
      "|    neg_free_energy    | -0.356   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 62000    |\n",
      "|    fps                | 351      |\n",
      "|    num. episodes      | 312      |\n",
      "|    num. updates       | 297000   |\n",
      "| train/                |          |\n",
      "|    loss               | 2.09e+20 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.13     |\n",
      "|    prior_loss         | 5.45e-06 |\n",
      "|    theta              | 0.122    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 57.2      |\n",
      "|    action 1 (%)       | 42.8      |\n",
      "|    auc                | -5.21e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -30.8     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.6      |\n",
      "|    action 1 (%)       | 49.4      |\n",
      "|    avg_entropy        | 4.02e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00826  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.26     |\n",
      "|    neg_free_energy    | -0.00826  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 63000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 313       |\n",
      "|    num. updates       | 298000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.4e+20   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0592    |\n",
      "|    prior_loss         | 2.05e-05  |\n",
      "|    theta              | 0.0811    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 57.2      |\n",
      "|    action 1 (%)       | 42.8      |\n",
      "|    auc                | -5.21e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -30.8     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.4       |\n",
      "|    action 1 (%)       | 98.6      |\n",
      "|    avg_entropy        | 2.24e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.37     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -370      |\n",
      "|    neg_free_energy    | -0.37     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 64000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 314       |\n",
      "|    num. updates       | 299000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.93e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.128     |\n",
      "|    prior_loss         | 1.37e-05  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 57.9      |\n",
      "|    action 1 (%)       | 42.1      |\n",
      "|    auc                | -5.21e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -33.2     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 53.5      |\n",
      "|    action 1 (%)       | 46.5      |\n",
      "|    avg_entropy        | 3.51e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00959  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.59     |\n",
      "|    neg_free_energy    | -0.00959  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 65000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 315       |\n",
      "|    num. updates       | 300000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.23e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.182     |\n",
      "|    prior_loss         | 1.14e-06  |\n",
      "|    theta              | 0.133     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 57.9      |\n",
      "|    action 1 (%)       | 42.1      |\n",
      "|    auc                | -5.22e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -33.2     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.7      |\n",
      "|    action 1 (%)       | 48.3      |\n",
      "|    avg_entropy        | 2.94e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00979  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.79     |\n",
      "|    neg_free_energy    | -0.00979  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 66000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 316       |\n",
      "|    num. updates       | 301000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.6e+20   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.141     |\n",
      "|    prior_loss         | 1.14e-05  |\n",
      "|    theta              | 0.111     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 57.9      |\n",
      "|    action 1 (%)       | 42.1      |\n",
      "|    auc                | -5.22e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -33.2     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.7       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.9      |\n",
      "|    action 1 (%)       | 50.1      |\n",
      "|    avg_entropy        | 2.5e-06   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0135   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -13.5     |\n",
      "|    neg_free_energy    | -0.0135   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 67000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 317       |\n",
      "|    num. updates       | 302000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.62e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.061     |\n",
      "|    prior_loss         | 2.37e-05  |\n",
      "|    theta              | 0.103     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 57.9      |\n",
      "|    action 1 (%)       | 42.1      |\n",
      "|    auc                | -5.22e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -33.2     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 15.5      |\n",
      "|    action 1 (%)       | 84.5      |\n",
      "|    avg_entropy        | 7.65e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.264    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -264      |\n",
      "|    neg_free_energy    | -0.264    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 68000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 318       |\n",
      "|    num. updates       | 303000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.83e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0956    |\n",
      "|    prior_loss         | 8.16e-06  |\n",
      "|    theta              | 0.115     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 57.9      |\n",
      "|    action 1 (%)       | 42.1      |\n",
      "|    auc                | -5.23e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -33.2     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.4      |\n",
      "|    action 1 (%)       | 49.6      |\n",
      "|    avg_entropy        | 1.92e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00707  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.07     |\n",
      "|    neg_free_energy    | -0.00706  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 69000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 319       |\n",
      "|    num. updates       | 304000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.71e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.154     |\n",
      "|    prior_loss         | 1.29e-06  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.23e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.3      |\n",
      "|    action 1 (%)       | 48.7      |\n",
      "|    avg_entropy        | 1.54e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00868  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.68     |\n",
      "|    neg_free_energy    | -0.00868  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 70000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 320       |\n",
      "|    num. updates       | 305000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.78e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.131     |\n",
      "|    prior_loss         | 1.78e-05  |\n",
      "|    theta              | 0.117     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.23e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 12.4      |\n",
      "|    action 1 (%)       | 87.6      |\n",
      "|    avg_entropy        | 4.04e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.285    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -285      |\n",
      "|    neg_free_energy    | -0.285    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 71000     |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 321       |\n",
      "|    num. updates       | 306000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.52e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.151     |\n",
      "|    prior_loss         | 1.37e-05  |\n",
      "|    theta              | 0.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.24e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.73      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.1      |\n",
      "|    action 1 (%)       | 48.9      |\n",
      "|    avg_entropy        | 9.94e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00898  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.98     |\n",
      "|    neg_free_energy    | -0.00898  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 72000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 322       |\n",
      "|    num. updates       | 307000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.79e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.121     |\n",
      "|    prior_loss         | 1.02e-05  |\n",
      "|    theta              | 0.134     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.24e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.74      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 7.03e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00703  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.03     |\n",
      "|    neg_free_energy    | -0.00703  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 73000     |\n",
      "|    fps                | 348       |\n",
      "|    num. episodes      | 323       |\n",
      "|    num. updates       | 308000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.7e+20   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0912    |\n",
      "|    prior_loss         | 1.43e-05  |\n",
      "|    theta              | 0.111     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.24e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 11.3      |\n",
      "|    action 1 (%)       | 88.7      |\n",
      "|    avg_entropy        | 1.84e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.29     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -290      |\n",
      "|    neg_free_energy    | -0.29     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 74000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 324       |\n",
      "|    num. updates       | 309000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.22e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.135     |\n",
      "|    prior_loss         | 8.6e-05   |\n",
      "|    theta              | 0.115     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.25e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.5       |\n",
      "|    action 1 (%)       | 98.5      |\n",
      "|    avg_entropy        | 9.14e-08  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.368    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -368      |\n",
      "|    neg_free_energy    | -0.368    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 75000     |\n",
      "|    fps                | 351       |\n",
      "|    num. episodes      | 325       |\n",
      "|    num. updates       | 310000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.78e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.123     |\n",
      "|    prior_loss         | 5.96e-06  |\n",
      "|    theta              | 0.127     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.25e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.48e+03  |\n",
      "|    time               | 6.75      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 3         |\n",
      "|    action 1 (%)       | 97        |\n",
      "|    avg_entropy        | 1.13e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.355    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -355      |\n",
      "|    neg_free_energy    | -0.355    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 76000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 326       |\n",
      "|    num. updates       | 311000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.95e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.141     |\n",
      "|    prior_loss         | 2.96e-06  |\n",
      "|    theta              | 0.114     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.26e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    avg_entropy        | 1.93e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0241   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -24.1     |\n",
      "|    neg_free_energy    | -0.0241   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 77000     |\n",
      "|    fps                | 349       |\n",
      "|    num. episodes      | 327       |\n",
      "|    num. updates       | 312000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.49e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.163     |\n",
      "|    prior_loss         | 9.53e-06  |\n",
      "|    theta              | 0.128     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.26e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.69      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 22.3      |\n",
      "|    action 1 (%)       | 77.7      |\n",
      "|    avg_entropy        | 1.05e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.219    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -219      |\n",
      "|    neg_free_energy    | -0.219    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 78000     |\n",
      "|    fps                | 354       |\n",
      "|    num. episodes      | 328       |\n",
      "|    num. updates       | 313000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.94e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.185     |\n",
      "|    prior_loss         | 4.79e-06  |\n",
      "|    theta              | 0.149     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.26e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.72      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.9      |\n",
      "|    action 1 (%)       | 48.1      |\n",
      "|    avg_entropy        | 1.18e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0121   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -12.1     |\n",
      "|    neg_free_energy    | -0.0121   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 79000     |\n",
      "|    fps                | 345       |\n",
      "|    num. episodes      | 329       |\n",
      "|    num. updates       | 314000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.46e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.153     |\n",
      "|    prior_loss         | 7.72e-06  |\n",
      "|    theta              | 0.126     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.27e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 9.23e-08  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00827  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.27     |\n",
      "|    neg_free_energy    | -0.00826  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 80000     |\n",
      "|    fps                | 337       |\n",
      "|    num. episodes      | 330       |\n",
      "|    num. updates       | 315000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.36e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.134     |\n",
      "|    prior_loss         | 8.58e-06  |\n",
      "|    theta              | 0.118     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.27e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.57      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.5      |\n",
      "|    action 1 (%)       | 49.5      |\n",
      "|    avg_entropy        | 1.94e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00973  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.73     |\n",
      "|    neg_free_energy    | -0.00973  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 81000     |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 331       |\n",
      "|    num. updates       | 316000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.01e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0588    |\n",
      "|    prior_loss         | 1.02e-06  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.27e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.62      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 53.4      |\n",
      "|    action 1 (%)       | 46.6      |\n",
      "|    avg_entropy        | 2.49e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00691  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -6.91     |\n",
      "|    neg_free_energy    | -0.00691  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 82000     |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 332       |\n",
      "|    num. updates       | 317000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.92e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.118     |\n",
      "|    prior_loss         | 4.81e-05  |\n",
      "|    theta              | 0.0987    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.28e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 6         |\n",
      "|    action 1 (%)       | 94        |\n",
      "|    avg_entropy        | 1.21e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.336    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -336      |\n",
      "|    neg_free_energy    | -0.336    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 83000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 333       |\n",
      "|    num. updates       | 318000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.4e+20   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.123     |\n",
      "|    prior_loss         | 3.86e-06  |\n",
      "|    theta              | 0.121     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.28e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.5       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 54        |\n",
      "|    action 1 (%)       | 46        |\n",
      "|    avg_entropy        | 7.99e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00904  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9.04     |\n",
      "|    neg_free_energy    | -0.00904  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 84000     |\n",
      "|    fps                | 365       |\n",
      "|    num. episodes      | 334       |\n",
      "|    num. updates       | 319000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.48e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0965    |\n",
      "|    prior_loss         | 9.74e-06  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.28e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.54      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.6      |\n",
      "|    action 1 (%)       | 48.4      |\n",
      "|    avg_entropy        | 1.19e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00887  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.87     |\n",
      "|    neg_free_energy    | -0.00887  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 85000     |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 335       |\n",
      "|    num. updates       | 320000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.84e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.125     |\n",
      "|    prior_loss         | 1.05e-05  |\n",
      "|    theta              | 0.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.29e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.35      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.1       |\n",
      "|    action 1 (%)       | 98.9      |\n",
      "|    avg_entropy        | 1.93e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.372    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -372      |\n",
      "|    neg_free_energy    | -0.372    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 86000     |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 336       |\n",
      "|    num. updates       | 321000    |\n",
      "| train/                |           |\n",
      "|    loss               | 7.58e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0762    |\n",
      "|    prior_loss         | 6.95e-05  |\n",
      "|    theta              | 0.0888    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.29e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.47      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.5       |\n",
      "|    action 1 (%)       | 98.5      |\n",
      "|    avg_entropy        | 1.89e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.368    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -368      |\n",
      "|    neg_free_energy    | -0.368    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 87000     |\n",
      "|    fps                | 371       |\n",
      "|    num. episodes      | 337       |\n",
      "|    num. updates       | 322000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.4e+20   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0985    |\n",
      "|    prior_loss         | 5.64e-06  |\n",
      "|    theta              | 0.104     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.29e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.54      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 16.3      |\n",
      "|    action 1 (%)       | 83.7      |\n",
      "|    avg_entropy        | 8.39e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.261    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -261      |\n",
      "|    neg_free_energy    | -0.261    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 88000     |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 338       |\n",
      "|    num. updates       | 323000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.13e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.106     |\n",
      "|    prior_loss         | 4.9e-06   |\n",
      "|    theta              | 0.105     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 58.2     |\n",
      "|    action 1 (%)       | 41.8     |\n",
      "|    auc                | -5.3e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -35.5    |\n",
      "|    fps                | 1.52e+03 |\n",
      "|    time               | 6.57     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 24.8     |\n",
      "|    action 1 (%)       | 75.2     |\n",
      "|    avg_entropy        | 1.56e-06 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.197   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -197     |\n",
      "|    neg_free_energy    | -0.197   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 89000    |\n",
      "|    fps                | 362      |\n",
      "|    num. episodes      | 339      |\n",
      "|    num. updates       | 324000   |\n",
      "| train/                |          |\n",
      "|    loss               | 1.01e+21 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.138    |\n",
      "|    prior_loss         | 0.000155 |\n",
      "|    theta              | 0.124    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 58.2     |\n",
      "|    action 1 (%)       | 41.8     |\n",
      "|    auc                | -5.3e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -35.5    |\n",
      "|    fps                | 1.51e+03 |\n",
      "|    time               | 6.62     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 3.5      |\n",
      "|    action 1 (%)       | 96.5     |\n",
      "|    avg_entropy        | 3.84e-07 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.353   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -353     |\n",
      "|    neg_free_energy    | -0.353   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 90000    |\n",
      "|    fps                | 357      |\n",
      "|    num. episodes      | 340      |\n",
      "|    num. updates       | 325000   |\n",
      "| train/                |          |\n",
      "|    loss               | 1.07e+21 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.146    |\n",
      "|    prior_loss         | 5.99e-06 |\n",
      "|    theta              | 0.128    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.31e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.56      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 51.6      |\n",
      "|    action 1 (%)       | 48.4      |\n",
      "|    avg_entropy        | 4.05e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00594  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.94     |\n",
      "|    neg_free_energy    | -0.00594  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 91000     |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 341       |\n",
      "|    num. updates       | 326000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.11e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.124     |\n",
      "|    prior_loss         | 1.26e-05  |\n",
      "|    theta              | 0.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.31e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.54      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 22.1      |\n",
      "|    action 1 (%)       | 77.9      |\n",
      "|    avg_entropy        | 2.17e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.211    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -211      |\n",
      "|    neg_free_energy    | -0.211    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 92000     |\n",
      "|    fps                | 355       |\n",
      "|    num. episodes      | 342       |\n",
      "|    num. updates       | 327000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.51e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.103     |\n",
      "|    prior_loss         | 1.22e-05  |\n",
      "|    theta              | 0.114     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.31e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.56      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.8       |\n",
      "|    action 1 (%)       | 99.2      |\n",
      "|    avg_entropy        | 2e-07     |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.375    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -375      |\n",
      "|    neg_free_energy    | -0.375    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 93000     |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 343       |\n",
      "|    num. updates       | 328000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.08e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.159     |\n",
      "|    prior_loss         | 7.6e-06   |\n",
      "|    theta              | 0.126     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.2      |\n",
      "|    action 1 (%)       | 41.8      |\n",
      "|    auc                | -5.32e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.5     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.38      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49        |\n",
      "|    action 1 (%)       | 51        |\n",
      "|    avg_entropy        | 5.07e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0351   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -35.1     |\n",
      "|    neg_free_energy    | -0.0351   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 94000     |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 344       |\n",
      "|    num. updates       | 329000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.63e+20  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.111     |\n",
      "|    prior_loss         | 2.81e-06  |\n",
      "|    theta              | 0.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.32e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.37      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.3      |\n",
      "|    action 1 (%)       | 49.7      |\n",
      "|    avg_entropy        | 5.82e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0057   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.7      |\n",
      "|    neg_free_energy    | -0.00569  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 95000     |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 345       |\n",
      "|    num. updates       | 330000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.53e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.136     |\n",
      "|    prior_loss         | 5.9e-06   |\n",
      "|    theta              | 0.128     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.32e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.42      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 6.25e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00558  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.58     |\n",
      "|    neg_free_energy    | -0.00558  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 96000     |\n",
      "|    fps                | 369       |\n",
      "|    num. episodes      | 346       |\n",
      "|    num. updates       | 331000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.28e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.116     |\n",
      "|    prior_loss         | 9.66e-05  |\n",
      "|    theta              | 0.107     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.33e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.56      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.6      |\n",
      "|    action 1 (%)       | 49.4      |\n",
      "|    avg_entropy        | 6.93e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00562  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.62     |\n",
      "|    neg_free_energy    | -0.00561  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 97000     |\n",
      "|    fps                | 355       |\n",
      "|    num. episodes      | 347       |\n",
      "|    num. updates       | 332000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.36e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0901    |\n",
      "|    prior_loss         | 1.12e-05  |\n",
      "|    theta              | 0.109     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.33e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.3       |\n",
      "|    action 1 (%)       | 98.7      |\n",
      "|    avg_entropy        | 4.42e-07  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.37     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -370      |\n",
      "|    neg_free_energy    | -0.37     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 98000     |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 348       |\n",
      "|    num. updates       | 333000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.48e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.12      |\n",
      "|    prior_loss         | 3.1e-06   |\n",
      "|    theta              | 0.119     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.33e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.61      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 30.6      |\n",
      "|    action 1 (%)       | 69.4      |\n",
      "|    avg_entropy        | 5.18e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.156    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -156      |\n",
      "|    neg_free_energy    | -0.156    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 99000     |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 349       |\n",
      "|    num. updates       | 334000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.47e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.155     |\n",
      "|    prior_loss         | 6.25e-06  |\n",
      "|    theta              | 0.121     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.34e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.57      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 8.6e-06   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00558  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.58     |\n",
      "|    neg_free_energy    | -0.00557  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 100000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 350       |\n",
      "|    num. updates       | 335000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.19e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.149     |\n",
      "|    prior_loss         | 4.61e-06  |\n",
      "|    theta              | 0.114     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.34e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.59      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.4      |\n",
      "|    action 1 (%)       | 50.6      |\n",
      "|    avg_entropy        | 9.16e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0147   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -14.7     |\n",
      "|    neg_free_energy    | -0.0147   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 101000    |\n",
      "|    fps                | 362       |\n",
      "|    num. episodes      | 351       |\n",
      "|    num. updates       | 336000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.05e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.15      |\n",
      "|    prior_loss         | 1.17e-05  |\n",
      "|    theta              | 0.127     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.34e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.4      |\n",
      "|    action 1 (%)       | 49.6      |\n",
      "|    avg_entropy        | 9.94e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00804  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.04     |\n",
      "|    neg_free_energy    | -0.00803  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 102000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 352       |\n",
      "|    num. updates       | 337000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.8e+21   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.132     |\n",
      "|    prior_loss         | 4.55e-06  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.35e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 1.06e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00517  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.17     |\n",
      "|    neg_free_energy    | -0.00516  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 103000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 353       |\n",
      "|    num. updates       | 338000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.74e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.169     |\n",
      "|    prior_loss         | 6.07e-05  |\n",
      "|    theta              | 0.123     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.35e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.6       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 42.1      |\n",
      "|    action 1 (%)       | 57.9      |\n",
      "|    avg_entropy        | 9.51e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0718   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -71.8     |\n",
      "|    neg_free_energy    | -0.0718   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 104000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 354       |\n",
      "|    num. updates       | 339000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.65e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.153     |\n",
      "|    prior_loss         | 7.52e-06  |\n",
      "|    theta              | 0.128     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.36e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 39.2      |\n",
      "|    action 1 (%)       | 60.8      |\n",
      "|    avg_entropy        | 9.37e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0946   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -94.6     |\n",
      "|    neg_free_energy    | -0.0946   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 105000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 355       |\n",
      "|    num. updates       | 340000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.22e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.105     |\n",
      "|    prior_loss         | 1.55e-05  |\n",
      "|    theta              | 0.0975    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.36e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.56e+03  |\n",
      "|    time               | 6.39      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.1      |\n",
      "|    action 1 (%)       | 47.9      |\n",
      "|    avg_entropy        | 1.27e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00864  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -8.64     |\n",
      "|    neg_free_energy    | -0.00863  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 106000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 356       |\n",
      "|    num. updates       | 341000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.64e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.115     |\n",
      "|    prior_loss         | 4.25e-07  |\n",
      "|    theta              | 0.124     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.36e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.58e+03  |\n",
      "|    time               | 6.33      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 10.4      |\n",
      "|    action 1 (%)       | 89.6      |\n",
      "|    avg_entropy        | 3.12e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.301    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -301      |\n",
      "|    neg_free_energy    | -0.301    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 107000    |\n",
      "|    fps                | 368       |\n",
      "|    num. episodes      | 357       |\n",
      "|    num. updates       | 342000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.45e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.116     |\n",
      "|    prior_loss         | 8.94e-06  |\n",
      "|    theta              | 0.117     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.37e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 41        |\n",
      "|    action 1 (%)       | 59        |\n",
      "|    avg_entropy        | 1.2e-05   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0745   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -74.5     |\n",
      "|    neg_free_energy    | -0.0744   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 108000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 358       |\n",
      "|    num. updates       | 343000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.65e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.1       |\n",
      "|    prior_loss         | 5.73e-06  |\n",
      "|    theta              | 0.103     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 58.3      |\n",
      "|    action 1 (%)       | 41.7      |\n",
      "|    auc                | -5.37e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -35.6     |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 52.9      |\n",
      "|    action 1 (%)       | 47.1      |\n",
      "|    avg_entropy        | 1.53e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0111   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -11.1     |\n",
      "|    neg_free_energy    | -0.0111   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 109000    |\n",
      "|    fps                | 350       |\n",
      "|    num. episodes      | 359       |\n",
      "|    num. updates       | 344000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.01e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.104     |\n",
      "|    prior_loss         | 4.6e-06   |\n",
      "|    theta              | 0.0988    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.2      |\n",
      "|    action 1 (%)       | 44.8      |\n",
      "|    auc                | -5.37e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 13.7      |\n",
      "|    action 1 (%)       | 86.3      |\n",
      "|    avg_entropy        | 4.5e-06   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.28     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -280      |\n",
      "|    neg_free_energy    | -0.28     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 110000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 360       |\n",
      "|    num. updates       | 345000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.38e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.112     |\n",
      "|    prior_loss         | 1.74e-06  |\n",
      "|    theta              | 0.122     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.2      |\n",
      "|    action 1 (%)       | 44.8      |\n",
      "|    auc                | -5.37e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.53      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 34.2      |\n",
      "|    action 1 (%)       | 65.8      |\n",
      "|    avg_entropy        | 1.23e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.111    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -111      |\n",
      "|    neg_free_energy    | -0.111    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 111000    |\n",
      "|    fps                | 353       |\n",
      "|    num. episodes      | 361       |\n",
      "|    num. updates       | 346000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.67e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0827    |\n",
      "|    prior_loss         | 6.77e-07  |\n",
      "|    theta              | 0.103     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.2      |\n",
      "|    action 1 (%)       | 44.8      |\n",
      "|    auc                | -5.38e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.48      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 5.7       |\n",
      "|    action 1 (%)       | 94.3      |\n",
      "|    avg_entropy        | 2.27e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.34     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -340      |\n",
      "|    neg_free_energy    | -0.34     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 112000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 362       |\n",
      "|    num. updates       | 347000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.71e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0749    |\n",
      "|    prior_loss         | 1.17e-05  |\n",
      "|    theta              | 0.114     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.2      |\n",
      "|    action 1 (%)       | 44.8      |\n",
      "|    auc                | -5.38e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.59      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 16.7      |\n",
      "|    action 1 (%)       | 83.3      |\n",
      "|    avg_entropy        | 6.72e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.247    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -247      |\n",
      "|    neg_free_energy    | -0.247    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 113000    |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 363       |\n",
      "|    num. updates       | 348000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.12e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0956    |\n",
      "|    prior_loss         | 7.58e-06  |\n",
      "|    theta              | 0.125     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 55.2      |\n",
      "|    action 1 (%)       | 44.8      |\n",
      "|    auc                | -5.38e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -22.9     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.59      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 37.1      |\n",
      "|    action 1 (%)       | 62.9      |\n",
      "|    avg_entropy        | 1.37e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.117    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -117      |\n",
      "|    neg_free_energy    | -0.117    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 114000    |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 364       |\n",
      "|    num. updates       | 349000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.46e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0964    |\n",
      "|    prior_loss         | 4.38e-06  |\n",
      "|    theta              | 0.101     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 52.5      |\n",
      "|    action 1 (%)       | 47.5      |\n",
      "|    auc                | -5.38e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -13       |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.51      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.5       |\n",
      "|    action 1 (%)       | 98.5      |\n",
      "|    avg_entropy        | 1.02e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.369    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -369      |\n",
      "|    neg_free_energy    | -0.369    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 115000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 365       |\n",
      "|    num. updates       | 350000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.8e+21   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.133     |\n",
      "|    prior_loss         | 4.12e-06  |\n",
      "|    theta              | 0.119     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 52.5      |\n",
      "|    action 1 (%)       | 47.5      |\n",
      "|    auc                | -5.38e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -13       |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.51      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 5.1       |\n",
      "|    action 1 (%)       | 94.9      |\n",
      "|    avg_entropy        | 2.53e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.342    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -342      |\n",
      "|    neg_free_energy    | -0.342    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 116000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 366       |\n",
      "|    num. updates       | 351000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.57e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.033     |\n",
      "|    prior_loss         | 1.2e-05   |\n",
      "|    theta              | 0.0928    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 52.5      |\n",
      "|    action 1 (%)       | 47.5      |\n",
      "|    auc                | -5.38e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -13       |\n",
      "|    fps                | 1.54e+03  |\n",
      "|    time               | 6.51      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 11.3      |\n",
      "|    action 1 (%)       | 88.7      |\n",
      "|    avg_entropy        | 4.91e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.298    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -298      |\n",
      "|    neg_free_energy    | -0.298    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 117000    |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 367       |\n",
      "|    num. updates       | 352000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.56e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.121     |\n",
      "|    prior_loss         | 9.14e-06  |\n",
      "|    theta              | 0.115     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 52.5      |\n",
      "|    action 1 (%)       | 47.5      |\n",
      "|    auc                | -5.39e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -13       |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.46      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.7      |\n",
      "|    action 1 (%)       | 49.3      |\n",
      "|    avg_entropy        | 2.2e-05   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00527  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.27     |\n",
      "|    neg_free_energy    | -0.00524  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 118000    |\n",
      "|    fps                | 355       |\n",
      "|    num. episodes      | 368       |\n",
      "|    num. updates       | 353000    |\n",
      "| train/                |           |\n",
      "|    loss               | 2.24e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.111     |\n",
      "|    prior_loss         | 4.98e-06  |\n",
      "|    theta              | 0.0949    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 52.5      |\n",
      "|    action 1 (%)       | 47.5      |\n",
      "|    auc                | -5.39e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -13       |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 8.1       |\n",
      "|    action 1 (%)       | 91.9      |\n",
      "|    avg_entropy        | 4.14e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.32     |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -320      |\n",
      "|    neg_free_energy    | -0.32     |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 119000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 369       |\n",
      "|    num. updates       | 354000    |\n",
      "| train/                |           |\n",
      "|    loss               | 3.02e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.167     |\n",
      "|    prior_loss         | 5.89e-06  |\n",
      "|    theta              | 0.126     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.3      |\n",
      "|    action 1 (%)       | 45.7      |\n",
      "|    auc                | -5.39e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.5     |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.54      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.1      |\n",
      "|    action 1 (%)       | 50.9      |\n",
      "|    avg_entropy        | 2.3e-05   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00713  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -7.13     |\n",
      "|    neg_free_energy    | -0.0071   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 120000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 370       |\n",
      "|    num. updates       | 355000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.11e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.115     |\n",
      "|    prior_loss         | 1.26e-06  |\n",
      "|    theta              | 0.0994    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.3      |\n",
      "|    action 1 (%)       | 45.7      |\n",
      "|    auc                | -5.39e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.5     |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.63      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 11.3      |\n",
      "|    action 1 (%)       | 88.7      |\n",
      "|    avg_entropy        | 6.14e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.291    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -291      |\n",
      "|    neg_free_energy    | -0.291    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 121000    |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 371       |\n",
      "|    num. updates       | 356000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.37e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.123     |\n",
      "|    prior_loss         | 7.85e-06  |\n",
      "|    theta              | 0.123     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.3      |\n",
      "|    action 1 (%)       | 45.7      |\n",
      "|    auc                | -5.39e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.5     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.5      |\n",
      "|    action 1 (%)       | 50.5      |\n",
      "|    avg_entropy        | 2.54e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00286  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -2.86     |\n",
      "|    neg_free_energy    | -0.00284  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 122000    |\n",
      "|    fps                | 356       |\n",
      "|    num. episodes      | 372       |\n",
      "|    num. updates       | 357000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.67e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0906    |\n",
      "|    prior_loss         | 4.81e-06  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 54.3     |\n",
      "|    action 1 (%)       | 45.7     |\n",
      "|    auc                | -5.4e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -20.5    |\n",
      "|    fps                | 1.52e+03 |\n",
      "|    time               | 6.57     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 1.7      |\n",
      "|    action 1 (%)       | 98.3     |\n",
      "|    avg_entropy        | 1.36e-06 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.367   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -367     |\n",
      "|    neg_free_energy    | -0.367   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 123000   |\n",
      "|    fps                | 356      |\n",
      "|    num. episodes      | 373      |\n",
      "|    num. updates       | 358000   |\n",
      "| train/                |          |\n",
      "|    loss               | 3e+21    |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.145    |\n",
      "|    prior_loss         | 1.71e-05 |\n",
      "|    theta              | 0.125    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 54.3     |\n",
      "|    action 1 (%)       | 45.7     |\n",
      "|    auc                | -5.4e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -20.5    |\n",
      "|    fps                | 1.54e+03 |\n",
      "|    time               | 6.51     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 51.8     |\n",
      "|    action 1 (%)       | 48.2     |\n",
      "|    avg_entropy        | 2.64e-05 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00627 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -6.27    |\n",
      "|    neg_free_energy    | -0.00624 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 124000   |\n",
      "|    fps                | 362      |\n",
      "|    num. episodes      | 374      |\n",
      "|    num. updates       | 359000   |\n",
      "| train/                |          |\n",
      "|    loss               | 5.56e+21 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.11     |\n",
      "|    prior_loss         | 1.86e-06 |\n",
      "|    theta              | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 54.8     |\n",
      "|    action 1 (%)       | 45.2     |\n",
      "|    auc                | -5.4e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -20.9    |\n",
      "|    fps                | 1.53e+03 |\n",
      "|    time               | 6.53     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 33.5     |\n",
      "|    action 1 (%)       | 66.5     |\n",
      "|    avg_entropy        | 1.88e-05 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.122   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -122     |\n",
      "|    neg_free_energy    | -0.122   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 125000   |\n",
      "|    fps                | 369      |\n",
      "|    num. episodes      | 375      |\n",
      "|    num. updates       | 360000   |\n",
      "| train/                |          |\n",
      "|    loss               | 8.4e+21  |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0516   |\n",
      "|    prior_loss         | 3.94e-06 |\n",
      "|    theta              | 0.0887   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 54.8     |\n",
      "|    action 1 (%)       | 45.2     |\n",
      "|    auc                | -5.4e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -20.9    |\n",
      "|    fps                | 1.52e+03 |\n",
      "|    time               | 6.6      |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 0.4      |\n",
      "|    action 1 (%)       | 99.6     |\n",
      "|    avg_entropy        | 6.02e-07 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.378   |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -378     |\n",
      "|    neg_free_energy    | -0.378   |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 126000   |\n",
      "|    fps                | 359      |\n",
      "|    num. episodes      | 376      |\n",
      "|    num. updates       | 361000   |\n",
      "| train/                |          |\n",
      "|    loss               | 5.14e+21 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.123    |\n",
      "|    prior_loss         | 1.29e-05 |\n",
      "|    theta              | 0.113    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    action 0 (%)       | 54.8     |\n",
      "|    action 1 (%)       | 45.2     |\n",
      "|    auc                | -5.4e+04 |\n",
      "|    avg_episode_length | 1e+03    |\n",
      "|    avg_reward         | -20.9    |\n",
      "|    fps                | 1.53e+03 |\n",
      "|    time               | 6.55     |\n",
      "| rollout/              |          |\n",
      "|    action 0 (%)       | 50       |\n",
      "|    action 1 (%)       | 50       |\n",
      "|    avg_entropy        | 2.87e-05 |\n",
      "|    avg_episode_length | 1000     |\n",
      "|    avg_reward_rate    | -0.00887 |\n",
      "|    beta               | 1        |\n",
      "|    ep_reward          | -8.87    |\n",
      "|    neg_free_energy    | -0.00884 |\n",
      "| time/                 |          |\n",
      "|    env. steps         | 127000   |\n",
      "|    fps                | 357      |\n",
      "|    num. episodes      | 377      |\n",
      "|    num. updates       | 362000   |\n",
      "| train/                |          |\n",
      "|    loss               | 7.52e+21 |\n",
      "|    lr                 | 0.0035   |\n",
      "|    new_theta          | 0.0819   |\n",
      "|    prior_loss         | 2.28e-06 |\n",
      "|    theta              | 0.113    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.8      |\n",
      "|    action 1 (%)       | 45.2      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.9     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.36      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 43.9      |\n",
      "|    action 1 (%)       | 56.1      |\n",
      "|    avg_entropy        | 2.52e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.0615   |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -61.5     |\n",
      "|    neg_free_energy    | -0.0615   |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 128000    |\n",
      "|    fps                | 360       |\n",
      "|    num. episodes      | 378       |\n",
      "|    num. updates       | 363000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.93e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0718    |\n",
      "|    prior_loss         | 3.19e-05  |\n",
      "|    theta              | 0.102     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 54.8      |\n",
      "|    action 1 (%)       | 45.2      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -20.9     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.59      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 5.8       |\n",
      "|    action 1 (%)       | 94.2      |\n",
      "|    avg_entropy        | 4.07e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.335    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -335      |\n",
      "|    neg_free_energy    | -0.335    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 129000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 379       |\n",
      "|    num. updates       | 364000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.69e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.131     |\n",
      "|    prior_loss         | 8.66e-05  |\n",
      "|    theta              | 0.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 48.8      |\n",
      "|    action 1 (%)       | 51.2      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -0.699    |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.6       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 33.7      |\n",
      "|    action 1 (%)       | 66.3      |\n",
      "|    avg_entropy        | 2.17e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.123    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -123      |\n",
      "|    neg_free_energy    | -0.123    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 130000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 380       |\n",
      "|    num. updates       | 365000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.3e+21   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.126     |\n",
      "|    prior_loss         | 4.99e-06  |\n",
      "|    theta              | 0.107     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.8      |\n",
      "|    action 1 (%)       | 52.2      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.87      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.2      |\n",
      "|    action 1 (%)       | 49.8      |\n",
      "|    avg_entropy        | 3.11e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00546  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -5.46     |\n",
      "|    neg_free_energy    | -0.00542  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 131000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 381       |\n",
      "|    num. updates       | 366000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.37e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.147     |\n",
      "|    prior_loss         | 5.37e-06  |\n",
      "|    theta              | 0.139     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.8      |\n",
      "|    action 1 (%)       | 52.2      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.87      |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 24.9      |\n",
      "|    action 1 (%)       | 75.1      |\n",
      "|    avg_entropy        | 1.63e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.194    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -194      |\n",
      "|    neg_free_energy    | -0.194    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 132000    |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 382       |\n",
      "|    num. updates       | 367000    |\n",
      "| train/                |           |\n",
      "|    loss               | 4.77e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.123     |\n",
      "|    prior_loss         | 1.54e-05  |\n",
      "|    theta              | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.8      |\n",
      "|    action 1 (%)       | 52.2      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.87      |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.6       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50        |\n",
      "|    action 1 (%)       | 50        |\n",
      "|    avg_entropy        | 3.2e-05   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00361  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -3.61     |\n",
      "|    neg_free_energy    | -0.00358  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 133000    |\n",
      "|    fps                | 356       |\n",
      "|    num. episodes      | 383       |\n",
      "|    num. updates       | 368000    |\n",
      "| train/                |           |\n",
      "|    loss               | 5.08e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.119     |\n",
      "|    prior_loss         | 4.15e-06  |\n",
      "|    theta              | 0.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.8      |\n",
      "|    action 1 (%)       | 52.2      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.87      |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.54      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 6.5       |\n",
      "|    action 1 (%)       | 93.5      |\n",
      "|    avg_entropy        | 4.7e-06   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.331    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -331      |\n",
      "|    neg_free_energy    | -0.331    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 134000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 384       |\n",
      "|    num. updates       | 369000    |\n",
      "| train/                |           |\n",
      "|    loss               | 7.26e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.138     |\n",
      "|    prior_loss         | 2.03e-05  |\n",
      "|    theta              | 0.139     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 56.6      |\n",
      "|    action 1 (%)       | 43.4      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -26.2     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.56      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 28.2      |\n",
      "|    action 1 (%)       | 71.8      |\n",
      "|    avg_entropy        | 1.87e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.171    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -171      |\n",
      "|    neg_free_energy    | -0.171    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 135000    |\n",
      "|    fps                | 356       |\n",
      "|    num. episodes      | 385       |\n",
      "|    num. updates       | 370000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.29e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.141     |\n",
      "|    prior_loss         | 3.47e-06  |\n",
      "|    theta              | 0.132     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 56.6      |\n",
      "|    action 1 (%)       | 43.4      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -26.2     |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.61      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 10.3      |\n",
      "|    action 1 (%)       | 89.7      |\n",
      "|    avg_entropy        | 7.15e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.304    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -304      |\n",
      "|    neg_free_energy    | -0.304    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 136000    |\n",
      "|    fps                | 364       |\n",
      "|    num. episodes      | 386       |\n",
      "|    num. updates       | 371000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.99e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.166     |\n",
      "|    prior_loss         | 1.03e-06  |\n",
      "|    theta              | 0.145     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 56.6      |\n",
      "|    action 1 (%)       | 43.4      |\n",
      "|    auc                | -5.41e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -26.2     |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.38      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 3.2       |\n",
      "|    action 1 (%)       | 96.8      |\n",
      "|    avg_entropy        | 2.83e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.355    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -355      |\n",
      "|    neg_free_energy    | -0.355    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 137000    |\n",
      "|    fps                | 361       |\n",
      "|    num. episodes      | 387       |\n",
      "|    num. updates       | 372000    |\n",
      "| train/                |           |\n",
      "|    loss               | 7.75e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0828    |\n",
      "|    prior_loss         | 1.04e-05  |\n",
      "|    theta              | 0.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 56.6      |\n",
      "|    action 1 (%)       | 43.4      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -26.2     |\n",
      "|    fps                | 1.53e+03  |\n",
      "|    time               | 6.53      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.9       |\n",
      "|    action 1 (%)       | 99.1      |\n",
      "|    avg_entropy        | 1.25e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.375    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -375      |\n",
      "|    neg_free_energy    | -0.375    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 138000    |\n",
      "|    fps                | 366       |\n",
      "|    num. episodes      | 388       |\n",
      "|    num. updates       | 373000    |\n",
      "| train/                |           |\n",
      "|    loss               | 9.43e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.142     |\n",
      "|    prior_loss         | 7.73e-06  |\n",
      "|    theta              | 0.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 56.6      |\n",
      "|    action 1 (%)       | 43.4      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | -26.2     |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 3.5       |\n",
      "|    action 1 (%)       | 96.5      |\n",
      "|    avg_entropy        | 3.16e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.353    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -353      |\n",
      "|    neg_free_energy    | -0.353    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 139000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 389       |\n",
      "|    num. updates       | 374000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.4e+21   |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.151     |\n",
      "|    prior_loss         | 3.07e-06  |\n",
      "|    theta              | 0.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.5      |\n",
      "|    action 1 (%)       | 52.5      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 3.2       |\n",
      "|    fps                | 1.57e+03  |\n",
      "|    time               | 6.37      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 49.9      |\n",
      "|    action 1 (%)       | 50.1      |\n",
      "|    avg_entropy        | 3.56e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.009    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -9        |\n",
      "|    neg_free_energy    | -0.00896  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 140000    |\n",
      "|    fps                | 358       |\n",
      "|    num. episodes      | 390       |\n",
      "|    num. updates       | 375000    |\n",
      "| train/                |           |\n",
      "|    loss               | 7.53e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.144     |\n",
      "|    prior_loss         | 4.55e-06  |\n",
      "|    theta              | 0.131     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.5      |\n",
      "|    action 1 (%)       | 52.5      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 3.2       |\n",
      "|    fps                | 1.55e+03  |\n",
      "|    time               | 6.44      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 50.1      |\n",
      "|    action 1 (%)       | 49.9      |\n",
      "|    avg_entropy        | 3.69e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.00405  |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -4.05     |\n",
      "|    neg_free_energy    | -0.00402  |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 141000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 391       |\n",
      "|    num. updates       | 376000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.21e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.0821    |\n",
      "|    prior_loss         | 2.12e-06  |\n",
      "|    theta              | 0.111     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.5      |\n",
      "|    action 1 (%)       | 52.5      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 3.2       |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.62      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 6.8       |\n",
      "|    action 1 (%)       | 93.2      |\n",
      "|    avg_entropy        | 6.2e-06   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.323    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -323      |\n",
      "|    neg_free_energy    | -0.323    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 142000    |\n",
      "|    fps                | 353       |\n",
      "|    num. episodes      | 392       |\n",
      "|    num. updates       | 377000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.06e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.104     |\n",
      "|    prior_loss         | 1.11e-05  |\n",
      "|    theta              | 0.113     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.5      |\n",
      "|    action 1 (%)       | 52.5      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 3.2       |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.6       |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 21.1      |\n",
      "|    action 1 (%)       | 78.9      |\n",
      "|    avg_entropy        | 1.65e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.221    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -221      |\n",
      "|    neg_free_energy    | -0.221    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 143000    |\n",
      "|    fps                | 354       |\n",
      "|    num. episodes      | 393       |\n",
      "|    num. updates       | 378000    |\n",
      "| train/                |           |\n",
      "|    loss               | 6.01e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.171     |\n",
      "|    prior_loss         | 3.34e-06  |\n",
      "|    theta              | 0.132     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.5      |\n",
      "|    action 1 (%)       | 52.5      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 3.2       |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.62      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 12.4      |\n",
      "|    action 1 (%)       | 87.6      |\n",
      "|    avg_entropy        | 1e-05     |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.286    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -286      |\n",
      "|    neg_free_energy    | -0.286    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 144000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 394       |\n",
      "|    num. updates       | 379000    |\n",
      "| train/                |           |\n",
      "|    loss               | 8.06e+21  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.153     |\n",
      "|    prior_loss         | 6.38e-06  |\n",
      "|    theta              | 0.142     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.4      |\n",
      "|    action 1 (%)       | 52.6      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.95      |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.59      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 9.3       |\n",
      "|    action 1 (%)       | 90.7      |\n",
      "|    avg_entropy        | 7.82e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.309    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -309      |\n",
      "|    neg_free_energy    | -0.309    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 145000    |\n",
      "|    fps                | 356       |\n",
      "|    num. episodes      | 395       |\n",
      "|    num. updates       | 380000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.18e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.146     |\n",
      "|    prior_loss         | 5.86e-06  |\n",
      "|    theta              | 0.133     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.2      |\n",
      "|    action 1 (%)       | 52.8      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.26      |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.57      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.6       |\n",
      "|    action 1 (%)       | 99.4      |\n",
      "|    avg_entropy        | 1.03e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.376    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -376      |\n",
      "|    neg_free_energy    | -0.376    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 146000    |\n",
      "|    fps                | 357       |\n",
      "|    num. episodes      | 396       |\n",
      "|    num. updates       | 381000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.44e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.115     |\n",
      "|    prior_loss         | 1.17e-06  |\n",
      "|    theta              | 0.115     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.2      |\n",
      "|    action 1 (%)       | 52.8      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.26      |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.58      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 1.5       |\n",
      "|    action 1 (%)       | 98.5      |\n",
      "|    avg_entropy        | 1.8e-06   |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.368    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -368      |\n",
      "|    neg_free_energy    | -0.368    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 147000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 397       |\n",
      "|    num. updates       | 382000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.47e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.111     |\n",
      "|    prior_loss         | 1.43e-05  |\n",
      "|    theta              | 0.131     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.2      |\n",
      "|    action 1 (%)       | 52.8      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.26      |\n",
      "|    fps                | 1.51e+03  |\n",
      "|    time               | 6.62      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 0.8       |\n",
      "|    action 1 (%)       | 99.2      |\n",
      "|    avg_entropy        | 1.21e-06  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.375    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -375      |\n",
      "|    neg_free_energy    | -0.375    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 148000    |\n",
      "|    fps                | 354       |\n",
      "|    num. episodes      | 398       |\n",
      "|    num. updates       | 383000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.41e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.15      |\n",
      "|    prior_loss         | 1.43e-06  |\n",
      "|    theta              | 0.145     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.2      |\n",
      "|    action 1 (%)       | 52.8      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 2.26      |\n",
      "|    fps                | 1.52e+03  |\n",
      "|    time               | 6.59      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 13.5      |\n",
      "|    action 1 (%)       | 86.5      |\n",
      "|    avg_entropy        | 1.15e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.275    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -275      |\n",
      "|    neg_free_energy    | -0.275    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 149000    |\n",
      "|    fps                | 359       |\n",
      "|    num. episodes      | 399       |\n",
      "|    num. updates       | 384000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.03e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.182     |\n",
      "|    prior_loss         | 0.000158  |\n",
      "|    theta              | 0.139     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    action 0 (%)       | 47.1      |\n",
      "|    action 1 (%)       | 52.9      |\n",
      "|    auc                | -5.42e+04 |\n",
      "|    avg_episode_length | 1e+03     |\n",
      "|    avg_reward         | 3.2       |\n",
      "|    fps                | 1.49e+03  |\n",
      "|    time               | 6.71      |\n",
      "| rollout/              |           |\n",
      "|    action 0 (%)       | 23.2      |\n",
      "|    action 1 (%)       | 76.8      |\n",
      "|    avg_entropy        | 1.92e-05  |\n",
      "|    avg_episode_length | 1000      |\n",
      "|    avg_reward_rate    | -0.203    |\n",
      "|    beta               | 1         |\n",
      "|    ep_reward          | -203      |\n",
      "|    neg_free_energy    | -0.203    |\n",
      "| time/                 |           |\n",
      "|    env. steps         | 150000    |\n",
      "|    fps                | 363       |\n",
      "|    num. episodes      | 400       |\n",
      "|    num. updates       | 385000    |\n",
      "| train/                |           |\n",
      "|    loss               | 1.11e+22  |\n",
      "|    lr                 | 0.0035    |\n",
      "|    new_theta          | 0.167     |\n",
      "|    prior_loss         | 4.07e-06  |\n",
      "|    theta              | 0.138     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continue training:\n",
    "model.env_steps = 0\n",
    "model.learn(total_timesteps=150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model:\n",
    "model.save(\"eval-ppi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
