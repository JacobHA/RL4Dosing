{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_env import CellEnv\n",
    "# Use sb3 env checker:\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO, DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CellEnv()\n",
    "check_env(env)\n",
    "env.reset()\n",
    "env.step(0)\n",
    "env.step(1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "\n",
    "# eval wrapper:\n",
    "env = TimeLimit(env, 1000)\n",
    "# use the monitor wrapper to log the results:\n",
    "env = Monitor(env)\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "eval_env = TimeLimit(CellEnv(), 1000)\n",
    "eval_env = Monitor(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./rl-logs/ppo_11\n",
      "Eval num_timesteps=1000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00486  |\n",
      "|    n_updates        | 249      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-82.80 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -82.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00532  |\n",
      "|    n_updates        | 499      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=4000, episode_reward=-364.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -365     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00926  |\n",
      "|    n_updates        | 749      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 4000     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-345.66 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -346     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 999      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-11.63 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -11.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 1249     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=7000, episode_reward=-114.33 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -114     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00837  |\n",
      "|    n_updates        | 1499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-142.66 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -143     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00561  |\n",
      "|    n_updates        | 1749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 8000     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-246.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -247     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00709  |\n",
      "|    n_updates        | 1999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-251.10 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -251     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00566  |\n",
      "|    n_updates        | 2249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=-188.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -189     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00904  |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-235.86 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -236     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 2749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 12000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=-350.08 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -350     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 13000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00669  |\n",
      "|    n_updates        | 2999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=-146.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -146     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00443  |\n",
      "|    n_updates        | 3249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-250.42 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -250     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00527  |\n",
      "|    n_updates        | 3499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-183.60 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -184     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 3749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -11.3    |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 16000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=-22.56 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 17000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 3999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=-94.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -94.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00597  |\n",
      "|    n_updates        | 4249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=-367.33 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -367     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 19000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00676  |\n",
      "|    n_updates        | 4499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-85.92 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -85.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 4749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=-52.97 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -53      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 21000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=-96.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -96.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00987  |\n",
      "|    n_updates        | 5249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=-366.44 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -366     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 23000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00814  |\n",
      "|    n_updates        | 5499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-53.01 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -53      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 5749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 24000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-38.50 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -38.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00602  |\n",
      "|    n_updates        | 5999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=-371.07 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -371     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00371  |\n",
      "|    n_updates        | 6249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=27000, episode_reward=-322.24 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -322     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 27000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 6499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=-5.10 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00448  |\n",
      "|    n_updates        | 6749     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 28000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=-315.60 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -316     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 29000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 6999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-37.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -37.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 7249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=-21.32 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -21.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 31000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=-127.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -127     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0056   |\n",
      "|    n_updates        | 7749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 32000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=33000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 33000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 7999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=-52.51 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -52.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 8249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-156.87 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -157     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00659  |\n",
      "|    n_updates        | 8499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00675  |\n",
      "|    n_updates        | 8749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.2    |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 36000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 37000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 8999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00964  |\n",
      "|    n_updates        | 9249     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 39000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00585  |\n",
      "|    n_updates        | 9499     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-380.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -381     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00485  |\n",
      "|    n_updates        | 9749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=41000, episode_reward=-376.23 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -376     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 41000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00524  |\n",
      "|    n_updates        | 10249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=43000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 43000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0076   |\n",
      "|    n_updates        | 10499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=-353.90 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -354     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00641  |\n",
      "|    n_updates        | 10749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.8    |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 44000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-378.86 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -379     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 10999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=-77.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -77.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00524  |\n",
      "|    n_updates        | 11249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=47000, episode_reward=-17.74 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -17.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 47000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 11499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-369.42 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -369     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00732  |\n",
      "|    n_updates        | 11749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 48000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=49000, episode_reward=-379.27 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -379     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 49000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0482   |\n",
      "|    n_updates        | 11999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-17.94 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -17.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00484  |\n",
      "|    n_updates        | 12249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=51000, episode_reward=-355.27 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -355     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 51000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=-378.83 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -379     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 52000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00475  |\n",
      "|    n_updates        | 12749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 52000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=53000, episode_reward=-373.42 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -373     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 53000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0066   |\n",
      "|    n_updates        | 12999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=-357.98 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -358     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 54000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 13249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-62.23 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -62.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00861  |\n",
      "|    n_updates        | 13499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=-19.93 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -19.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 56000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 13749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 56000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=57000, episode_reward=-9.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -9.75    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 57000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00523  |\n",
      "|    n_updates        | 13999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=-58.03 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -58      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 58000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00507  |\n",
      "|    n_updates        | 14249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=59000, episode_reward=-14.60 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 59000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 14499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-21.12 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -21.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 14749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=61000, episode_reward=-28.95 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -28.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 61000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00975  |\n",
      "|    n_updates        | 14999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=-97.57 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -97.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 62000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00563  |\n",
      "|    n_updates        | 15249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=63000, episode_reward=-15.27 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -15.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 63000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0462   |\n",
      "|    n_updates        | 15499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=-27.14 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -27.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 64000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00618  |\n",
      "|    n_updates        | 15749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -14.1    |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 64000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-37.66 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -37.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 15999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=-21.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -21.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 66000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 16249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=67000, episode_reward=-14.31 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 67000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 16499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=-378.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -379     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 68000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00719  |\n",
      "|    n_updates        | 16749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 68000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=69000, episode_reward=-23.87 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -23.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 69000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00695  |\n",
      "|    n_updates        | 16999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-12.04 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00983  |\n",
      "|    n_updates        | 17249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=71000, episode_reward=-91.41 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -91.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 71000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 17499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=-2.13 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.13    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 17749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -14.5    |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 72000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=73000, episode_reward=-13.71 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -13.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 73000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 17999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=-79.09 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -79.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 74000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00494  |\n",
      "|    n_updates        | 18249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-36.37 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -36.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 18499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=-23.54 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -23.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 76000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 18749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -14.9    |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 76000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=77000, episode_reward=-186.72 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -187     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 77000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0633   |\n",
      "|    n_updates        | 18999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=-285.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -286     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 78000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00562  |\n",
      "|    n_updates        | 19249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=79000, episode_reward=-72.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -72.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 79000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 19499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-24.81 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -24.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00781  |\n",
      "|    n_updates        | 19749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -15.1    |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 80000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=81000, episode_reward=-20.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -20.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 81000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 19999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=-9.57 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -9.57    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 82000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00532  |\n",
      "|    n_updates        | 20249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=83000, episode_reward=-152.19 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -152     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.685    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 83000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 20499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=-359.79 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -360     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00712  |\n",
      "|    n_updates        | 20749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -15.4    |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 84000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-117.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -117     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00566  |\n",
      "|    n_updates        | 20999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=86000, episode_reward=-83.44 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -83.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 86000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00927  |\n",
      "|    n_updates        | 21249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=87000, episode_reward=-19.81 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -19.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 87000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00444  |\n",
      "|    n_updates        | 21499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=-12.54 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 88000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00637  |\n",
      "|    n_updates        | 21749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -15.9    |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 88000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=89000, episode_reward=-24.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -24.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 89000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 21999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-74.26 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -74.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00846  |\n",
      "|    n_updates        | 22249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=91000, episode_reward=-380.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -380     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 91000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00611  |\n",
      "|    n_updates        | 22499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=-37.94 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -37.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 92000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 22749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -16.4    |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 92000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=93000, episode_reward=-175.66 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -176     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 93000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00806  |\n",
      "|    n_updates        | 22999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=-39.56 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -39.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 94000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0076   |\n",
      "|    n_updates        | 23249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-71.31 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -71.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 95000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 23499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=-41.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -41.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 96000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 23749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -16.9    |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 96000    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=97000, episode_reward=-106.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -106     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 97000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00445  |\n",
      "|    n_updates        | 23999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=-34.64 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -34.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 98000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 24249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=99000, episode_reward=-69.58 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -69.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 99000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 24499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-12.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 24749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -17.3    |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 100000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=101000, episode_reward=-152.15 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -152     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 101000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00723  |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=102000, episode_reward=-370.77 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -371     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 102000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 25249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=103000, episode_reward=-21.97 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 103000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00373  |\n",
      "|    n_updates        | 25499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=-10.65 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -10.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 104000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00751  |\n",
      "|    n_updates        | 25749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 104000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-317.12 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -317     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 105000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00698  |\n",
      "|    n_updates        | 25999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=106000, episode_reward=-32.83 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -32.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 106000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00832  |\n",
      "|    n_updates        | 26249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=107000, episode_reward=-2.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.36    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 107000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 26499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=-83.22 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -83.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 108000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00517  |\n",
      "|    n_updates        | 26749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -18.4    |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 108000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=109000, episode_reward=-380.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -381     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 109000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 26999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-380.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -381     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 110000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00932  |\n",
      "|    n_updates        | 27249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=111000, episode_reward=-26.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -26.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 111000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 27499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=-345.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -345     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 112000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00418  |\n",
      "|    n_updates        | 27749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -19.3    |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 112000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=113000, episode_reward=-43.78 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -43.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 113000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 27999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=114000, episode_reward=-29.28 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -29.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 114000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 28249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-32.10 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -32.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 115000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 28499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=-54.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -54.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 116000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 28749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -20.1    |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 116000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=117000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 117000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 28999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=118000, episode_reward=-56.74 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -56.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 118000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 29249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=119000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 119000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 29499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-28.79 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -28.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0869   |\n",
      "|    n_updates        | 29749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -20.8    |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 120000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=121000, episode_reward=-378.23 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -378     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 121000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 29999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=122000, episode_reward=-5.45 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.45    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 122000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00459  |\n",
      "|    n_updates        | 30249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=123000, episode_reward=-380.06 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -380     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 123000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00644  |\n",
      "|    n_updates        | 30499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=-22.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 124000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00645  |\n",
      "|    n_updates        | 30749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 124000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 125000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00903  |\n",
      "|    n_updates        | 30999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=126000, episode_reward=-317.55 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -318     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 126000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 31249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=127000, episode_reward=-47.48 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -47.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 127000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00694  |\n",
      "|    n_updates        | 31499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=-367.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -368     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 128000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00589  |\n",
      "|    n_updates        | 31749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -22.3    |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 128000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=129000, episode_reward=-83.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -83.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 129000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00831  |\n",
      "|    n_updates        | 31999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-17.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 130000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 32249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=131000, episode_reward=-29.26 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -29.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 131000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00711  |\n",
      "|    n_updates        | 32499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=-381.62 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -382     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 132000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00738  |\n",
      "|    n_updates        | 32749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -23.2    |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 132000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=133000, episode_reward=-38.82 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -38.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 133000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00511  |\n",
      "|    n_updates        | 32999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=134000, episode_reward=-46.65 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -46.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 134000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00737  |\n",
      "|    n_updates        | 33249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-37.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -37.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 135000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00408  |\n",
      "|    n_updates        | 33499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=-82.04 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -82      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 136000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00827  |\n",
      "|    n_updates        | 33749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -23.9    |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 136000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=137000, episode_reward=-8.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -8.53    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 137000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 33999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=138000, episode_reward=-23.63 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -23.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 138000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00705  |\n",
      "|    n_updates        | 34249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=139000, episode_reward=-81.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -81.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 139000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00776  |\n",
      "|    n_updates        | 34499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-120.31 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -120     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0091   |\n",
      "|    n_updates        | 34749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -24.6    |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total_timesteps  | 140000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=141000, episode_reward=-30.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -30.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 141000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00718  |\n",
      "|    n_updates        | 34999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=142000, episode_reward=-371.86 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -372     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 142000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0529   |\n",
      "|    n_updates        | 35249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=143000, episode_reward=-20.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -20.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 143000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 35499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=-353.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -354     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 144000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 35749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -25.2    |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 378      |\n",
      "|    total_timesteps  | 144000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-85.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -85.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 145000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 35999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=146000, episode_reward=-375.37 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -375     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.445    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 146000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 36249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=147000, episode_reward=-18.04 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -18      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 147000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 36499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=-22.43 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 148000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00737  |\n",
      "|    n_updates        | 36749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -25.8    |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 388      |\n",
      "|    total_timesteps  | 148000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=149000, episode_reward=-16.71 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -16.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 149000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00941  |\n",
      "|    n_updates        | 36999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-30.72 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -30.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00822  |\n",
      "|    n_updates        | 37249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=151000, episode_reward=-47.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -47.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 151000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00862  |\n",
      "|    n_updates        | 37499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=-22.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 152000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 37749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.6    |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 399      |\n",
      "|    total_timesteps  | 152000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=153000, episode_reward=-22.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 153000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00803  |\n",
      "|    n_updates        | 37999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=154000, episode_reward=-80.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -80.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 154000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0084   |\n",
      "|    n_updates        | 38249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-22.19 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -22.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 155000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0089   |\n",
      "|    n_updates        | 38499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=156000, episode_reward=-24.31 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -24.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 156000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 38749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.6    |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 410      |\n",
      "|    total_timesteps  | 156000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=157000, episode_reward=-27.24 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -27.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 157000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 38999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=158000, episode_reward=-38.57 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -38.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.4      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 158000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 39249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=159000, episode_reward=-17.17 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -17.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 159000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 39499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-10.86 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -10.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00938  |\n",
      "|    n_updates        | 39749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.6    |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 420      |\n",
      "|    total_timesteps  | 160000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=161000, episode_reward=-151.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -152     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 161000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00902  |\n",
      "|    n_updates        | 39999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=162000, episode_reward=-23.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -23.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 162000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 40249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=163000, episode_reward=-19.29 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -19.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 163000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 40499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=-16.42 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -16.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 164000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00877  |\n",
      "|    n_updates        | 40749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.8    |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 431      |\n",
      "|    total_timesteps  | 164000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-25.14 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -25.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 165000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00946  |\n",
      "|    n_updates        | 40999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=166000, episode_reward=-34.67 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -34.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 166000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 41249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=167000, episode_reward=-377.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -377     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 167000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 41499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=-8.82 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -8.82    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 168000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00868  |\n",
      "|    n_updates        | 41749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.8    |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 441      |\n",
      "|    total_timesteps  | 168000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=169000, episode_reward=-138.86 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -139     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 169000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 41999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-59.84 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -59.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 170000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00873  |\n",
      "|    n_updates        | 42249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=171000, episode_reward=-16.68 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -16.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 171000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00694  |\n",
      "|    n_updates        | 42499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=-1.97 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.97    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 172000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00978  |\n",
      "|    n_updates        | 42749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -27      |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 452      |\n",
      "|    total_timesteps  | 172000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=173000, episode_reward=-10.66 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -10.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.343    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 173000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 42999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=174000, episode_reward=-6.57 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -6.57    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 174000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00841  |\n",
      "|    n_updates        | 43249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-26.81 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -26.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 175000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 43499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=-5.59 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.59    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 176000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 43749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.9    |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 462      |\n",
      "|    total_timesteps  | 176000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=177000, episode_reward=-42.71 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -42.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 177000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 43999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=178000, episode_reward=-2.79 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.79    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.324    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 178000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00889  |\n",
      "|    n_updates        | 44249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=179000, episode_reward=-14.26 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 179000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 44499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-9.86 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -9.86    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00675  |\n",
      "|    n_updates        | 44749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.8    |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 473      |\n",
      "|    total_timesteps  | 180000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=181000, episode_reward=-14.57 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 181000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 44999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=182000, episode_reward=-33.24 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -33.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 182000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00826  |\n",
      "|    n_updates        | 45249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=183000, episode_reward=-56.03 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -56      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 183000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00931  |\n",
      "|    n_updates        | 45499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=-36.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -36.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 184000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 45749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.8    |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 484      |\n",
      "|    total_timesteps  | 184000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-82.10 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -82.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 185000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 45999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=186000, episode_reward=-23.50 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -23.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 186000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00881  |\n",
      "|    n_updates        | 46249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=187000, episode_reward=-7.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.89    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 187000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 46499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=188000, episode_reward=-7.10 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 188000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 46749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -26.4    |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 495      |\n",
      "|    total_timesteps  | 188000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=189000, episode_reward=-6.31 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -6.31    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 189000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 46999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-1.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.53    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 190000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 47249    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=191000, episode_reward=-46.47 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -46.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 191000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 47499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=-1.73 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.73    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.27     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 192000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 47749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -25.8    |\n",
      "|    exploration_rate | 0.27     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 505      |\n",
      "|    total_timesteps  | 192000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=193000, episode_reward=-7.92 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.92    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 193000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 47999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=194000, episode_reward=-1.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.61    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 194000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 48249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-15.51 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -15.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 195000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 48499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=0.12 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.124    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 196000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 48749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -25.8    |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 515      |\n",
      "|    total_timesteps  | 196000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=197000, episode_reward=-7.77 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.77    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 197000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00695  |\n",
      "|    n_updates        | 48999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=198000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.00529  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 198000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 49249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=199000, episode_reward=-232.51 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -233     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.244    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 199000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 49499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-12.07 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00878  |\n",
      "|    n_updates        | 49749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -25.4    |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 525      |\n",
      "|    total_timesteps  | 200000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=201000, episode_reward=-11.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 201000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 49999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=202000, episode_reward=-18.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -18.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.232    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 202000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0095   |\n",
      "|    n_updates        | 50249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=203000, episode_reward=-14.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 203000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00795  |\n",
      "|    n_updates        | 50499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=204000, episode_reward=-6.57 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -6.57    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 204000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 50749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -24.7    |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 536      |\n",
      "|    total_timesteps  | 204000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=-6.93 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -6.93    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 205000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 50999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=206000, episode_reward=-6.52 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -6.52    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 206000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 51249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=207000, episode_reward=-14.23 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -14.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 207000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00815  |\n",
      "|    n_updates        | 51499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=-13.71 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -13.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 208000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00797  |\n",
      "|    n_updates        | 51749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -24.1    |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 546      |\n",
      "|    total_timesteps  | 208000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=209000, episode_reward=-7.21 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7.21    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.206    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 209000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 51999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-3.90 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 210000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 52249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=211000, episode_reward=-4.41 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.41    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 211000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 52499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=212000, episode_reward=-4.68 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.68    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 212000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 52749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -23.2    |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 557      |\n",
      "|    total_timesteps  | 212000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=213000, episode_reward=-8.79 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -8.79    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.191    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 213000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00938  |\n",
      "|    n_updates        | 52999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=214000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 214000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 53249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-11.12 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -11.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 215000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 53499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=216000, episode_reward=-2.34 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.34    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 216000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0098   |\n",
      "|    n_updates        | 53749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -22.2    |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 568      |\n",
      "|    total_timesteps  | 216000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=217000, episode_reward=-1.10 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 217000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 53999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=218000, episode_reward=-8.21 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -8.21    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.172    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 218000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 54249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=219000, episode_reward=-10.05 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 219000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 54499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.695    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 54749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -21.4    |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 579      |\n",
      "|    total_timesteps  | 220000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=221000, episode_reward=-1.88 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.88    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.16     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 221000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 54999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=222000, episode_reward=-1.43 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.43    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 222000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 55249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=223000, episode_reward=-2.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.25    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 223000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 55499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=3.04 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.04     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 224000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00708  |\n",
      "|    n_updates        | 55749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -20.4    |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 590      |\n",
      "|    total_timesteps  | 224000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-2.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.36    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 225000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00574  |\n",
      "|    n_updates        | 55999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=226000, episode_reward=2.54 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.54     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.141    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 226000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00796  |\n",
      "|    n_updates        | 56249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=227000, episode_reward=-12.06 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 227000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00949  |\n",
      "|    n_updates        | 56499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=228000, episode_reward=-1.28 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.28    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 228000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 56749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -19.1    |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 601      |\n",
      "|    total_timesteps  | 228000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=229000, episode_reward=-11.66 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -11.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 229000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 56999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=0.22 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.219    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 230000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 57249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=231000, episode_reward=-5.04 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.04    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.122    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 231000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 57499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=232000, episode_reward=2.86 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.86     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 232000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00475  |\n",
      "|    n_updates        | 57749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -17.9    |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 612      |\n",
      "|    total_timesteps  | 232000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=233000, episode_reward=0.90 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.897    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.115    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 233000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 57999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=234000, episode_reward=3.82 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.82     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.111    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 234000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00916  |\n",
      "|    n_updates        | 58249    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=235000, episode_reward=-2.81 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.81    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 235000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 58499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=236000, episode_reward=3.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.76     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 236000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00516  |\n",
      "|    n_updates        | 58749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -16.8    |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 623      |\n",
      "|    total_timesteps  | 236000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=237000, episode_reward=3.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0994   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 237000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 58999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=238000, episode_reward=-0.33 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.334   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0956   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 238000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 59249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=239000, episode_reward=0.26 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.264    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0918   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 239000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 59499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-2.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.16    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.088    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 59749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -15.6    |\n",
      "|    exploration_rate | 0.088    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 634      |\n",
      "|    total_timesteps  | 240000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=241000, episode_reward=-2.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.25    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0842   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 241000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 59999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=242000, episode_reward=3.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0804   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 242000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 60249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=243000, episode_reward=2.41 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.41     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0766   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 243000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 60499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=244000, episode_reward=2.95 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.95     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0728   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 244000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 60749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -14.4    |\n",
      "|    exploration_rate | 0.0728   |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 645      |\n",
      "|    total_timesteps  | 244000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=3.38 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.38     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.069    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 245000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00939  |\n",
      "|    n_updates        | 60999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=246000, episode_reward=1.64 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.64     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0652   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 246000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 61249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=247000, episode_reward=4.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.46     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0614   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 247000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.007    |\n",
      "|    n_updates        | 61499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=248000, episode_reward=3.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0576   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 248000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0041   |\n",
      "|    n_updates        | 61749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.0576   |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 655      |\n",
      "|    total_timesteps  | 248000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=249000, episode_reward=-0.06 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.0618  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0538   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 249000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 61999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=2.30 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.3      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 62249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=251000, episode_reward=2.93 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.93     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 251000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00526  |\n",
      "|    n_updates        | 62499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=252000, episode_reward=3.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.16     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 252000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 62749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 667      |\n",
      "|    total_timesteps  | 252000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=253000, episode_reward=1.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 253000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00466  |\n",
      "|    n_updates        | 62999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=254000, episode_reward=-4.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.16    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 254000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0054   |\n",
      "|    n_updates        | 63249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=1.77 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.77     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 255000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00547  |\n",
      "|    n_updates        | 63499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=-5.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.16    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 256000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 63749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 678      |\n",
      "|    total_timesteps  | 256000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=257000, episode_reward=3.17 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.17     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 257000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 63999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=258000, episode_reward=3.72 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.72     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 258000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 64249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=259000, episode_reward=3.06 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.06     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 259000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 64499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=4.51 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.51     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 260000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00684  |\n",
      "|    n_updates        | 64749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -10.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 689      |\n",
      "|    total_timesteps  | 260000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=261000, episode_reward=-3.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 261000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 64999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=262000, episode_reward=0.05 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.0487   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 262000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 65249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=263000, episode_reward=1.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.39     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 263000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 65499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=264000, episode_reward=-4.01 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.01    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 264000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 65749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 700      |\n",
      "|    total_timesteps  | 264000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=1.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.76     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 265000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 65999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=266000, episode_reward=4.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.49     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 266000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 66249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=267000, episode_reward=2.40 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 267000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00497  |\n",
      "|    n_updates        | 66499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=268000, episode_reward=5.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.18     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 268000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 66749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 710      |\n",
      "|    total_timesteps  | 268000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=269000, episode_reward=2.91 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.91     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 269000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 66999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=3.55 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.55     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 270000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 67249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=271000, episode_reward=3.29 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.29     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 271000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 67499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=3.96 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.96     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 272000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00322  |\n",
      "|    n_updates        | 67749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 721      |\n",
      "|    total_timesteps  | 272000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=273000, episode_reward=-1.08 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.08    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 273000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 67999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=274000, episode_reward=-2.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.89    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 274000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00547  |\n",
      "|    n_updates        | 68249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=1.96 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.96     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 275000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 68499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=276000, episode_reward=2.72 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.72     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 276000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 68749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -7.48    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 732      |\n",
      "|    total_timesteps  | 276000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=277000, episode_reward=3.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 277000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 68999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=278000, episode_reward=3.54 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.54     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 278000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 69249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=279000, episode_reward=4.52 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 279000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 69499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=2.05 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.05     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 280000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000514 |\n",
      "|    n_updates        | 69749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -6.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 742      |\n",
      "|    total_timesteps  | 280000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=281000, episode_reward=1.31 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.31     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 281000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 69999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=282000, episode_reward=1.82 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.82     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 282000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 70249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=283000, episode_reward=-30.45 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -30.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 283000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 70499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=284000, episode_reward=-2.07 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.07    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 284000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 70749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -6.09    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 754      |\n",
      "|    total_timesteps  | 284000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 285000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 70999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=286000, episode_reward=2.94 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.94     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 286000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 71249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=287000, episode_reward=-2.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.49    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 287000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000939 |\n",
      "|    n_updates        | 71499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=2.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.25     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 288000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 71749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -5.48    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 764      |\n",
      "|    total_timesteps  | 288000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=289000, episode_reward=2.41 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.41     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 289000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 71999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-0.30 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.296   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 290000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 72249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=291000, episode_reward=-4.80 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 291000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000291 |\n",
      "|    n_updates        | 72499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=292000, episode_reward=3.02 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.02     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 292000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 72749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -4.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 775      |\n",
      "|    total_timesteps  | 292000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=293000, episode_reward=-0.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.247   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 293000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000899 |\n",
      "|    n_updates        | 72999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=294000, episode_reward=3.17 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.17     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 294000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000626 |\n",
      "|    n_updates        | 73249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=-2.52 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.52    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 295000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000379 |\n",
      "|    n_updates        | 73499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=296000, episode_reward=2.22 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.22     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 296000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000909 |\n",
      "|    n_updates        | 73749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -3.75    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 786      |\n",
      "|    total_timesteps  | 296000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=297000, episode_reward=0.45 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.454    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 297000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 73999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=298000, episode_reward=1.03 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.03     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 298000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000685 |\n",
      "|    n_updates        | 74249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=299000, episode_reward=3.14 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.14     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 299000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 74499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=4.29 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.29     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000286 |\n",
      "|    n_updates        | 74749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -3.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 797      |\n",
      "|    total_timesteps  | 300000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=301000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.00211  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 301000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 74999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=302000, episode_reward=2.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.16     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 302000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000155 |\n",
      "|    n_updates        | 75249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=303000, episode_reward=4.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 303000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000611 |\n",
      "|    n_updates        | 75499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=-2.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.75    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 304000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000146 |\n",
      "|    n_updates        | 75749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 808      |\n",
      "|    total_timesteps  | 304000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=305000, episode_reward=-4.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.76    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 305000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 75999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=306000, episode_reward=4.07 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.07     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 306000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0002   |\n",
      "|    n_updates        | 76249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=307000, episode_reward=-363.98 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -364     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 307000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00039  |\n",
      "|    n_updates        | 76499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=308000, episode_reward=1.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.36     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 308000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 76749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -3.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 820      |\n",
      "|    total_timesteps  | 308000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=309000, episode_reward=4.68 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.68     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 309000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00348  |\n",
      "|    n_updates        | 76999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-0.35 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.353   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 310000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 77249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=311000, episode_reward=3.67 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.67     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 311000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00068  |\n",
      "|    n_updates        | 77499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=312000, episode_reward=4.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.36     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 312000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000234 |\n",
      "|    n_updates        | 77749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -3.28    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 831      |\n",
      "|    total_timesteps  | 312000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=313000, episode_reward=-0.23 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.232   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 313000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 77999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=314000, episode_reward=3.84 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.84     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 314000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000512 |\n",
      "|    n_updates        | 78249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=3.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.18     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 315000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000407 |\n",
      "|    n_updates        | 78499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=316000, episode_reward=3.34 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.34     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 316000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000282 |\n",
      "|    n_updates        | 78749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -3.03    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 842      |\n",
      "|    total_timesteps  | 316000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=317000, episode_reward=3.43 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.43     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 317000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000529 |\n",
      "|    n_updates        | 78999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=318000, episode_reward=3.96 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.96     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 318000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000248 |\n",
      "|    n_updates        | 79249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=319000, episode_reward=4.43 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.43     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 319000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000503 |\n",
      "|    n_updates        | 79499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=3.73 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.73     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 320000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000284 |\n",
      "|    n_updates        | 79749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 852      |\n",
      "|    total_timesteps  | 320000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=321000, episode_reward=0.73 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.732    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 321000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000251 |\n",
      "|    n_updates        | 79999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=322000, episode_reward=2.98 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.98     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 322000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000149 |\n",
      "|    n_updates        | 80249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=323000, episode_reward=0.50 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.501    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 323000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000484 |\n",
      "|    n_updates        | 80499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=324000, episode_reward=-0.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.488   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 324000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00294  |\n",
      "|    n_updates        | 80749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 863      |\n",
      "|    total_timesteps  | 324000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=-2.85 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.85    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 325000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000297 |\n",
      "|    n_updates        | 80999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=326000, episode_reward=2.94 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.94     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 326000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000762 |\n",
      "|    n_updates        | 81249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=327000, episode_reward=-29.59 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -29.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 327000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 81499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=328000, episode_reward=3.94 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.94     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 328000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000221 |\n",
      "|    n_updates        | 81749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.93    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 874      |\n",
      "|    total_timesteps  | 328000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=329000, episode_reward=3.60 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 329000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000112 |\n",
      "|    n_updates        | 81999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=4.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.46     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 330000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 82249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=331000, episode_reward=-13.15 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -13.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 331000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000219 |\n",
      "|    n_updates        | 82499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=332000, episode_reward=-3.64 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.64    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 332000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 82749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 885      |\n",
      "|    total_timesteps  | 332000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=333000, episode_reward=2.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.49     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 333000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000124 |\n",
      "|    n_updates        | 82999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=334000, episode_reward=1.69 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.69     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 334000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000332 |\n",
      "|    n_updates        | 83249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=0.19 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.187    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 335000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 83499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=-0.77 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.77    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 336000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 83749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.68    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 896      |\n",
      "|    total_timesteps  | 336000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=337000, episode_reward=4.83 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.83     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 337000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000116 |\n",
      "|    n_updates        | 83999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=338000, episode_reward=4.26 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.26     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 338000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000997 |\n",
      "|    n_updates        | 84249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=339000, episode_reward=-0.56 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.562   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 339000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000135 |\n",
      "|    n_updates        | 84499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=3.33 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.33     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 340000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000263 |\n",
      "|    n_updates        | 84749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.67    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 907      |\n",
      "|    total_timesteps  | 340000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=341000, episode_reward=0.90 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.903    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 341000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 84999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=342000, episode_reward=3.98 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.98     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 342000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000254 |\n",
      "|    n_updates        | 85249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=343000, episode_reward=-89.73 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -89.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 343000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000167 |\n",
      "|    n_updates        | 85499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=344000, episode_reward=4.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 344000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000503 |\n",
      "|    n_updates        | 85749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.62    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 918      |\n",
      "|    total_timesteps  | 344000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=4.41 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.41     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 345000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000161 |\n",
      "|    n_updates        | 85999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=346000, episode_reward=1.15 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.15     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 346000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000129 |\n",
      "|    n_updates        | 86249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=347000, episode_reward=3.07 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.07     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 347000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 86499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=348000, episode_reward=4.93 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.93     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 348000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000116 |\n",
      "|    n_updates        | 86749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.28    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 928      |\n",
      "|    total_timesteps  | 348000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=349000, episode_reward=4.59 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.59     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 349000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000168 |\n",
      "|    n_updates        | 86999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=2.72 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.72     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000863 |\n",
      "|    n_updates        | 87249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=351000, episode_reward=2.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.53     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 351000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 87499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=5.71 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.71     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 352000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000728 |\n",
      "|    n_updates        | 87749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.01    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 940      |\n",
      "|    total_timesteps  | 352000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=353000, episode_reward=4.03 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.03     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 353000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 87999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=354000, episode_reward=3.37 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.37     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 354000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000215 |\n",
      "|    n_updates        | 88249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=3.94 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.94     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 355000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000816 |\n",
      "|    n_updates        | 88499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=356000, episode_reward=3.90 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.9      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 356000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000761 |\n",
      "|    n_updates        | 88749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 950      |\n",
      "|    total_timesteps  | 356000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=357000, episode_reward=3.60 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 357000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000485 |\n",
      "|    n_updates        | 88999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=358000, episode_reward=3.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 358000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000184 |\n",
      "|    n_updates        | 89249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=359000, episode_reward=-1.44 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.44    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 359000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 89499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=5.42 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.42     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 360000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000544 |\n",
      "|    n_updates        | 89749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -1.86    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 961      |\n",
      "|    total_timesteps  | 360000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=361000, episode_reward=5.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 361000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 89999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=362000, episode_reward=4.47 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.47     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 362000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000727 |\n",
      "|    n_updates        | 90249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=363000, episode_reward=4.79 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.79     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 363000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000789 |\n",
      "|    n_updates        | 90499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=364000, episode_reward=3.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 364000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 7.05e-05 |\n",
      "|    n_updates        | 90749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -1.83    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 972      |\n",
      "|    total_timesteps  | 364000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=4.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.53     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 365000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 90999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=366000, episode_reward=4.02 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.02     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 366000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000139 |\n",
      "|    n_updates        | 91249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=367000, episode_reward=4.43 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.43     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 367000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000162 |\n",
      "|    n_updates        | 91499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=4.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 368000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000359 |\n",
      "|    n_updates        | 91749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.73    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 983      |\n",
      "|    total_timesteps  | 368000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=369000, episode_reward=4.41 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.41     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 369000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000422 |\n",
      "|    n_updates        | 91999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=5.08 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.08     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 370000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00016  |\n",
      "|    n_updates        | 92249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=371000, episode_reward=4.30 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.3      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 371000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000885 |\n",
      "|    n_updates        | 92499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=372000, episode_reward=3.13 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.13     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 372000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 92749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 994      |\n",
      "|    total_timesteps  | 372000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=373000, episode_reward=-2.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.89    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 373000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000305 |\n",
      "|    n_updates        | 92999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=374000, episode_reward=4.60 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 374000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000148 |\n",
      "|    n_updates        | 93249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=5.04 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.04     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 375000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000149 |\n",
      "|    n_updates        | 93499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=376000, episode_reward=-1.58 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.58    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 376000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 93749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.57    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1005     |\n",
      "|    total_timesteps  | 376000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=377000, episode_reward=2.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.36     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 377000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 93999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=378000, episode_reward=5.51 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.51     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 378000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 94249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=379000, episode_reward=1.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.7      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 379000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 94499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=4.70 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.7      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 380000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000231 |\n",
      "|    n_updates        | 94749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.71    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1016     |\n",
      "|    total_timesteps  | 380000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=381000, episode_reward=4.13 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.13     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 381000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 94999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=382000, episode_reward=5.19 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.19     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 382000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000257 |\n",
      "|    n_updates        | 95249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=383000, episode_reward=1.19 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.19     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 383000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00587  |\n",
      "|    n_updates        | 95499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=3.07 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.07     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 384000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 95749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.79    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1027     |\n",
      "|    total_timesteps  | 384000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=3.65 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.65     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 385000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000458 |\n",
      "|    n_updates        | 95999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=386000, episode_reward=1.71 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.71     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 386000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000279 |\n",
      "|    n_updates        | 96249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=387000, episode_reward=2.26 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.26     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 387000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000467 |\n",
      "|    n_updates        | 96499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=388000, episode_reward=2.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.75     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 388000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000764 |\n",
      "|    n_updates        | 96749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1038     |\n",
      "|    total_timesteps  | 388000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=389000, episode_reward=3.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.89     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 389000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000299 |\n",
      "|    n_updates        | 96999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=1.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 390000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 97249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=391000, episode_reward=3.88 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.88     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 391000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000114 |\n",
      "|    n_updates        | 97499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=392000, episode_reward=3.80 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.8      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 392000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 97749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.55    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1049     |\n",
      "|    total_timesteps  | 392000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=393000, episode_reward=1.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.49     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 393000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000818 |\n",
      "|    n_updates        | 97999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=394000, episode_reward=-3.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -3.18    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 394000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000336 |\n",
      "|    n_updates        | 98249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=3.69 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.69     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 395000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000867 |\n",
      "|    n_updates        | 98499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=396000, episode_reward=4.19 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.19     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 396000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000157 |\n",
      "|    n_updates        | 98749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.49    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1060     |\n",
      "|    total_timesteps  | 396000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=397000, episode_reward=1.04 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.04     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 397000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000201 |\n",
      "|    n_updates        | 98999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=398000, episode_reward=4.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.18     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 398000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 99249    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=399000, episode_reward=3.12 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.12     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 399000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000527 |\n",
      "|    n_updates        | 99499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=2.74 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.74     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 99749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.35    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1071     |\n",
      "|    total_timesteps  | 400000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=401000, episode_reward=1.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.53     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 401000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000377 |\n",
      "|    n_updates        | 99999    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=402000, episode_reward=5.45 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.45     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 402000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 100249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=403000, episode_reward=5.32 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.32     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 403000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000706 |\n",
      "|    n_updates        | 100499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=404000, episode_reward=2.91 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.91     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 404000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 100749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -2.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1082     |\n",
      "|    total_timesteps  | 404000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.967    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 405000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000199 |\n",
      "|    n_updates        | 100999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=406000, episode_reward=4.37 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.37     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 406000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 101249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=407000, episode_reward=3.97 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.97     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 407000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000325 |\n",
      "|    n_updates        | 101499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=408000, episode_reward=3.68 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.68     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 408000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 101749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -0.735   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1093     |\n",
      "|    total_timesteps  | 408000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=409000, episode_reward=4.85 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.85     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 409000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000127 |\n",
      "|    n_updates        | 101999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=4.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.89     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 410000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 102249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=411000, episode_reward=3.83 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.83     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 411000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000241 |\n",
      "|    n_updates        | 102499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=412000, episode_reward=4.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.39     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 412000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000873 |\n",
      "|    n_updates        | 102749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -0.842   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 1104     |\n",
      "|    total_timesteps  | 412000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=413000, episode_reward=-1.33 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.33    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 413000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000763 |\n",
      "|    n_updates        | 102999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=414000, episode_reward=3.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.39     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 414000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 103249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=4.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.39     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 415000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000513 |\n",
      "|    n_updates        | 103499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=-5.07 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.07    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 416000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000297 |\n",
      "|    n_updates        | 103749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -0.742   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1115     |\n",
      "|    total_timesteps  | 416000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=417000, episode_reward=5.44 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.44     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 417000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 103999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=418000, episode_reward=4.40 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 418000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00026  |\n",
      "|    n_updates        | 104249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=419000, episode_reward=4.37 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.37     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 419000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00077  |\n",
      "|    n_updates        | 104499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=4.65 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.65     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 420000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000137 |\n",
      "|    n_updates        | 104749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -0.283   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1126     |\n",
      "|    total_timesteps  | 420000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=421000, episode_reward=5.05 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.05     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 421000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000101 |\n",
      "|    n_updates        | 104999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=422000, episode_reward=3.67 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.67     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 422000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000331 |\n",
      "|    n_updates        | 105249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=423000, episode_reward=-2.68 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -2.68    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 423000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000225 |\n",
      "|    n_updates        | 105499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=424000, episode_reward=4.25 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.25     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 424000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000105 |\n",
      "|    n_updates        | 105749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | -0.104   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1137     |\n",
      "|    total_timesteps  | 424000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=2.26 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.26     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 425000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 6.91e-05 |\n",
      "|    n_updates        | 105999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=426000, episode_reward=5.55 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.55     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 426000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 106249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=427000, episode_reward=4.83 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.83     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 427000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000228 |\n",
      "|    n_updates        | 106499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=428000, episode_reward=3.53 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.53     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 428000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000159 |\n",
      "|    n_updates        | 106749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.208    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1148     |\n",
      "|    total_timesteps  | 428000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=429000, episode_reward=4.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 429000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000537 |\n",
      "|    n_updates        | 106999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-1.19 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -1.19    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 430000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 107249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=431000, episode_reward=3.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.61     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 431000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000208 |\n",
      "|    n_updates        | 107499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=3.41 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.41     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 432000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 107749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.384    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1159     |\n",
      "|    total_timesteps  | 432000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=433000, episode_reward=3.92 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.92     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 433000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000111 |\n",
      "|    n_updates        | 107999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=434000, episode_reward=4.59 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.59     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 434000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000106 |\n",
      "|    n_updates        | 108249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=435000, episode_reward=4.16 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.16     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 435000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000293 |\n",
      "|    n_updates        | 108499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=436000, episode_reward=5.34 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.34     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 436000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000151 |\n",
      "|    n_updates        | 108749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.419    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1170     |\n",
      "|    total_timesteps  | 436000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=437000, episode_reward=4.99 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.99     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 437000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000125 |\n",
      "|    n_updates        | 108999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=438000, episode_reward=4.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.39     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 438000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000379 |\n",
      "|    n_updates        | 109249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=439000, episode_reward=1.81 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 1.81     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 439000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00026  |\n",
      "|    n_updates        | 109499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.84     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 440000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000553 |\n",
      "|    n_updates        | 109749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.597    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1181     |\n",
      "|    total_timesteps  | 440000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=441000, episode_reward=3.38 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.38     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 441000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000211 |\n",
      "|    n_updates        | 109999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=442000, episode_reward=2.36 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.36     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 442000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000199 |\n",
      "|    n_updates        | 110249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=443000, episode_reward=-335.46 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -335     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 443000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000158 |\n",
      "|    n_updates        | 110499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=444000, episode_reward=2.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.75     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 444000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000182 |\n",
      "|    n_updates        | 110749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.724    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1192     |\n",
      "|    total_timesteps  | 444000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=5.35 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.35     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 445000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 5.18e-05 |\n",
      "|    n_updates        | 110999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=446000, episode_reward=5.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.89     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 446000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000905 |\n",
      "|    n_updates        | 111249   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=447000, episode_reward=2.42 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.42     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 447000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000347 |\n",
      "|    n_updates        | 111499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=4.67 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.67     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 448000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000344 |\n",
      "|    n_updates        | 111749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.713    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1203     |\n",
      "|    total_timesteps  | 448000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=449000, episode_reward=2.96 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.96     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 449000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 6.79e-05 |\n",
      "|    n_updates        | 111999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-0.56 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -0.557   |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000557 |\n",
      "|    n_updates        | 112249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=451000, episode_reward=4.54 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.54     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 451000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000549 |\n",
      "|    n_updates        | 112499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=452000, episode_reward=3.88 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.88     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 452000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000162 |\n",
      "|    n_updates        | 112749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.769    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1214     |\n",
      "|    total_timesteps  | 452000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=453000, episode_reward=2.99 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.99     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 453000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000221 |\n",
      "|    n_updates        | 112999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=454000, episode_reward=4.51 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.51     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 454000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 9.11e-05 |\n",
      "|    n_updates        | 113249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=3.95 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.95     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 455000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000157 |\n",
      "|    n_updates        | 113499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=456000, episode_reward=4.89 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.89     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 456000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 113749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.846    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1225     |\n",
      "|    total_timesteps  | 456000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=457000, episode_reward=4.02 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.02     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 457000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000187 |\n",
      "|    n_updates        | 113999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=458000, episode_reward=4.79 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.79     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 458000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000748 |\n",
      "|    n_updates        | 114249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=459000, episode_reward=4.12 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.12     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 459000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 114499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=5.02 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.02     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 460000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000245 |\n",
      "|    n_updates        | 114749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.794    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1236     |\n",
      "|    total_timesteps  | 460000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=461000, episode_reward=3.49 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.49     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 461000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 9.29e-05 |\n",
      "|    n_updates        | 114999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=462000, episode_reward=3.34 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.34     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 462000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 115249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=463000, episode_reward=5.37 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 5.37     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 463000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000167 |\n",
      "|    n_updates        | 115499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=4.59 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.59     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 464000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000213 |\n",
      "|    n_updates        | 115749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 1247     |\n",
      "|    total_timesteps  | 464000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=4.21 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.21     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 465000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000268 |\n",
      "|    n_updates        | 115999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=466000, episode_reward=3.81 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.81     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 466000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00045  |\n",
      "|    n_updates        | 116249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=467000, episode_reward=3.58 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.58     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 467000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000196 |\n",
      "|    n_updates        | 116499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=468000, episode_reward=-6.90 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -6.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 468000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00064  |\n",
      "|    n_updates        | 116749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 1.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 1258     |\n",
      "|    total_timesteps  | 468000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=469000, episode_reward=3.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.76     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 469000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000344 |\n",
      "|    n_updates        | 116999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=0.94 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 0.942    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 470000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000504 |\n",
      "|    n_updates        | 117249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=471000, episode_reward=4.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.18     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 471000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000228 |\n",
      "|    n_updates        | 117499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=472000, episode_reward=4.13 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.13     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 472000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 117749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 1.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 1269     |\n",
      "|    total_timesteps  | 472000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=473000, episode_reward=-290.14 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -290     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 473000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000339 |\n",
      "|    n_updates        | 117999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=474000, episode_reward=3.45 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.45     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 474000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000188 |\n",
      "|    n_updates        | 118249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=4.76 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.76     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 475000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000419 |\n",
      "|    n_updates        | 118499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=476000, episode_reward=4.48 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.48     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 476000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000396 |\n",
      "|    n_updates        | 118749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 1.71     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 1280     |\n",
      "|    total_timesteps  | 476000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=477000, episode_reward=4.64 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.64     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 477000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000391 |\n",
      "|    n_updates        | 118999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=478000, episode_reward=3.93 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.93     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 478000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00058  |\n",
      "|    n_updates        | 119249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=479000, episode_reward=4.59 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.59     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 479000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 6.22e-05 |\n",
      "|    n_updates        | 119499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=3.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.39     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 480000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 9.4e-05  |\n",
      "|    n_updates        | 119749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 2.07     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 1290     |\n",
      "|    total_timesteps  | 480000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=481000, episode_reward=2.78 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 2.78     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 481000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000278 |\n",
      "|    n_updates        | 119999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=482000, episode_reward=3.43 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.43     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 482000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 120249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=483000, episode_reward=4.39 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.39     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 483000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000175 |\n",
      "|    n_updates        | 120499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=484000, episode_reward=4.18 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.18     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 484000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 6.8e-05  |\n",
      "|    n_updates        | 120749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 2.22     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 1301     |\n",
      "|    total_timesteps  | 484000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=485000, episode_reward=-4.38 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -4.38    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 485000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000109 |\n",
      "|    n_updates        | 120999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=486000, episode_reward=4.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.75     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 486000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000103 |\n",
      "|    n_updates        | 121249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=487000, episode_reward=3.91 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.91     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 487000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 121499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=488000, episode_reward=3.81 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.81     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 488000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 121749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 2.23     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1311     |\n",
      "|    total_timesteps  | 488000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=489000, episode_reward=3.60 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 489000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 121999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=4.31 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.31     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 490000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000419 |\n",
      "|    n_updates        | 122249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=491000, episode_reward=4.48 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.48     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 491000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000456 |\n",
      "|    n_updates        | 122499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=492000, episode_reward=3.90 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.9      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 492000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 8.42e-05 |\n",
      "|    n_updates        | 122749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 2.29     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1322     |\n",
      "|    total_timesteps  | 492000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=493000, episode_reward=4.61 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.61     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 493000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00012  |\n",
      "|    n_updates        | 122999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=494000, episode_reward=3.20 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.2      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 494000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000512 |\n",
      "|    n_updates        | 123249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=3.13 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.13     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 495000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 6.86e-05 |\n",
      "|    n_updates        | 123499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=4.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 496000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000259 |\n",
      "|    n_updates        | 123749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 2.31     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1333     |\n",
      "|    total_timesteps  | 496000   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=497000, episode_reward=4.75 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 4.75     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 497000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 123999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=498000, episode_reward=-12.11 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -12.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 498000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000233 |\n",
      "|    n_updates        | 124249   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=499000, episode_reward=3.09 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.09     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 499000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 8.09e-05 |\n",
      "|    n_updates        | 124499   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=3.34 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | 3.34     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 124749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 2.29     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 1343     |\n",
      "|    total_timesteps  | 500000   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x16d2685e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./rl-models/',\n",
    "                             log_path='./rl-logs/', eval_freq=1000,\n",
    "                             deterministic=True, render=False,\n",
    "                             )\n",
    "# model = PPO(\"MlpPolicy\", env, verbose=4,\n",
    "#             tensorboard_log=\"./rl-logs/\")\n",
    "model = DQN(\"MlpPolicy\", DummyVecEnv([lambda: Monitor(env)]), verbose=4, tensorboard_log=\"./rl-logs/\",\n",
    "            exploration_fraction=0.4,\n",
    "            target_update_interval=5000,\n",
    "            buffer_size=100000,\n",
    "            learning_starts=1000,\n",
    "            learning_rate=0.001\n",
    ")\n",
    "model.learn(total_timesteps=1000000, tb_log_name=\"ppo\",\n",
    "            callback=eval_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(env_class, max_steps, num_episodes, model=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model over several episodes and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained RL model to be evaluated.\n",
    "    - env_class: Environment class to create new instances of the evaluation environment.\n",
    "    - max_steps: Maximum number of steps per episode.\n",
    "    - num_episodes: Number of episodes to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - avg_observations: Average observations at each step.\n",
    "    - all_observations: List of observations for all episodes.\n",
    "    \"\"\"\n",
    "    all_observations = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        eval_env = TimeLimit(env_class(), max_steps)\n",
    "        done = False\n",
    "        obs, _ = eval_env.reset()\n",
    "        episode_observations = []\n",
    "        while not done:\n",
    "            if model is not None:\n",
    "                action, _states = model.predict(obs)\n",
    "            else:\n",
    "                action = eval_env.action_space.sample()\n",
    "            obs, rewards, term, trunc, info = eval_env.step(action)\n",
    "            done = term or trunc\n",
    "            episode_observations.append(info['n_cells'])\n",
    "        \n",
    "        all_observations.append(episode_observations)\n",
    "    \n",
    "    # Compute the average observations\n",
    "    max_len = max(len(obs) for obs in all_observations)\n",
    "    avg_observations = np.zeros(max_len)\n",
    "    counts = np.zeros(max_len)\n",
    "    \n",
    "    for obs in all_observations:\n",
    "        for i, val in enumerate(obs):\n",
    "            avg_observations[i] += val[-1]\n",
    "            counts[i] += 1\n",
    "    \n",
    "    avg_observations /= counts\n",
    "\n",
    "    return avg_observations, all_observations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_observations(avg_observations, all_observations, unif_obs=None, all_unif_obs=None):\n",
    "    \"\"\"\n",
    "    Plot the average observations and individual episode tracks.\n",
    "\n",
    "    Parameters:\n",
    "    - avg_observations: Average observations at each step.\n",
    "    - all_observations: List of observations for all episodes.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot individual episode tracks with lower alpha\n",
    "    for obs in all_observations:\n",
    "        plt.plot(x_axis, obs, alpha=0.05, linewidth=0.5, color='black')\n",
    "\n",
    "    if unif_obs is not None:\n",
    "        for obs in all_unif_obs:\n",
    "            plt.plot(x_axis, obs, alpha=0.05, linewidth=0.5, color='red')\n",
    "    \n",
    "    # Plot average observations\n",
    "    plt.plot(x_axis, avg_observations, label='trained policy', linewidth=3, color='black')\n",
    "    if unif_obs is not None:\n",
    "        plt.plot(x_axis, unif_obs, label='random policy', linewidth=3, color='red')\n",
    "    \n",
    "    plt.xlabel('Time (hours)')\n",
    "    plt.ylabel('Total cells (n_cells)')\n",
    "    plt.title('Model Evaluation: Average Observations and Individual Episode Tracks')\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "avg_obs, all_obs = evaluate_model(CellEnv, 1200, 10, model)\n",
    "unif_obs, unif_all_obs = evaluate_model(CellEnv, 1200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_observations(avg_obs, all_obs, unif_obs, unif_all_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
